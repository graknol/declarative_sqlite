# Project Documentation

Generated by llmifier on: 2025-09-23T21:09:13
Extraction Mode: full
Project Type: dart

---

<!-- BEGIN FILE: README.md -->
# Declarative SQLite

A comprehensive Dart and Flutter library ecosystem for declarative SQLite schema management and database operations with real-time synchronization capabilities.

## Overview

Declarative SQLite provides a fluent, type-safe API for defining database schemas and managing data with automatic migrations, streaming queries, and built-in synchronization features. The ecosystem consists of two main packages that work together seamlessly.

## Packages

### üì¶ Core Library (`declarative_sqlite`)

The foundation package providing declarative schema definition and database operations.

**Key Features:**
- **Declarative Schema Definition**: Define tables, columns, and relationships using a fluent builder API
- **Automatic Migration**: Schema changes are automatically applied to the database
- **Streaming Queries**: Real-time reactive queries that automatically update when data changes
- **File Management**: Built-in support for file attachments with FilesetField
- **Synchronization**: Conflict-free synchronization with remote servers using Last-Writer-Wins (LWW)
- **Type Safety**: Full type safety with proper column type definitions

### üì± Flutter Integration (`declarative_sqlite_flutter`)

Flutter-specific widgets and utilities that integrate seamlessly with the core library.

**Key Features:**
- **DatabaseProvider**: InheritedWidget for managing database lifecycle
- **QueryListView**: Reactive ListView that automatically updates when database changes
- **ServerSyncManagerWidget**: Widget for managing background synchronization
- **Seamless Integration**: Works with any Flutter app architecture

## Quick Start

### Core Library (Dart)

```dart
import 'package:declarative_sqlite/declarative_sqlite.dart';

// Define your schema
void buildSchema(SchemaBuilder builder) {
  builder.table('users', (table) {
    table.guid('id').notNull();
    table.text('name').notNull();
    table.text('email').notNull();
    table.date('created_at').notNull();
    table.key(['id']).primary();
  });
}

// Initialize database
final database = DeclarativeDatabase(
  schema: buildSchema,
  path: 'my_app.db',
);

// Perform operations
await database.insert('users', {
  'id': 'user-123',
  'name': 'John Doe',
  'email': 'john@example.com',
  'created_at': DateTime.now().toIso8601String(),
});

// Query data
final users = await database.query('users');

// Stream live updates
final userStream = database.streamQuery('users');
userStream.listen((users) {
  print('Users updated: ${users.length} total users');
});
```

### Flutter Integration

```dart
import 'package:flutter/material.dart';
import 'package:declarative_sqlite_flutter/declarative_sqlite_flutter.dart';

class MyApp extends StatelessWidget {
  @override
  Widget build(BuildContext context) {
    return MaterialApp(
      home: DatabaseProvider(
        schema: buildSchema,
        databaseName: 'app.db',
        child: UserListScreen(),
      ),
    );
  }
}

class UserListScreen extends StatelessWidget {
  @override
  Widget build(BuildContext context) {
    return Scaffold(
      appBar: AppBar(title: Text('Users')),
      body: QueryListView<User>(
        database: DatabaseProvider.of(context),
        query: (q) => q.from('users').orderBy('name'),
        mapper: User.fromMap,
        itemBuilder: (context, user) => ListTile(
          title: Text(user.name),
          subtitle: Text(user.email),
        ),
      ),
      floatingActionButton: FloatingActionButton(
        onPressed: () => _addUser(context),
        child: Icon(Icons.add),
      ),
    );
  }
  
  Future<void> _addUser(BuildContext context) async {
    final db = DatabaseProvider.of(context);
    await db.insert('users', {
      'id': 'user-${DateTime.now().millisecondsSinceEpoch}',
      'name': 'New User',
      'email': 'user@example.com',
      'created_at': DateTime.now().toIso8601String(),
    });
  }
}

class User {
  final String id;
  final String name;
  final String email;
  final DateTime createdAt;

  User({required this.id, required this.name, required this.email, required this.createdAt});

  static User fromMap(Map<String, Object?> map) {
    return User(
      id: map['id'] as String,
      name: map['name'] as String,
      email: map['email'] as String,
      createdAt: DateTime.parse(map['created_at'] as String),
    );
  }
}
```

## Schema Definition

The schema builder provides a fluent API for defining your database structure:

```dart
void buildSchema(SchemaBuilder builder) {
  // Define a users table
  builder.table('users', (table) {
    table.guid('id').notNull();
    table.text('name').notNull();
    table.text('email').notNull();
    table.integer('age').min(0);
    table.date('created_at').notNull();
    table.date('updated_at');
    table.key(['id']).primary();
  });

  // Define a posts table with relationships
  builder.table('posts', (table) {
    table.guid('id').notNull();
    table.guid('user_id').notNull();
    table.text('title').notNull();
    table.text('content');
    table.date('created_at').notNull();
    table.key(['id']).primary();
    // Foreign key relationships are handled at the application level
  });

  // Define a view for post summaries
  builder.view('post_summaries', (view) {
    view.select('posts.id, posts.title, users.name as author')
        .from('posts')
        .join('users', 'posts.user_id = users.id');
  });
}
```

## Column Types

The library supports various column types with built-in validation:

- **`text(name)`**: Text/string columns with optional constraints
- **`integer(name)`**: Integer columns with min/max validation
- **`real(name)`**: Real number (double) columns with min/max validation
- **`date(name)`**: DateTime columns (stored as ISO 8601 strings)
- **`guid(name)`**: GUID/UUID columns for unique identifiers
- **`fileset(name)`**: File attachment columns for managing file collections

All columns support:
- **`.notNull()`**: Make column required
- **`.min(value)`** / **`.max(value)`**: Set validation constraints
- **`.defaultValue(value)`**: Set default values

## File Management

FilesetField provides managed file attachments:

```dart
// Define a table with file attachments
builder.table('documents', (table) {
  table.guid('id').notNull();
  table.text('title').notNull();
  table.fileset('attachments').notNull(); // Required fileset
  table.fileset('gallery'); // Optional fileset
  table.key(['id']).primary();
});

// Work with files in your data models
class Document {
  final String id;
  final String title;
  final FilesetField attachments;
  final FilesetField? gallery;

  static Document fromMap(Map<String, Object?> map, DeclarativeDatabase db) {
    return Document(
      id: map['id'] as String,
      title: map['title'] as String,
      attachments: DataMappingUtils.filesetFieldFromValue(map['attachments'], db)!,
      gallery: DataMappingUtils.filesetFieldFromValue(map['gallery'], db),
    );
  }
}

// Use FilesetField methods
final document = documents.first;
final fileId = await document.attachments.addFile('report.pdf', pdfBytes);
final files = await document.attachments.getFiles();
await document.attachments.deleteFile(fileId);
```

## Synchronization

Built-in synchronization with conflict resolution:

```dart
// Setup sync in Flutter
ServerSyncManagerWidget(
  fetchInterval: Duration(minutes: 2),
  onFetch: (database, table, lastSynced) async {
    // Fetch updates from your server
    final updates = await apiClient.fetchUpdates(table, lastSynced);
    for (final update in updates) {
      await database.insert(table, update);
    }
  },
  onSend: (operations) async {
    // Send local changes to server
    return await apiClient.sendChanges(operations);
  },
  child: MyApp(),
)

// Sync operations are automatically tracked
await database.insert('users', userData); // Will be synced automatically
await database.update('users', updates, where: 'id = ?', whereArgs: [userId]);
await database.delete('users', where: 'id = ?', whereArgs: [userId]);
```

## Installation

Add the packages to your `pubspec.yaml`:

```yaml
dependencies:
  # Core library (required)
  declarative_sqlite:
    path: declarative_sqlite
    
  # Flutter integration (for Flutter apps)
  declarative_sqlite_flutter:
    path: declarative_sqlite_flutter
    
  # SQLite driver (choose one)
  sqflite: ^2.3.0  # For Flutter apps
  # OR
  sqflite_common_ffi: ^2.3.0  # For standalone Dart apps
```

## Examples

Complete examples are available in each package:

- **Core Library**: [Core usage examples](declarative_sqlite/example/)
- **Flutter Integration**: [Flutter app examples](declarative_sqlite_flutter/example/)

## Architecture

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ        Flutter Application         ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ    declarative_sqlite_flutter      ‚îÇ
‚îÇ  ‚Ä¢ DatabaseProvider                ‚îÇ
‚îÇ  ‚Ä¢ QueryListView                   ‚îÇ
‚îÇ  ‚Ä¢ ServerSyncManagerWidget         ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ       declarative_sqlite           ‚îÇ
‚îÇ  ‚Ä¢ Schema Definition               ‚îÇ
‚îÇ  ‚Ä¢ DeclarativeDatabase             ‚îÇ
‚îÇ  ‚Ä¢ Streaming Queries               ‚îÇ
‚îÇ  ‚Ä¢ Sync Management                 ‚îÇ
‚îÇ  ‚Ä¢ File Management                 ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ          SQLite Database           ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

## Development

### Prerequisites
- Dart SDK 3.5.3 or later
- Flutter SDK (for Flutter package)

### Building Core Library
```bash
cd declarative_sqlite
dart pub get
dart test
dart analyze
```

### Building Flutter Library
```bash
cd declarative_sqlite_flutter
flutter pub get
flutter test
flutter analyze
```

## Contributing

1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Add tests for new functionality
5. Ensure all tests pass
6. Submit a pull request

## License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.
<!-- END FILE: README.md -->

<!-- BEGIN FILE: LICENSE -->
MIT License

Copyright (c) 2025 Sindre van der Linden

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all
copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
SOFTWARE.

<!-- END FILE: LICENSE -->

<!-- BEGIN FILE: declarative_sqlite/analysis_options.yaml -->
# This file configures the static analysis results for your project (errors,
# warnings, and lints).
#
# This enables the 'recommended' set of lints from `package:lints`.
# This set helps identify many issues that may lead to problems when running
# or consuming Dart code, and enforces writing Dart using a single, idiomatic
# style and format.
#
# If you want a smaller set of lints you can change this to specify
# 'package:lints/core.yaml'. These are just the most critical lints
# (the recommended set includes the core lints).
# The core lints are also what is used by pub.dev for scoring packages.

include: package:lints/recommended.yaml

# Uncomment the following section to specify additional rules.

# linter:
#   rules:
#     - camel_case_types

# analyzer:
#   exclude:
#     - path/to/excluded/files/**

# For more information about the core and recommended set of lints, see
# https://dart.dev/go/core-lints

# For additional information about configuring this file, see
# https://dart.dev/guides/language/analysis-options

<!-- END FILE: declarative_sqlite/analysis_options.yaml -->

<!-- BEGIN FILE: declarative_sqlite/lib/declarative_sqlite.dart -->
/// A declarative SQLite library for Dart.
///
/// This library provides a fluent, declarative, and type-safe way to define
/// and interact with a SQLite database.
library declarative_sqlite;

export 'src/annotations/db_record.dart';
export 'src/annotations/register_factory.dart';
export 'src/builders/column_builder.dart';
export 'src/builders/date_column_builder.dart';
export 'src/builders/fileset_column_builder.dart';
export 'src/builders/guid_column_builder.dart';
export 'src/builders/integer_column_builder.dart';
export 'src/builders/key_builder.dart';
export 'src/builders/query_builder.dart';
export 'src/builders/real_column_builder.dart';
export 'src/builders/schema_builder.dart';
export 'src/builders/table_builder.dart';
export 'src/builders/text_column_builder.dart';
export 'src/builders/view_builder.dart';
export 'src/builders/where_clause.dart';
export 'src/data_mapping.dart';
export 'src/database.dart' show DeclarativeDatabase;
export 'src/files/file_repository.dart';
export 'src/files/fileset_field.dart';
export 'src/files/filesystem_file_repository.dart';
export 'src/record.dart' show DbRecord;
export 'src/record_factory.dart';
export 'src/record_map_factory_registry.dart';
export 'src/exceptions/db_exceptions.dart';
export 'src/scheduling/task_scheduler.dart';
export 'src/scheduling/database_maintenance_tasks.dart';
export 'src/schema/schema.dart';
export 'src/schema/table.dart';
export 'src/schema/view.dart';
export 'src/streaming/advanced_streaming_query.dart';
export 'src/streaming/query_dependency_analyzer.dart';
export 'src/streaming/streaming_query.dart';
export 'src/streaming/query_stream_manager.dart';
export 'src/sync/dirty_row.dart';
export 'src/sync/dirty_row_store.dart';
export 'src/sync/server_sync_manager.dart';
export 'src/sync/sqlite_dirty_row_store.dart';
export 'src/sync/hlc.dart';

<!-- END FILE: declarative_sqlite/lib/declarative_sqlite.dart -->

<!-- BEGIN FILE: declarative_sqlite/lib/generated_registrations.dart -->
import 'package:declarative_sqlite/declarative_sqlite.dart';

// This file is generated, and the import will be resolved by the build process.
// ignore: uri_does_not_exist
import 'package:declarative_sqlite/example/ultimate_example.dart' as ultimate_example;
// ignore: uri_does_not_exist
import 'package:declarative_sqlite/example/annotation_example.dart' as annotation_example;
// ignore: uri_does_not_exist
import 'package:declarative_sqlite/example/ultra_minimal_example.dart' as ultra_minimal_example;
// ignore: uri_does_not_exist
import 'package:declarative_sqlite/test/enhanced_generator_test.dart' as enhanced_generator_test;

/// Auto-generated factory registration function
/// Call this function to register all annotated record factories
void registerAllGeneratedFactories(DeclarativeDatabase database) {
  RecordMapFactoryRegistry.register<ultimate_example.User>((data, db) => ultimate_example.User(data, db));
  RecordMapFactoryRegistry.register<ultimate_example.Post>((data, db) => ultimate_example.Post(data, db));
  RecordMapFactoryRegistry.register<ultimate_example.Comment>((data, db) => ultimate_example.Comment(data, db));
  RecordMapFactoryRegistry.register<annotation_example.User>((data, db) => annotation_example.User(data, db));
  RecordMapFactoryRegistry.register<ultra_minimal_example.User>((data, db) => ultra_minimal_example.User(data, db));
  RecordMapFactoryRegistry.register<enhanced_generator_test.Post>((data, db) => enhanced_generator_test.Post(data, db));
}

<!-- END FILE: declarative_sqlite/lib/generated_registrations.dart -->

<!-- BEGIN FILE: declarative_sqlite/lib/placeholder.dart -->
// Placeholder file for build_runner.
<!-- END FILE: declarative_sqlite/lib/placeholder.dart -->

<!-- BEGIN FILE: declarative_sqlite/lib/src/annotations/db_record.dart -->
/// Annotation to mark a class for DbRecord code generation.
///
/// Classes annotated with @GenerateDbRecord will have typed getters and setters
/// generated automatically based on the table schema.
///
/// Example:
/// ```dart
/// @GenerateDbRecord('users')
/// @RegisterFactory()  // Optional: for automatic factory registration
/// class User extends DbRecord {
///   User(Map<String, Object?> data, DeclarativeDatabase database)
///       : super(data, 'users', database);
///
///   // Optional redirect to generated extension
///   static User fromMap(Map<String, Object?> data, DeclarativeDatabase database) {
///     return UserGenerated.fromMap(data, database);
///   }
/// }
/// ```
class GenerateDbRecord {
  /// The name of the database table this record represents.
  final String tableName;

  /// Creates a GenerateDbRecord annotation.
  ///
  /// [tableName] must match a table defined in your database schema.
  const GenerateDbRecord(this.tableName);
}
<!-- END FILE: declarative_sqlite/lib/src/annotations/db_record.dart -->

<!-- BEGIN FILE: declarative_sqlite/lib/src/annotations/register_factory.dart -->
/// Annotation to mark a class for automatic factory registration.
///
/// Classes annotated with @RegisterFactory will have their fromMap factory
/// methods automatically registered in the RecordMapFactoryRegistry during
/// code generation.
///
/// This annotation should be used together with @GenerateDbRecord to create
/// a complete generated record class with automatic registration.
///
/// Example:
/// ```dart
/// @GenerateDbRecord('users')
/// @RegisterFactory()
/// class User extends DbRecord {
///   User(Map<String, Object?> data, DeclarativeDatabase database)
///       : super(data, 'users', database);
/// }
/// ```
///
/// This will generate:
/// 1. Typed getters and setters for the User class
/// 2. A fromMap factory method
/// 3. Registration calls in a generated registration function
class RegisterFactory {
  /// Creates a RegisterFactory annotation.
  const RegisterFactory();
}
<!-- END FILE: declarative_sqlite/lib/src/annotations/register_factory.dart -->

<!-- BEGIN FILE: declarative_sqlite/lib/src/builders/column_builder.dart -->
import 'package:declarative_sqlite/src/schema/column.dart';
import 'package:meta/meta.dart';

/// Base class for all column builders.
abstract class ColumnBuilder {
  final String name;
  final String logicalType;
  final String dbType;

  @protected
  bool isNotNull = false;
  @protected
  bool isParent = false;
  @protected
  bool isLww = false;
  @protected
  Object? defaultValue;

  ColumnBuilder(this.name, this.logicalType, this.dbType);

  ColumnBuilder notNull([Object? defaultValue]) {
    isNotNull = true;
    this.defaultValue = defaultValue;
    return this;
  }

  ColumnBuilder parent() {
    isParent = true;
    return this;
  }

  ColumnBuilder lww() {
    isLww = true;
    return this;
  }

  ColumnBuilder defaultsTo(Object? value) {
    defaultValue = value;
    return this;
  }

  Column build() {
    return Column(
      name: name,
      logicalType: logicalType,
      type: dbType,
      isNotNull: isNotNull,
      defaultValue: defaultValue,
      isParent: isParent,
      isLww: isLww,
    );
  }
}

<!-- END FILE: declarative_sqlite/lib/src/builders/column_builder.dart -->

<!-- BEGIN FILE: declarative_sqlite/lib/src/builders/date_column_builder.dart -->
import 'column_builder.dart';

class DateColumnBuilder extends ColumnBuilder {
  DateColumnBuilder(String name) : super(name, 'date', 'TEXT');
}

<!-- END FILE: declarative_sqlite/lib/src/builders/date_column_builder.dart -->

<!-- BEGIN FILE: declarative_sqlite/lib/src/builders/fileset_column_builder.dart -->
import 'column_builder.dart';
import '../schema/column.dart';

class FilesetColumnBuilder extends ColumnBuilder {
  FilesetColumnBuilder(String name) : super(name, 'fileset', 'TEXT');

  @override
  Column build() {
    return Column(
      name: name,
      logicalType: logicalType,
      type: dbType,
      isNotNull: isNotNull,
      defaultValue: defaultValue,
    );
  }
}

<!-- END FILE: declarative_sqlite/lib/src/builders/fileset_column_builder.dart -->

<!-- BEGIN FILE: declarative_sqlite/lib/src/builders/guid_column_builder.dart -->
import 'package:declarative_sqlite/src/builders/column_builder.dart';

class GuidColumnBuilder extends ColumnBuilder {
  GuidColumnBuilder(String name) : super(name, 'guid', 'TEXT');
}

<!-- END FILE: declarative_sqlite/lib/src/builders/guid_column_builder.dart -->

<!-- BEGIN FILE: declarative_sqlite/lib/src/builders/integer_column_builder.dart -->
import 'package:declarative_sqlite/src/builders/column_builder.dart';
import 'package:declarative_sqlite/src/schema/column.dart';

class IntegerColumnBuilder extends ColumnBuilder {
  num? _minValue;
  num? _maxValue;

  IntegerColumnBuilder(String name) : super(name, 'integer', 'INTEGER');

  IntegerColumnBuilder min(num value) {
    _minValue = value;
    return this;
  }

  IntegerColumnBuilder max(num value) {
    _maxValue = value;
    return this;
  }

  @override
  Column build() {
    return Column(
      name: name,
      logicalType: logicalType,
      type: dbType,
      isNotNull: isNotNull,
      defaultValue: defaultValue,
      isParent: isParent,
      isLww: isLww,
      minValue: _minValue,
      maxValue: _maxValue,
    );
  }
}

<!-- END FILE: declarative_sqlite/lib/src/builders/integer_column_builder.dart -->

<!-- BEGIN FILE: declarative_sqlite/lib/src/builders/key_builder.dart -->
import 'package:declarative_sqlite/src/schema/key.dart';

class KeyBuilder {
  final List<String> columns;
  KeyType _type = KeyType.indexed;
  String? _foreignTable;
  List<String>? _foreignColumns;

  KeyBuilder(this.columns);

  void primary() {
    _type = KeyType.primary;
  }

  void index() {
    _type = KeyType.indexed;
  }

  void unique() {
    _type = KeyType.unique;
  }

  void foreignKey(String table, List<String> columns) {
    _type = KeyType.foreign;
    _foreignTable = table;
    _foreignColumns = columns;
  }

  Key build() {
    return Key(
      columns: columns,
      type: _type,
      foreignTable: _foreignTable,
      foreignColumns: _foreignColumns,
    );
  }
}

<!-- END FILE: declarative_sqlite/lib/src/builders/key_builder.dart -->

<!-- BEGIN FILE: declarative_sqlite/lib/src/builders/query_builder.dart -->
import 'package:equatable/equatable.dart';
import 'where_clause.dart';

class QueryBuilder extends Equatable {
  String? _from;
  final List<String> _columns = [];
  WhereClause? _where;
  final List<String> _orderBy = [];
  final List<String> _groupBy = [];
  final List<String> _joins = [];
  final List<Object?> _joinParameters = [];
  String? _having;
  String? _updateTable; // Table to target for CRUD operations

  QueryBuilder select(String column, [String? alias]) {
    if (alias != null) {
      _columns.add('$column AS $alias');
    } else {
      _columns.add(column);
    }
    return this;
  }

  QueryBuilder from(String table, [String? alias]) {
    if (alias != null) {
      _from = '$table AS $alias';
    } else {
      _from = table;
    }
    return this;
  }

  QueryBuilder where(WhereClause clause) {
    _where = clause;
    return this;
  }

  QueryBuilder orderBy(List<String> columns) {
    _orderBy.addAll(columns);
    return this;
  }

  QueryBuilder groupBy(List<String> columns) {
    _groupBy.addAll(columns);
    return this;
  }

  QueryBuilder having(String condition) {
    _having = condition;
    return this;
  }

  /// Specifies that results from this query should be CRUD-enabled
  /// targeting the specified table for update operations.
  /// 
  /// This allows queries from views or joins to return updatable records
  /// as long as they include system_id and system_version from the target table.
  QueryBuilder forUpdate(String tableName) {
    _updateTable = tableName;
    return this;
  }

  QueryBuilder join(String joinClause) {
    _joins.add(joinClause);
    return this;
  }

  QueryBuilder innerJoin(String table, dynamic onCondition, [String? alias]) {
    final tableWithAlias = alias != null ? '$table AS $alias' : table;
    final conditionSql = _buildJoinCondition(onCondition);
    _joins.add('INNER JOIN $tableWithAlias ON $conditionSql');
    return this;
  }

  QueryBuilder leftJoin(String table, dynamic onCondition, [String? alias]) {
    final tableWithAlias = alias != null ? '$table AS $alias' : table;
    final conditionSql = _buildJoinCondition(onCondition);
    _joins.add('LEFT JOIN $tableWithAlias ON $conditionSql');
    return this;
  }

  QueryBuilder rightJoin(String table, dynamic onCondition, [String? alias]) {
    final tableWithAlias = alias != null ? '$table AS $alias' : table;
    final conditionSql = _buildJoinCondition(onCondition);
    _joins.add('RIGHT JOIN $tableWithAlias ON $conditionSql');
    return this;
  }

  QueryBuilder fullOuterJoin(String table, dynamic onCondition, [String? alias]) {
    final tableWithAlias = alias != null ? '$table AS $alias' : table;
    final conditionSql = _buildJoinCondition(onCondition);
    _joins.add('FULL OUTER JOIN $tableWithAlias ON $conditionSql');
    return this;
  }

  QueryBuilder crossJoin(String table, [String? alias]) {
    final tableWithAlias = alias != null ? '$table AS $alias' : table;
    _joins.add('CROSS JOIN $tableWithAlias');
    return this;
  }

  /// Select a subquery with an alias
  QueryBuilder selectSubQuery(void Function(QueryBuilder) build, String alias) {
    final subQueryBuilder = QueryBuilder();
    build(subQueryBuilder);
    final built = subQueryBuilder.build();
    final subQuery = built.$1;
    _columns.add('($subQuery) AS $alias');
    return this;
  }

  /// Helper method to build join conditions
  String _buildJoinCondition(dynamic onCondition) {
    if (onCondition is String) {
      return onCondition;
    } else if (onCondition is WhereClause) {
      final built = onCondition.build();
      _joinParameters.addAll(built.parameters);
      return built.sql;
    } else {
      throw ArgumentError('Join condition must be either a String or WhereClause');
    }
  }

  (String, List<Object?>) build() {
    if (_from == null) {
      throw StateError('A "from" clause is required to build a query.');
    }

    final columns = _columns.isEmpty ? '*' : _columns.join(', ');

    var sql = 'SELECT $columns FROM $_from';
    var parameters = <Object?>[];

    // Add JOINs
    if (_joins.isNotEmpty) {
      sql += ' ${_joins.join(' ')}';
      parameters.addAll(_joinParameters);
    }

    if (_where != null) {
      final builtWhere = _where!.build();
      sql += ' WHERE ${builtWhere.sql}';
      parameters.addAll(builtWhere.parameters);
    }

    if (_groupBy.isNotEmpty) {
      sql += ' GROUP BY ${_groupBy.join(', ')}';
    }

    if (_having != null) {
      sql += ' HAVING $_having';
    }

    if (_orderBy.isNotEmpty) {
      sql += ' ORDER BY ${_orderBy.join(', ')}';
    }

    if (_limit != null) {
      sql += ' LIMIT $_limit';
    }

    if (_offset != null) {
      sql += ' OFFSET $_offset';
    }

    return (sql, parameters);
  }

  /// Gets the main table name being queried (without alias).
  String? get tableName {
    if (_from == null) return null;
    // Handle "table AS alias" format
    final parts = _from!.split(' ');
    return parts.first;
  }

  /// Gets the table name specified for CRUD operations via forUpdate()
  String? get updateTableName => _updateTable;

  int? _limit;
  int? _offset;

  QueryBuilder limit(int count) {
    _limit = count;
    return this;
  }

  QueryBuilder offset(int count) {
    _offset = count;
    return this;
  }

  @override
  List<Object?> get props => [
        _from,
        _columns,
        _where,
        _orderBy,
        _groupBy,
        _joins,
        _joinParameters,
        _having,
        _updateTable,
        _limit,
        _offset,
      ];
}

<!-- END FILE: declarative_sqlite/lib/src/builders/query_builder.dart -->

<!-- BEGIN FILE: declarative_sqlite/lib/src/builders/real_column_builder.dart -->
import 'package:declarative_sqlite/src/builders/column_builder.dart';
import 'package:declarative_sqlite/src/schema/column.dart';

class RealColumnBuilder extends ColumnBuilder {
  num? _minValue;
  num? _maxValue;

  RealColumnBuilder(String name) : super(name, 'real', 'REAL');

  RealColumnBuilder min(num value) {
    _minValue = value;
    return this;
  }

  RealColumnBuilder max(num value) {
    _maxValue = value;
    return this;
  }

  @override
  Column build() {
    return Column(
      name: name,
      logicalType: logicalType,
      type: dbType,
      isNotNull: isNotNull,
      defaultValue: defaultValue,
      isParent: isParent,
      isLww: isLww,
      minValue: _minValue,
      maxValue: _maxValue,
    );
  }
}

<!-- END FILE: declarative_sqlite/lib/src/builders/real_column_builder.dart -->

<!-- BEGIN FILE: declarative_sqlite/lib/src/builders/schema_builder.dart -->
import 'package:declarative_sqlite/src/schema/table.dart';
import 'package:declarative_sqlite/src/schema/schema.dart';
import 'package:declarative_sqlite/src/builders/table_builder.dart';
import 'package:declarative_sqlite/src/builders/view_builder.dart';
import 'package:declarative_sqlite/src/sync/hlc.dart';

/// A fluent builder for defining a database schema.
///
/// The `SchemaBuilder` is the entry point for defining the structure of your
/// database, including its tables and views.
///
/// Example:
/// ```dart
/// final schemaBuilder = SchemaBuilder();
///
/// schemaBuilder.table('users', (table) {
///   table.guid('id').notNull(Uuid().v4());
///   table.text('name').notNull('Default Name');
///   table.integer('age').notNull(0);
///   table.key(['id']).primary();
/// });
///
/// schemaBuilder.view('user_names', (view) {
///   view.select('name').from('users');
/// });
///
/// final schema = schemaBuilder.build();
/// ```
class SchemaBuilder {
  final _tableBuilders = <TableBuilder>[];
  final _viewBuilders = <ViewBuilder>[];

  /// Defines a table in the schema.
  ///
  /// The [name] is the name of the table.
  /// The [build] callback provides a [TableBuilder] to define the table's
  /// columns and keys.
  ///
  /// The [name] is not allowed to start with `__` (two underscores) as that is
  /// reserved for system tables.
  SchemaBuilder table(String name, void Function(TableBuilder) build) {
    final builder = TableBuilder(name);
    build(builder);
    _tableBuilders.add(builder);
    return this;
  }

  /// Defines a view in the schema.
  ///
  /// The [name] is the name of the view.
  /// The [build] callback provides a [ViewBuilder] to define the view's
  /// SELECT statement.
  SchemaBuilder view(String name, void Function(ViewBuilder) build) {
    final builder = ViewBuilder(name);
    build(builder);
    _viewBuilders.add(builder);
    return this;
  }

  /// Builds the [Schema] object.
  ///
  /// This should be called after all tables and views have been defined.
  Schema build() {
    final userTables = _tableBuilders
        .where((t) => !t.name.startsWith('__'))
        .map((b) => b.build())
        .toList();
    final systemTables = [
      _buildSystemTableSettings(),
      _buildSystemTableFiles(),
      _buildSystemTableDirtyRows(),
    ];

    return Schema(
      tables: [...userTables, ...systemTables],
      views: _viewBuilders.map((b) => b.build()).toList(),
    );
  }

  Table _buildSystemTableSettings() {
    final builder = TableBuilder('__settings');
    builder.text('key').notNull('_');
    builder.text('value');
    builder.key(['key']).primary();
    return builder.build();
  }

  Table _buildSystemTableFiles() {
    final builder = TableBuilder('__files');
    builder.guid('id').notNull('00000000-0000-0000-0000-000000000000');
    builder.guid('owner_id').notNull('00000000-0000-0000-0000-000000000000');
    builder.text('filename').notNull('default');
    builder.integer('remote_version').notNull(0);
    builder.text('mimetype').notNull('application/octet-stream');
    builder.integer('size').notNull(0);
    builder.key(['id']).primary();
    builder.key(['owner_id', 'filename']).index();
    return builder.build();
  }

  Table _buildSystemTableDirtyRows() {
    final builder = TableBuilder('__dirty_rows');
    builder.text('table_name').notNull('default');
    builder.guid('row_id').notNull('00000000-0000-0000-0000-000000000000');
    builder.text('hlc').notNull(Hlc.min.toString());
    builder.key(['table_name', 'row_id']).primary();
    return builder.build();
  }
}

<!-- END FILE: declarative_sqlite/lib/src/builders/schema_builder.dart -->

<!-- BEGIN FILE: declarative_sqlite/lib/src/builders/table_builder.dart -->
import 'package:declarative_sqlite/src/schema/column.dart';
import 'package:declarative_sqlite/src/builders/column_builder.dart';
import 'package:declarative_sqlite/src/builders/date_column_builder.dart';
import 'package:declarative_sqlite/src/builders/fileset_column_builder.dart';
import 'package:declarative_sqlite/src/builders/guid_column_builder.dart';
import 'package:declarative_sqlite/src/builders/integer_column_builder.dart';
import 'package:declarative_sqlite/src/builders/key_builder.dart';
import 'package:declarative_sqlite/src/builders/real_column_builder.dart';
import 'package:declarative_sqlite/src/builders/text_column_builder.dart';
import 'package:declarative_sqlite/src/schema/table.dart';

class TableBuilder {
  final String name;
  final List<ColumnBuilder> _columnBuilders = [];
  final List<KeyBuilder> _keyBuilders = [];

  TableBuilder(this.name);

  T _addColumn<T extends ColumnBuilder>(T builder) {
    _columnBuilders.add(builder);
    return builder;
  }

  GuidColumnBuilder guid(String name) => _addColumn(GuidColumnBuilder(name));
  TextColumnBuilder text(String name) => _addColumn(TextColumnBuilder(name));
  IntegerColumnBuilder integer(String name) =>
      _addColumn(IntegerColumnBuilder(name));
  RealColumnBuilder real(String name) => _addColumn(RealColumnBuilder(name));
  DateColumnBuilder date(String name) => _addColumn(DateColumnBuilder(name));
  FilesetColumnBuilder fileset(String name) =>
      _addColumn(FilesetColumnBuilder(name));

  KeyBuilder key(List<String> columns) {
    final builder = KeyBuilder(columns);
    _keyBuilders.add(builder);
    return builder;
  }

  Table build() {
    final columns = _columnBuilders.map((b) => b.build()).toList();
    final hlcColumns = <Column>[];
    for (final column in columns) {
      if (column.isLww) {
        hlcColumns.add(
          Column(
            name: '${column.name}__hlc',
            logicalType: 'hlc',
            type: 'TEXT',
            isNotNull: false, // Nullable to support partial inserts
            isParent: false,
            isLww: false,
          ),
        );
      }
    }

    final isSystemTable = name.startsWith('__');

    final systemColumns = isSystemTable
        ? <Column>[]
        : [
            Column(
              name: 'system_id',
              logicalType: 'guid',
              type: 'TEXT', // GUID
              isNotNull: true,
              defaultValue: '00000000-0000-0000-0000-000000000000',
              isParent: false,
              isLww: false,
            ),
            Column(
              name: 'system_created_at',
              logicalType: 'hlc',
              type: 'TEXT', // HLC
              isNotNull: true,
              defaultValue: '0000-00-00T00:00:00.000Z-0000-0000000000000000',
              isParent: false,
              isLww: false,
            ),
            Column(
              name: 'system_version',
              logicalType: 'hlc',
              type: 'TEXT', // HLC
              isNotNull: true,
              defaultValue: '0000-00-00T00:00:00.000Z-0000-0000000000000000',
              isParent: false,
              isLww: false,
            ),
          ];

    return Table(
      name: name,
      columns: [...systemColumns, ...columns, ...hlcColumns],
      keys: _keyBuilders.map((b) => b.build()).toList(),
    );
  }
}

<!-- END FILE: declarative_sqlite/lib/src/builders/table_builder.dart -->

<!-- BEGIN FILE: declarative_sqlite/lib/src/builders/text_column_builder.dart -->
import 'package:declarative_sqlite/src/builders/column_builder.dart';
import 'package:declarative_sqlite/src/schema/column.dart';

class TextColumnBuilder extends ColumnBuilder {
  int? _maxLength;

  TextColumnBuilder(String name) : super(name, 'text', 'TEXT');

  TextColumnBuilder maxLength(int value) {
    _maxLength = value;
    return this;
  }

  @override
  Column build() {
    return Column(
      name: name,
      logicalType: logicalType,
      type: dbType,
      isNotNull: isNotNull,
      defaultValue: defaultValue,
      isParent: isParent,
      isLww: isLww,
      maxLength: _maxLength,
    );
  }
}

<!-- END FILE: declarative_sqlite/lib/src/builders/text_column_builder.dart -->

<!-- BEGIN FILE: declarative_sqlite/lib/src/builders/view_builder.dart -->
import 'query_builder.dart';
import 'where_clause.dart';
import '../schema/view.dart';

class ViewBuilder {
  final String name;
  final List<String> _selectColumns = [];
  final List<String> _fromClauses = [];
  final List<String> _joinClauses = [];
  final List<WhereClause> _whereClauses = [];
  final List<String> _groupByColumns = [];
  final List<String> _havingClauses = [];
  final List<String> _orderByColumns = [];
  bool _hasFrom = false;

  ViewBuilder(this.name);

  /// Select a single column with optional alias
  /// Each column must be specified in a separate select() call
  ViewBuilder select(String columnExpression, [String? alias]) {
    assert(columnExpression.isNotEmpty, 
        'Column expression cannot be empty');
    assert(!columnExpression.contains(','), 
        'Multiple columns in single select() call are not allowed. '
        'Use separate select() calls for each column: '
        'view.select("col1").select("col2") instead of view.select("col1, col2")');
    assert(!columnExpression.toLowerCase().contains(' as ') || alias == null,
        'Do not use both inline AS alias and alias parameter. '
        'Use either select("column AS alias") or select("column", "alias")');
    
    if (alias != null) {
      _selectColumns.add('$columnExpression AS $alias');
    } else {
      _selectColumns.add(columnExpression);
    }
    return this;
  }

  ViewBuilder selectSubQuery(
      void Function(QueryBuilder) callback, String alias) {
    assert(alias.isNotEmpty, 'Sub-query alias cannot be empty');
    assert(!alias.contains(' '), 'Alias cannot contain spaces');
    
    final subQueryBuilder = QueryBuilder();
    callback(subQueryBuilder);
    final built = subQueryBuilder.build();
    final subQuery = built.$1;
    
    _selectColumns.add('($subQuery) AS $alias');
    return this;
  }

  ViewBuilder from(String table, [String? alias]) {
    assert(table.isNotEmpty, 'Table name cannot be empty');
    assert(!_hasFrom, 'FROM clause already specified. Use joins for additional tables.');
    assert(_fromClauses.isEmpty, 'FROM clause already specified');
    
    if (alias != null) {
      assert(alias.isNotEmpty, 'Table alias cannot be empty');
      assert(!alias.contains(' '), 'Table alias cannot contain spaces');
      _fromClauses.add('$table AS $alias');
    } else {
      _fromClauses.add(table);
    }
    _hasFrom = true;
    return this;
  }

  ViewBuilder fromSubQuery(
    void Function(QueryBuilder) build, [
    String? alias,
  ]) {
    assert(!_hasFrom, 'FROM clause already specified');
    assert(_fromClauses.isEmpty, 'FROM clause already specified');
    
    final subQueryBuilder = QueryBuilder();
    build(subQueryBuilder);
    final built = subQueryBuilder.build();
    final subQuery = built.$1;

    if (alias != null) {
      assert(alias.isNotEmpty, 'Sub-query alias cannot be empty');
      assert(!alias.contains(' '), 'Sub-query alias cannot contain spaces');
      _fromClauses.add('($subQuery) AS $alias');
    } else {
      _fromClauses.add('($subQuery)');
    }
    _hasFrom = true;
    return this;
  }

  @Deprecated('Use typed join methods instead: innerJoin(), leftJoin(), etc.')
  ViewBuilder join(String joinClause) {
    assert(joinClause.isNotEmpty, 'Join clause cannot be empty');
    assert(_hasFrom, 'FROM clause must be specified before joins');
    
    _joinClauses.add(joinClause);
    return this;
  }

  /// Inner join with proper condition builder support
  ViewBuilder innerJoin(String table, WhereClause onCondition, [String? alias]) {
    assert(table.isNotEmpty, 'Table name cannot be empty');
    assert(_hasFrom, 'FROM clause must be specified before joins');
    
    final tableWithAlias = alias != null ? '$table AS $alias' : table;
    final built = onCondition.build();
    _joinClauses.add('INNER JOIN $tableWithAlias ON ${built.sql}');
    return this;
  }

  /// Left join with proper condition builder support  
  ViewBuilder leftJoin(String table, WhereClause onCondition, [String? alias]) {
    assert(table.isNotEmpty, 'Table name cannot be empty');
    assert(_hasFrom, 'FROM clause must be specified before joins');
    
    final tableWithAlias = alias != null ? '$table AS $alias' : table;
    final built = onCondition.build();
    _joinClauses.add('LEFT JOIN $tableWithAlias ON ${built.sql}');
    return this;
  }

  /// Right join with proper condition builder support
  ViewBuilder rightJoin(String table, WhereClause onCondition, [String? alias]) {
    assert(table.isNotEmpty, 'Table name cannot be empty');
    assert(_hasFrom, 'FROM clause must be specified before joins');
    
    final tableWithAlias = alias != null ? '$table AS $alias' : table;
    final built = onCondition.build();
    _joinClauses.add('RIGHT JOIN $tableWithAlias ON ${built.sql}');
    return this;
  }

  /// Full outer join with proper condition builder support
  ViewBuilder fullOuterJoin(String table, WhereClause onCondition, [String? alias]) {
    assert(table.isNotEmpty, 'Table name cannot be empty');
    assert(_hasFrom, 'FROM clause must be specified before joins');
    
    final tableWithAlias = alias != null ? '$table AS $alias' : table;
    final built = onCondition.build();
    _joinClauses.add('FULL OUTER JOIN $tableWithAlias ON ${built.sql}');
    return this;
  }

  /// Cross join (Cartesian product)
  ViewBuilder crossJoin(String table, [String? alias]) {
    assert(table.isNotEmpty, 'Table name cannot be empty');
    assert(_hasFrom, 'FROM clause must be specified before joins');
    
    final tableWithAlias = alias != null ? '$table AS $alias' : table;
    _joinClauses.add('CROSS JOIN $tableWithAlias');
    return this;
  }

  ViewBuilder where(WhereClause condition) {
    assert(_hasFrom, 'FROM clause must be specified before WHERE clause');
    
    _whereClauses.add(condition);
    return this;
  }

  ViewBuilder groupBy(List<String> columns) {
    assert(columns.isNotEmpty, 'GROUP BY columns cannot be empty');
    assert(columns.every((col) => col.isNotEmpty), 'GROUP BY column names cannot be empty');
    assert(_hasFrom, 'FROM clause must be specified before GROUP BY clause');
    
    _groupByColumns.addAll(columns);
    return this;
  }

  @Deprecated('Use WhereClause builder for HAVING conditions')
  ViewBuilder having(String condition) {
    assert(condition.isNotEmpty, 'HAVING condition cannot be empty');
    assert(_groupByColumns.isNotEmpty, 'GROUP BY clause must be specified before HAVING clause');
    
    _havingClauses.add(condition);
    return this;
  }

  ViewBuilder orderBy(List<String> columns) {
    assert(columns.isNotEmpty, 'ORDER BY columns cannot be empty');
    assert(columns.every((col) => col.isNotEmpty), 'ORDER BY column names cannot be empty');
    assert(_hasFrom, 'FROM clause must be specified before ORDER BY clause');
    
    _orderByColumns.addAll(columns);
    return this;
  }

  View build() {
    assert(_selectColumns.isNotEmpty, 'At least one SELECT column must be specified');
    assert(_hasFrom, 'FROM clause must be specified');
    
    final definition = StringBuffer();
    
    // SELECT clause
    definition.write('SELECT ${_selectColumns.join(', ')}');
    
    // FROM clause
    definition.write(' FROM ${_fromClauses.join(', ')}');
    
    // JOIN clauses
    if (_joinClauses.isNotEmpty) {
      definition.write(' ${_joinClauses.join(' ')}');
    }
    
    // WHERE clause
    if (_whereClauses.isNotEmpty) {
      final combinedWhere = and(_whereClauses);
      final built = combinedWhere.build();
      definition.write(' WHERE ${built.sql}');
    }
    
    // GROUP BY clause
    if (_groupByColumns.isNotEmpty) {
      definition.write(' GROUP BY ${_groupByColumns.join(', ')}');
    }
    
    // HAVING clause
    if (_havingClauses.isNotEmpty) {
      definition.write(' HAVING ${_havingClauses.join(' AND ')}');
    }
    
    // ORDER BY clause
    if (_orderByColumns.isNotEmpty) {
      definition.write(' ORDER BY ${_orderByColumns.join(', ')}');
    }
    
    return View(name: name, definition: definition.toString());
  }
}

<!-- END FILE: declarative_sqlite/lib/src/builders/view_builder.dart -->

<!-- BEGIN FILE: declarative_sqlite/lib/src/builders/where_clause.dart -->
// lib/src/builders/where_clause.dart
import 'query_builder.dart';

abstract class WhereClause {
  BuiltWhereClause build();
}

class BuiltWhereClause {
  final String sql;
  final List<Object?> parameters;

  BuiltWhereClause(this.sql, this.parameters);
}

class Condition {
  final String _column;

  Condition(this._column);
  
  String get column => _column;

  Comparison eq(Object value) => _compare('=', value);
  Comparison neq(Object value) => _compare('!=', value);
  Comparison gt(Object value) => _compare('>', value);
  Comparison gte(Object value) => _compare('>=', value);
  Comparison lt(Object value) => _compare('<', value);
  Comparison lte(Object value) => _compare('<=', value);
  Comparison like(String value) => _compare('LIKE', value);
  Comparison get nil => _compare('IS NULL', null);
  Comparison get notNil => _compare('IS NOT NULL', null);

  Comparison _compare(String operator, Object? value) {
    return Comparison(_column, operator, value);
  }
}

class Comparison extends WhereClause {
  final String column;
  final String operator;
  final Object? value;

  Comparison(this.column, this.operator, this.value);

  @override
  BuiltWhereClause build() {
    if (value == null && (operator == 'IS NULL' || operator == 'IS NOT NULL')) {
      return BuiltWhereClause('$column $operator', []);
    }
    
    // Check if value is a column reference (Condition object)
    if (value is Condition) {
      final condition = value as Condition;
      return BuiltWhereClause('$column $operator ${condition.column}', []);
    }
    
    return BuiltWhereClause('$column $operator ?', [value]);
  }
}

class LogicalOperator extends WhereClause {
  final String operator;
  final List<WhereClause> clauses;

  LogicalOperator(this.operator, this.clauses);

  @override
  BuiltWhereClause build() {
    if (clauses.isEmpty) {
      return BuiltWhereClause('', []);
    }
    final builtClauses = clauses.map((c) => c.build()).toList();
    final sql = '(${builtClauses.map((c) => c.sql).join(' $operator ')})';
    final parameters = builtClauses.expand((c) => c.parameters).toList();
    return BuiltWhereClause(sql, parameters);
  }
}

Condition col(String column) => Condition(column);
LogicalOperator and(List<WhereClause> clauses) =>
    LogicalOperator('AND', clauses);
LogicalOperator or(List<WhereClause> clauses) => LogicalOperator('OR', clauses);

class Exists extends WhereClause {
  final QueryBuilder _subQuery;
  final bool _negated;

  Exists(this._subQuery, [this._negated = false]);

  @override
  BuiltWhereClause build() {
    final builtSubQuery = _subQuery.build();
    final subQuerySql = builtSubQuery.$1;
    final subQueryParameters = builtSubQuery.$2;
    final operator = _negated ? 'NOT EXISTS' : 'EXISTS';
    return BuiltWhereClause(
        '$operator ($subQuerySql)', subQueryParameters);
  }
}

Exists exists(void Function(QueryBuilder) build) {
  final builder = QueryBuilder();
  build(builder);
  return Exists(builder);
}

Exists notExists(void Function(QueryBuilder) build) {
  final builder = QueryBuilder();
  build(builder);
  return Exists(builder, true);
}

class RawSqlWhereClause extends WhereClause {
  final String sql;
  final List<Object?>? parameters;

  RawSqlWhereClause(this.sql, [this.parameters]);

  @override
  BuiltWhereClause build() {
    return BuiltWhereClause(sql, parameters ?? []);
  }
}

<!-- END FILE: declarative_sqlite/lib/src/builders/where_clause.dart -->

<!-- BEGIN FILE: declarative_sqlite/lib/src/data_mapping.dart -->
import 'package:declarative_sqlite/src/database.dart';
import 'package:declarative_sqlite/src/files/fileset_field.dart';

/// Base class for mapping database rows to typed objects.
///
/// Generated code will create subclasses of this for each table/view.
abstract class DataMapper<T> {
  String get tableName;

  /// Creates an instance of [T] from a database row map.
  T fromMap(Map<String, dynamic> map);
}

/// Utility class for converting database values to appropriate types.
class DataMappingUtils {
  /// Creates a FilesetField from a database value.
  /// 
  /// [value] should be the fileset identifier (string) from the database.
  /// [database] is the DeclarativeDatabase instance.
  static FilesetField? filesetFieldFromValue(
    dynamic value,
    DeclarativeDatabase database,
  ) {
    if (value == null) return null;
    return FilesetField.fromDatabaseValue(value, database);
  }

  /// Converts a FilesetField back to a database value.
  /// 
  /// Returns the fileset identifier string or null.
  static String? filesetFieldToValue(FilesetField? field) {
    return field?.toDatabaseValue();
  }
}

<!-- END FILE: declarative_sqlite/lib/src/data_mapping.dart -->

<!-- BEGIN FILE: declarative_sqlite/lib/src/database.dart -->
import 'dart:async';

import 'package:declarative_sqlite/src/builders/query_builder.dart';
import 'package:declarative_sqlite/src/builders/where_clause.dart';
import 'package:declarative_sqlite/src/exceptions/db_exception_wrapper.dart';
import 'package:declarative_sqlite/src/record.dart';
import 'package:declarative_sqlite/src/record_factory.dart';
import 'package:declarative_sqlite/src/record_map_factory_registry.dart';
import 'package:declarative_sqlite/src/schema/table.dart';
import 'package:declarative_sqlite/src/sync/sqlite_dirty_row_store.dart';
import 'package:sqflite_common/sqlite_api.dart' as sqflite;
import 'package:uuid/uuid.dart';

import 'files/file_repository.dart';
import 'files/fileset.dart';
import 'files/fileset_field.dart';
import 'migration/diff_schemas.dart';
import 'migration/generate_migration_scripts.dart';
import 'migration/introspect_schema.dart';
import 'schema/schema.dart';
import 'streaming/query_stream_manager.dart';
import 'streaming/streaming_query.dart';
import 'sync/hlc.dart';
import 'sync/dirty_row_store.dart';

/// A declarative SQLite database.
class DeclarativeDatabase {
  /// The underlying sqflite database.
  ///
  /// This is exposed for advanced use cases, but it's recommended to use the
  /// declarative API as much as possible.
  sqflite.DatabaseExecutor get db => _db;
  final sqflite.DatabaseExecutor _db;

  /// The schema for the database.
  final Schema schema;

  final DirtyRowStore? dirtyRowStore;

  /// The repository for storing and retrieving file content.
  final IFileRepository fileRepository;

  /// The Hybrid Logical Clock for generating timestamps.
  final HlcClock hlcClock;

  final String? transactionId;

  /// API for interacting with filesets.
  late final FileSet files;

  /// Manager for streaming queries.
  late final QueryStreamManager _streamManager;

  final Map<String, DbRecord> _recordCache = {};

  void registerRecord(DbRecord record) {
    final systemId = record.systemId;
    if (systemId != null) {
      _recordCache[systemId] = record;
    }
  }

  DbRecord? getRecordFromCache(String systemId) {
    return _recordCache[systemId];
  }

  DeclarativeDatabase._internal(
    this._db,
    this.schema,
    this.dirtyRowStore,
    this.hlcClock,
    this.fileRepository,
  ) : transactionId = null {
    files = FileSet(this);
    _streamManager = QueryStreamManager();
  }

  DeclarativeDatabase._inTransaction(
    this._db,
    this.schema,
    this.dirtyRowStore,
    this.hlcClock,
    this.fileRepository,
    this.transactionId,
  ) {
    files = FileSet(this);
    _streamManager = QueryStreamManager();
  }

  /// Opens the database at the given [path].
  ///
  /// The [schema] is used to create and migrate the database.
  /// The [dirtyRowStore] is used to store and retrieve operations for CRDTs.
  /// The [databaseFactory] is used to open the database.
  static Future<DeclarativeDatabase> open(
    String path, {
    required sqflite.DatabaseFactory databaseFactory,
    required Schema schema,
    DirtyRowStore? dirtyRowStore,
    required IFileRepository fileRepository,
    bool isReadOnly = false,
    bool isSingleInstance = true,
  }) async {
    return await DbExceptionWrapper.wrapConnection(() async {
      final db = await databaseFactory.openDatabase(
        path,
        options: sqflite.OpenDatabaseOptions(
          readOnly: isReadOnly,
          singleInstance: isSingleInstance,
        ),
      );

      // Migrate schema
      final liveSchemaHash = await _getSetting(db, 'schema_hash');
      final newSchemaHash = schema.toHash();
      if (newSchemaHash != liveSchemaHash) {
        final liveSchema = await introspectSchema(db);
        final changes = diffSchemas(schema, liveSchema);
        final scripts = generateMigrationScripts(changes);
        for (final script in scripts) {
          await db.execute(script);
        }
        await _setSetting(db, 'schema_hash', newSchemaHash);
      }

      // Initialize the dirty row store
      dirtyRowStore ??= SqliteDirtyRowStore();
      await dirtyRowStore?.init(db);

      // Get or create the persistent HLC node ID
      final nodeId =
          await _setSettingIfNotSet(db, 'hlc_node_id', () => Uuid().v4());

      final hlcClock = HlcClock(nodeId: nodeId);

      return DeclarativeDatabase._internal(
        db,
        schema,
        dirtyRowStore,
        hlcClock,
        fileRepository,
      );
    });
  }

  /// Closes the database.
  Future<void> close() async {
    _streamManager.dispose();
    if (_db is sqflite.Database) {
      await _db.close();
    }
  }

  /// Executes a raw SQL statement.
  Future<void> execute(String sql, [List<Object?>? arguments]) async {
    await _db.execute(sql, arguments);
  }

  /// Executes a raw SQL query and returns a list of the results.
  Future<List<Map<String, Object?>>> rawQuery(
    String sql, [
    List<Object?>? arguments,
  ]) {
    return _db.rawQuery(sql, arguments);
  }

  /// Executes a raw SQL statement and returns the number of changes.
  Future<int> rawUpdate(
    String sql, [
    List<Object?>? arguments,
  ]) {
    return _db.rawUpdate(sql, arguments);
  }

  /// Executes a raw SQL INSERT query and returns the last inserted row ID.
  Future<int> rawInsert(
    String sql, [
    List<Object?>? arguments,
  ]) {
    return _db.rawInsert(sql, arguments);
  }

  /// Executes a raw SQL DELETE query and returns the number of changes.
  Future<int> rawDelete(
    String sql, [
    List<Object?>? arguments,
  ]) {
    return _db.rawDelete(sql, arguments);
  }

  /// Executes a query built with a [QueryBuilder] and returns raw Map objects.
  ///
  /// This is a lower-level method. Most code should use query() to get
  /// typed DbRecord objects instead of raw maps.
  ///
  /// Example:
  /// ```dart
  /// final results = await db.queryMaps((q) => q.from('users'));
  /// final userName = results.first['name'] as String; // Manual casting needed
  /// ```
  Future<List<Map<String, Object?>>> queryMaps(
      void Function(QueryBuilder) onBuild) {
    final builder = QueryBuilder();
    onBuild(builder);
    return queryMapsWith(builder);
  }

  /// Executes a query built with a [QueryBuilder] and returns raw Map results.
  Future<List<Map<String, Object?>>> queryMapsWith(QueryBuilder builder) async {
    final (sql, params) = builder.build();
    final rawResults = await rawQuery(sql, params);

    // Apply fileset transformation if we have table context
    final tableName = builder.tableName;
    if (tableName != null) {
      return _transformFilesetColumns(tableName, rawResults);
    }

    return rawResults;
  }

  /// Creates a streaming query that emits new results whenever the underlying data changes.
  ///
  /// The [onBuild] callback is used to configure the query using a [QueryBuilder].
  /// The [mapper] function converts raw database rows to typed objects.
  ///
  /// Returns a [Stream] that emits a list of results whenever the query result changes.
  /// The stream will emit an initial result when subscribed to, and then emit new results
  /// whenever insert, update, delete, or bulkLoad operations affect the query dependencies.
  ///
  /// Example:
  /// ```dart
  /// final usersStream = db.stream<User>(
  ///   (q) => q.from('users').where(col('age').gt(18)),
  ///   (row) => User.fromMap(row),
  /// );
  ///
  /// usersStream.listen((users) {
  ///   print('Users updated: ${users.length}');
  /// });
  /// ```
  Stream<List<T>> stream<T>(
    void Function(QueryBuilder) onBuild,
    T Function(Map<String, Object?>) mapper,
  ) {
    final builder = QueryBuilder();
    onBuild(builder);
    return streamMapsWith(builder, mapper);
  }

  /// Creates a streaming query using an existing [QueryBuilder].
  ///
  /// See [stream] for more details.
  Stream<List<T>> streamMapsWith<T>(
    QueryBuilder builder,
    T Function(Map<String, Object?>) mapper,
  ) {
    final queryId = Uuid().v4();
    final streamingQuery = StreamingQuery.create(
      id: queryId,
      builder: builder,
      database: this,
      mapper: mapper,
    );

    _streamManager.register(streamingQuery);

    // Clean up when stream is disposed
    streamingQuery.stream.listen(
      null,
      onDone: () => _streamManager.unregister(queryId),
    );

    return streamingQuery.stream;
  }

  /// Executes a query and returns typed DbRecord objects.
  ///
  /// This is the main query method that intelligently determines CRUD vs read-only
  /// behavior by inspecting the QueryBuilder:
  /// - Table queries (simple from('table')) ‚Üí CRUD-enabled
  /// - View queries ‚Üí Read-only
  /// - Complex queries with forUpdate('table') ‚Üí CRUD-enabled for specified table
  ///
  /// Examples:
  /// ```dart
  /// // Table query - CRUD enabled
  /// final users = await db.query((q) => q.from('users'));
  /// users.first.setValue('name', 'Updated');
  /// await users.first.save(); // ‚úÖ Works
  ///
  /// // View query - read-only
  /// final details = await db.query((q) => q.from('user_details_view'));
  /// details.first.setValue('name', 'Test'); // ‚ùå StateError
  ///
  /// // Complex query with forUpdate - CRUD enabled for target table
  /// final results = await db.query(
  ///   (q) => q.from('user_details_view').forUpdate('users')
  /// );
  /// results.first.setValue('name', 'Updated');
  /// await results.first.save(); // ‚úÖ Updates users table
  /// ```
  Future<List<DbRecord>> query(void Function(QueryBuilder) onBuild) async {
    final builder = QueryBuilder();
    onBuild(builder);
    return queryWith(builder);
  }

  /// Executes a query built with a [QueryBuilder] and returns typed DbRecord objects.
  Future<List<DbRecord>> queryWith(QueryBuilder builder) async {
    final results = await queryMapsWith(builder);
    final tableName = builder.tableName;
    final updateTableName = builder.updateTableName;

    if (tableName == null) {
      throw ArgumentError(
          'QueryBuilder must specify a table to return DbRecord objects');
    }

    // If forUpdate was specified, validate the requirements
    if (updateTableName != null) {
      _validateForUpdateQuery(results, updateTableName);

      // Return records configured for CRUD with the specified update table
      return RecordFactory.fromMapList(results, tableName, this,
          updateTable: updateTableName);
    }

    // Determine if this is a table or view query by inspecting the QueryBuilder
    final isSimpleTableQuery = _isSimpleTableQuery(builder);

    if (isSimpleTableQuery) {
      // Simple table query - CRUD enabled by default
      return results
          .map((data) => RecordFactory.fromTable(data, tableName, this))
          .toList();
    } else {
      // View or complex query - read-only by default
      return results
          .map((data) => RecordFactory.fromQuery(data, tableName, this))
          .toList();
    }
  }

  /// Creates a streaming query that returns typed DbRecord objects.
  ///
  /// Like the query() method, this intelligently determines CRUD vs read-only
  /// behavior by inspecting the QueryBuilder shape.
  ///
  /// Example:
  /// ```dart
  /// final usersStream = db.streamRecords(
  ///   (q) => q.from('users').where(col('age').gt(18)),
  /// );
  ///
  /// usersStream.listen((users) {
  ///   for (final user in users) {
  ///     print('User: ${user.getValue<String>('name')}');
  ///     user.setValue('last_seen', DateTime.now());
  ///     await user.save(); // ‚úÖ Works for table queries
  ///   }
  /// });
  /// ```
  Stream<List<DbRecord>> streamRecords(
    void Function(QueryBuilder) onBuild,
  ) {
    final builder = QueryBuilder();
    onBuild(builder);
    return streamRecordsWith(builder);
  }

  /// Creates a streaming query using an existing [QueryBuilder] that returns DbRecord objects.
  Stream<List<DbRecord>> streamRecordsWith(QueryBuilder builder) {
    final tableName = builder.tableName;
    final updateTableName = builder.updateTableName;

    if (tableName == null) {
      throw ArgumentError(
          'QueryBuilder must specify a table to return DbRecord objects');
    }

    return streamMapsWith(
      builder,
      (row) {
        // Validate forUpdate requirements on each emitted result
        if (updateTableName != null) {
          _validateForUpdateQuery([row], updateTableName);
          return RecordFactory.fromQuery(row, tableName, this,
              updateTable: updateTableName);
        }

        // Determine if this is a simple table query by inspecting the QueryBuilder
        final isSimpleTableQuery = _isSimpleTableQuery(builder);

        if (isSimpleTableQuery) {
          return RecordFactory.fromTable(row, tableName, this);
        } else {
          return RecordFactory.fromQuery(row, tableName, this);
        }
      },
    );
  }

  // Typed query methods using RecordMapFactoryRegistry

  /// Executes a query and returns typed record objects using registered factories.
  ///
  /// The record type T must be registered with RecordMapFactoryRegistry.register<T>().
  /// This method uses the same intelligent CRUD vs read-only detection as query().
  ///
  /// Example:
  /// ```dart
  /// // First register the factory
  /// RecordMapFactoryRegistry.register<User>(User.fromMap);
  ///
  /// // Then query with automatic typing
  /// final users = await db.queryTyped<User>((q) => q.from('users'));
  /// users.first.name = 'Updated'; // Direct property access
  /// await users.first.save(); // ‚úÖ Works for table queries
  /// ```
  Future<List<T>> queryTyped<T extends DbRecord>(
    void Function(QueryBuilder) onBuild,
  ) async {
    final builder = QueryBuilder();
    onBuild(builder);
    return queryTypedWith<T>(builder);
  }

  /// Executes a query using an existing QueryBuilder and returns typed record objects.
  Future<List<T>> queryTypedWith<T extends DbRecord>(
      QueryBuilder builder) async {
    final results = await queryMapsWith(builder);
    final factory = RecordMapFactoryRegistry.getFactory<T>();

    return results.map((row) => factory(row, this)).toList();
  }

  /// Creates a streaming query that returns typed record objects using registered factories.
  ///
  /// Uses the same intelligent CRUD vs read-only detection as stream().
  Stream<List<T>> streamTyped<T extends DbRecord>(
    void Function(QueryBuilder) onBuild,
  ) {
    final builder = QueryBuilder();
    onBuild(builder);
    return streamTypedWith<T>(builder);
  }

  /// Creates a streaming query using an existing QueryBuilder that returns typed record objects.
  Stream<List<T>> streamTypedWith<T extends DbRecord>(QueryBuilder builder) {
    final factory = RecordMapFactoryRegistry.getFactory<T>();

    return streamMapsWith(
      builder,
      (row) => factory(row, this),
    );
  }

  /// Creates a transaction and runs the given [action] in it.
  ///
  /// The [action] is provided with a new [DeclarativeDatabase] instance that
  /// is bound to the transaction.
  Future<T> transaction<T>(
    Future<T> Function(DeclarativeDatabase txn) action, {
    bool? exclusive,
  }) async {
    return await DbExceptionWrapper.wrapTransaction(() async {
      if (_db is! sqflite.Database) {
        throw StateError('Cannot start a transaction within a transaction.');
      }
      final txnId = Uuid().v4();
      return _db.transaction(
        (txn) async {
          final db = DeclarativeDatabase._inTransaction(
            txn,
            schema,
            dirtyRowStore,
            hlcClock,
            fileRepository,
            txnId,
          );
          return await action(db);
        },
        exclusive: exclusive,
      );
    });
  }

  /// Inserts a row into the given [tableName].
  ///
  /// Returns the System ID of the last inserted row.
  Future<String> insert(String tableName, Map<String, Object?> values) async {
    return await DbExceptionWrapper.wrapCreate(() async {
      final now = hlcClock.now();
      final systemId = await _insert(tableName, values, now);
      await dirtyRowStore?.add(tableName, systemId, now);

      // Notify streaming queries of the change
      await _streamManager.notifyTableChanged(tableName);

      return systemId;
    }, tableName: tableName);
  }

  Future<String> _insert(
      String tableName, Map<String, Object?> values, Hlc hlc) async {
    final tableDef = _getTableDefinition(tableName);

    // Convert FilesetField values to database strings
    final convertedValues = _convertFilesetFieldsToValues(tableName, values);

    final valuesToInsert = {...convertedValues};
    valuesToInsert['system_version'] = hlc.toString();
    if (valuesToInsert['system_id'] == null) {
      valuesToInsert['system_id'] = Uuid().v4();
    }
    if (valuesToInsert['system_created_at'] == null) {
      valuesToInsert['system_created_at'] = hlc.toString();
    }

    for (final col in tableDef.columns) {
      if (col.isLww) {
        valuesToInsert['${col.name}__hlc'] = hlc.toString();
      }
    }

    await _db.insert(tableName, valuesToInsert);

    return valuesToInsert['system_id']! as String;
  }

  /// Updates rows in the given [tableName].
  ///
  /// The [values] are the new values for the rows.
  /// The [where] and [whereArgs] are used to filter the rows to update.
  ///
  /// Returns the number of rows updated.
  Future<int> update(
    String tableName,
    Map<String, Object?> values, {
    String? where,
    List<Object?>? whereArgs,
  }) async {
    return await DbExceptionWrapper.wrapUpdate(() async {
      final rowsToUpdate = await query(
        (q) {
          q.from(tableName).select('system_id');
          if (where != null) {
            q.where(RawSqlWhereClause(where, whereArgs));
          }
        },
      );

      final now = hlcClock.now();
      final result = await _update(
        tableName,
        values,
        now,
        where: where,
        whereArgs: whereArgs,
      );

      if (result > 0) {
        for (final row in rowsToUpdate) {
          await dirtyRowStore?.add(
              tableName, row.getValue<String>('system_id')!, now);
        }
        await _streamManager.notifyTableChanged(tableName);
      }

      return result;
    }, tableName: tableName);
  }

  Future<int> _update(
    String tableName,
    Map<String, Object?> values,
    Hlc hlc, {
    String? where,
    List<Object?>? whereArgs,
  }) async {
    final tableDef = _getTableDefinition(tableName);

    // Convert FilesetField values to database strings
    final convertedValues = _convertFilesetFieldsToValues(tableName, values);

    final lwwColumns =
        tableDef.columns.where((c) => c.isLww).map((c) => c.name);

    final valuesToUpdate = {...convertedValues};
    valuesToUpdate['system_version'] = hlc.toString();

    if (lwwColumns.isNotEmpty) {
      // We need to check the HLCs of the existing rows to see if we can
      // update them.
      final existingRows = await queryMaps(
        (q) {
          q.from(tableName)
              .select(lwwColumns.map((c) => '${c}__hlc').toList().join(', '));
          if (where != null) {
            q.where(RawSqlWhereClause(where, whereArgs));
          }
        },
      );

      if (existingRows.isNotEmpty) {
        final existingHlcs = existingRows.first;
        for (final colName in values.keys) {
          if (lwwColumns.contains(colName)) {
            final hlcColName = '${colName}__hlc';
            final existingHlc = existingHlcs[hlcColName] != null
                ? Hlc.parse(existingHlcs[hlcColName] as String)
                : null;
            if (existingHlc == null || hlc.compareTo(existingHlc) > 0) {
              valuesToUpdate[hlcColName] = hlc.toString();
            } else {
              // The value in the database is newer, so we remove this
              // column from the update.
              valuesToUpdate.remove(colName);
            }
          }
        }
      }
    }

    if (valuesToUpdate.length == 1 &&
        valuesToUpdate.containsKey('system_version')) {
      // Nothing to update except the system version, so we can skip this.
      return 0;
    }

    return _db.update(
      tableName,
      valuesToUpdate,
      where: where,
      whereArgs: whereArgs,
    );
  }

  Table _getTableDefinition(String tableName) {
    return schema.tables.firstWhere(
      (t) => t.name == tableName,
      orElse: () =>
          throw ArgumentError('Table not found in schema: $tableName'),
    );
  }

  /// Deletes rows from the given [tableName].
  ///
  /// The [where] and [whereArgs] are used to filter the rows to delete.
  ///
  /// Returns the number of rows deleted.
  Future<int> delete(
    String tableName, {
    String? where,
    List<Object?>? whereArgs,
  }) async {
    return await DbExceptionWrapper.wrapDelete(() async {
      // Make sure the table exists or throw an exception
      final _ = _getTableDefinition(tableName);

      final rowsToDelete = await query(
        (q) {
          q.from(tableName).select('system_id');
          if (where != null) {
            q.where(RawSqlWhereClause(where, whereArgs));
          }
        },
      );

      final result = await _db.delete(
        tableName,
        where: where,
        whereArgs: whereArgs,
      );

      if (result > 0) {
        final now = hlcClock.now();
        for (final row in rowsToDelete) {
          await dirtyRowStore?.add(
              tableName, row.getValue<String>('system_id')!, now);
        }
        await _streamManager.notifyTableChanged(tableName);
      }

      return result;
    }, tableName: tableName);
  }

  /// Queries the given [table] and returns a list of the results.
  Future<List<Map<String, Object?>>> queryTable(
    String table, {
    bool? distinct,
    List<String>? columns,
    String? where,
    List<Object?>? whereArgs,
    String? groupBy,
    String? having,
    String? orderBy,
    int? limit,
    int? offset,
  }) async {
    return await DbExceptionWrapper.wrapRead(() async {
      final rawResults = await _db.query(
        table,
        distinct: distinct,
        columns: columns,
        where: where,
        whereArgs: whereArgs,
        groupBy: groupBy,
        having: having,
        orderBy: orderBy,
        limit: limit,
        offset: offset,
      );

      return _transformFilesetColumns(table, rawResults);
    }, tableName: table);
  }

  /// Queries a query and returns a single result, or null if none is found.
  Future<Map<String, Object?>?> queryFirst(
    String table, {
    bool? distinct,
    List<String>? columns,
    String? where,
    List<Object?>? whereArgs,
    String? groupBy,
    String? having,
    String? orderBy,
    int? offset,
  }) async {
    final results = await queryTable(
      table,
      distinct: distinct,
      columns: columns,
      where: where,
      whereArgs: whereArgs,
      groupBy: groupBy,
      having: having,
      orderBy: orderBy,
      limit: 1,
      offset: offset,
    );
    return results.isNotEmpty ? results.first : null;
  }

  /// Queries an entire table and returns typed record objects using registered factories.
  ///
  /// The record type T must be registered with RecordMapFactoryRegistry.register<T>().
  ///
  /// Example:
  /// ```dart
  /// // First register the factory
  /// RecordMapFactoryRegistry.register<User>(User.fromMap);
  ///
  /// // Then query the whole table
  /// final allUsers = await db.queryTableTyped<User>('users');
  /// ```
  Future<List<T>> queryTableTyped<T extends DbRecord>(
    String tableName, {
    bool? distinct,
    List<String>? columns,
    String? where,
    List<Object?>? whereArgs,
    String? groupBy,
    String? having,
    String? orderBy,
    int? limit,
    int? offset,
  }) async {
    final results = await queryTable(
      tableName,
      distinct: distinct,
      columns: columns,
      where: where,
      whereArgs: whereArgs,
      groupBy: groupBy,
      having: having,
      orderBy: orderBy,
      limit: limit,
      offset: offset,
    );
    final factory = RecordMapFactoryRegistry.getFactory<T>();
    return results.map((row) => factory(row, this)).toList();
  }

  /// Transforms raw query results by converting fileset columns to FilesetField objects.
  List<Map<String, Object?>> _transformFilesetColumns(
    String tableName,
    List<Map<String, Object?>> rawResults,
  ) {
    if (rawResults.isEmpty) return rawResults;

    // Get table definition to identify fileset columns
    final tableDef = _getTableDefinition(tableName);
    final filesetColumns = tableDef.columns
        .where((col) => col.logicalType == 'fileset')
        .map((col) => col.name)
        .toSet();

    if (filesetColumns.isEmpty) return rawResults;

    // Transform each row
    return rawResults.map((row) {
      final transformedRow = <String, Object?>{...row};

      for (final columnName in filesetColumns) {
        if (transformedRow.containsKey(columnName)) {
          final value = transformedRow[columnName];
          transformedRow[columnName] = _createFilesetField(value);
        }
      }

      return transformedRow;
    }).toList();
  }

  /// Creates a FilesetField from a database value.
  Object? _createFilesetField(Object? value) {
    if (value == null) return null;
    return FilesetField.fromDatabaseValue(value, this);
  }

  /// Converts FilesetField values back to database strings before storing.
  Map<String, Object?> _convertFilesetFieldsToValues(
    String tableName,
    Map<String, Object?> values,
  ) {
    final tableDef = _getTableDefinition(tableName);
    final filesetColumns = tableDef.columns
        .where((col) => col.logicalType == 'fileset')
        .map((col) => col.name)
        .toSet();

    if (filesetColumns.isEmpty) return values;

    final convertedValues = <String, Object?>{...values};

    for (final columnName in filesetColumns) {
      if (convertedValues.containsKey(columnName)) {
        final value = convertedValues[columnName];
        if (value is FilesetField) {
          convertedValues[columnName] = value.toDatabaseValue();
        }
      }
    }

    return convertedValues;
  }

  /// Bulk loads data into a table, performing an "upsert" operation.
  ///
  /// This method is designed for loading data from a sync source. It respects
  /// LWW (Last-Write-Wins) semantics for columns marked as such.
  ///
  /// For each row in [rows]:
  /// - If a local row with the same `system_id` exists, it's an UPDATE.
  ///   - LWW columns are only updated if the incoming HLC is newer.
  ///   - Regular columns are always updated.
  /// - If no local row exists, it's an INSERT.
  ///
  /// Rows processed by this method are NOT marked as dirty.
  Future<void> bulkLoad(
      String tableName, List<Map<String, Object?>> rows) async {
    final tableDef = _getTableDefinition(tableName);
    final pkColumns = tableDef.keys
        .where((k) => k.isPrimary)
        .expand((k) => k.columns)
        .toSet();
    final lwwColumns =
        tableDef.columns.where((c) => c.isLww).map((c) => c.name).toSet();

    await transaction((db) async {
      for (final row in rows) {
        final systemId = row['system_id'] as String?;
        if (systemId == null) continue;

        final existing = await db.query(
          (q) => q
              .from(tableName)
              .where(RawSqlWhereClause('system_id = ?', [systemId])).limit(1),
        );

        if (existing.isNotEmpty) {
          // UPDATE logic
          final existingRow = existing.first;
          final valuesToUpdate = <String, Object?>{};
          final now = hlcClock.now();

          for (final entry in row.entries) {
            final colName = entry.key;
            if (pkColumns.contains(colName) || colName.endsWith('__hlc')) {
              continue;
            }

            if (lwwColumns.contains(colName)) {
              final hlcColName = '${colName}__hlc';
              final remoteHlcString = row[hlcColName] as String?;

              if (remoteHlcString != null) {
                // If HLC is provided, do a proper LWW comparison.
                final localHlcString =
                    existingRow.getValue<String?>(hlcColName);
                final localHlc =
                    localHlcString != null ? Hlc.parse(localHlcString) : null;
                final remoteHlc = Hlc.parse(remoteHlcString);

                if (localHlc == null || remoteHlc.compareTo(localHlc) > 0) {
                  valuesToUpdate[colName] = entry.value;
                  valuesToUpdate[hlcColName] = remoteHlc.toString();
                }
              } else {
                // If no HLC is provided, the server value wins (non-LWW update).
                valuesToUpdate[colName] = entry.value;
              }
            } else {
              // Regular column, always update.
              valuesToUpdate[colName] = entry.value;
            }
          }

          if (valuesToUpdate.isNotEmpty) {
            await db._update(
              tableName,
              valuesToUpdate,
              now,
              where: 'system_id = ?',
              whereArgs: [systemId],
            );
          }
        } else {
          // INSERT logic
          await db._insert(tableName, row, hlcClock.now());
        }
      }
    });

    // Notify streaming queries of the change
    await _streamManager.notifyTableChanged(tableName);
  }

  /// Validates that a query result meets the requirements for forUpdate
  void _validateForUpdateQuery(
      List<Map<String, Object?>> results, String updateTableName) {
    // Check that the update table exists in the schema
    schema.userTables.firstWhere(
      (table) => table.name == updateTableName,
      orElse: () =>
          throw ArgumentError('Update table $updateTableName not found in schema'),
    );

    if (results.isEmpty) return; // No results to validate

    final firstResult = results.first;

    // Verify that system_id is present
    if (!firstResult.containsKey('system_id') ||
        firstResult['system_id'] == null) {
      throw StateError(
          'Query with forUpdate(\'$updateTableName\') must include system_id column from the target table');
    }

    // Verify that system_version is present
    if (!firstResult.containsKey('system_version') ||
        firstResult['system_version'] == null) {
      throw StateError(
          'Query with forUpdate(\'$updateTableName\') must include system_version column from the target table');
    }
  }

  /// Determines if a QueryBuilder represents a simple table query (CRUD-enabled)
  /// vs a complex query or view query (read-only by default).
  ///
  /// A simple table query is one that:
  /// - Queries directly from a table (not a view)
  /// - Has no complex joins, subqueries, or aggregations
  /// - Can be safely updated via system_id
  bool _isSimpleTableQuery(QueryBuilder builder) {
    final tableName = builder.tableName;
    if (tableName == null) return false;

    // Check if the table name refers to an actual table (not a view)
    final isActualTable =
        schema.userTables.any((table) => table.name == tableName);
    if (!isActualTable) return false;

    // For now, we'll consider any direct table reference as "simple"
    // This could be enhanced to check for complex joins, aggregations, etc.
    // based on the QueryBuilder structure
    return true;
  }
}

// Static helper methods for settings
Future<String> _setSettingIfNotSet(
  sqflite.DatabaseExecutor db,
  String key,
  String Function() defaultFactory,
) async {
  var result = await _getSetting(db, key);
  result ??= await _setSetting(db, key, defaultFactory());
  return result;
}

Future<String> _setSetting(
  sqflite.DatabaseExecutor db,
  String key,
  String value,
) async {
  await db.insert(
    '__settings',
    {
      'key': key,
      'value': value,
    },
    conflictAlgorithm: sqflite.ConflictAlgorithm.replace,
  );
  return value;
}

Future<String?> _getSetting(
  sqflite.DatabaseExecutor db,
  String key,
) async {
  try {
    final result = await db.query('__settings',
        where: 'key = ?', whereArgs: [key], limit: 1, columns: ['value']);
    if (result.isNotEmpty) {
      return result.first['value'] as String?;
    }
  } on Exception {
    // Ignore any errors, most likely due to missing table,
    // in which case, there's nothing to do but to return null
  }
  return null;
}

<!-- END FILE: declarative_sqlite/lib/src/database.dart -->

<!-- BEGIN FILE: declarative_sqlite/lib/src/exceptions/db_exception_mapper.dart -->
import 'package:sqflite_common/sqlite_api.dart' as sqflite;
import 'db_exceptions.dart';

/// Utility class for mapping platform-specific database exceptions
/// to developer-friendly DbException types
class DbExceptionMapper {
  /// Maps a platform exception to a DbException based on operation type and error details
  static DbException mapException(
    Exception originalException,
    DbOperationType operationType, {
    String? tableName,
    String? columnName,
    Map<String, Object?>? context,
  }) {
    final errorMessage = originalException.toString();
    final lowerErrorMessage = errorMessage.toLowerCase();

    // Extract table name from error message if not provided
    final inferredTableName = tableName ?? _extractTableNameFromError(errorMessage);

    // Determine error category based on the exception type and message
    final errorCategory = _categorizeError(originalException, lowerErrorMessage);

    // Create appropriate exception based on operation type
    switch (operationType) {
      case DbOperationType.create:
        return _createInsertException(
          errorCategory,
          originalException,
          inferredTableName,
          columnName,
          context,
        );

      case DbOperationType.read:
        return _createReadException(
          errorCategory,
          originalException,
          inferredTableName,
          columnName,
          context,
        );

      case DbOperationType.update:
        return _createUpdateException(
          errorCategory,
          originalException,
          inferredTableName,
          columnName,
          context,
        );

      case DbOperationType.delete:
        return _createDeleteException(
          errorCategory,
          originalException,
          inferredTableName,
          context,
        );

      case DbOperationType.transaction:
        return _createTransactionException(
          errorCategory,
          originalException,
          context,
        );

      case DbOperationType.connection:
        return _createConnectionException(
          errorCategory,
          originalException,
          context,
        );

      case DbOperationType.migration:
        return _createMigrationException(
          errorCategory,
          originalException,
          context,
        );
    }
  }

  /// Categorizes an error based on the exception type and message content
  static DbErrorCategory _categorizeError(Exception originalException, String lowerErrorMessage) {
    // Check for SQLite-specific error codes and messages
    if (originalException is sqflite.DatabaseException) {
      final sqliteException = originalException;
      
      // Check by error codes first (more reliable)
      if (sqliteException.toString().contains('SQLITE_CONSTRAINT')) {
        return DbErrorCategory.constraintViolation;
      }
      
      if (sqliteException.toString().contains('SQLITE_BUSY') ||
          sqliteException.toString().contains('SQLITE_LOCKED')) {
        return DbErrorCategory.databaseLocked;
      }
      
      if (sqliteException.toString().contains('SQLITE_CORRUPT')) {
        return DbErrorCategory.corruption;
      }
      
      if (sqliteException.toString().contains('SQLITE_NOTFOUND') ||
          sqliteException.toString().contains('no such table') ||
          sqliteException.toString().contains('no such column')) {
        return DbErrorCategory.notFound;
      }
    }

    // Fallback to message-based detection
    if (lowerErrorMessage.contains('constraint') ||
        lowerErrorMessage.contains('unique') ||
        lowerErrorMessage.contains('foreign key') ||
        lowerErrorMessage.contains('primary key') ||
        lowerErrorMessage.contains('check constraint')) {
      return DbErrorCategory.constraintViolation;
    }

    if (lowerErrorMessage.contains('not found') ||
        lowerErrorMessage.contains('no such table') ||
        lowerErrorMessage.contains('no such column') ||
        lowerErrorMessage.contains('does not exist')) {
      return DbErrorCategory.notFound;
    }

    if (lowerErrorMessage.contains('locked') ||
        lowerErrorMessage.contains('busy') ||
        lowerErrorMessage.contains('timeout')) {
      return DbErrorCategory.databaseLocked;
    }

    if (lowerErrorMessage.contains('corrupt') ||
        lowerErrorMessage.contains('malformed')) {
      return DbErrorCategory.corruption;
    }

    if (lowerErrorMessage.contains('permission') ||
        lowerErrorMessage.contains('access denied') ||
        lowerErrorMessage.contains('unauthorized')) {
      return DbErrorCategory.accessDenied;
    }

    if (lowerErrorMessage.contains('invalid') ||
        lowerErrorMessage.contains('syntax error') ||
        lowerErrorMessage.contains('datatype mismatch')) {
      return DbErrorCategory.invalidData;
    }

    if (lowerErrorMessage.contains('conflict') ||
        lowerErrorMessage.contains('concurrent') ||
        lowerErrorMessage.contains('version')) {
      return DbErrorCategory.concurrencyConflict;
    }

    if (lowerErrorMessage.contains('schema') ||
        lowerErrorMessage.contains('migration')) {
      return DbErrorCategory.schemaMismatch;
    }

    if (lowerErrorMessage.contains('connection') ||
        lowerErrorMessage.contains('network') ||
        lowerErrorMessage.contains('disconnected')) {
      return DbErrorCategory.connectionError;
    }

    return DbErrorCategory.unknown;
  }

  /// Extracts table name from error message if possible
  static String? _extractTableNameFromError(String errorMessage) {
    // Try to extract table name from common error patterns
    final patterns = [
      RegExp(r'table (?:"|`)?(\w+)(?:"|`)?', caseSensitive: false),
      RegExp(r'in table (?:"|`)?(\w+)(?:"|`)?', caseSensitive: false),
      RegExp(r'on table (?:"|`)?(\w+)(?:"|`)?', caseSensitive: false),
    ];

    for (final pattern in patterns) {
      final match = pattern.firstMatch(errorMessage);
      if (match != null) {
        return match.group(1);
      }
    }

    return null;
  }

  static DbCreateException _createInsertException(
    DbErrorCategory errorCategory,
    Exception originalException,
    String? tableName,
    String? columnName,
    Map<String, Object?>? context,
  ) {
    switch (errorCategory) {
      case DbErrorCategory.constraintViolation:
        return DbCreateException.constraintViolation(
          message: _getConstraintViolationMessage(originalException, tableName, columnName),
          tableName: tableName,
          columnName: columnName,
          originalException: originalException,
          context: context,
        );

      case DbErrorCategory.invalidData:
        return DbCreateException.invalidData(
          message: _getInvalidDataMessage(originalException, tableName, columnName),
          tableName: tableName,
          columnName: columnName,
          originalException: originalException,
          context: context,
        );

      default:
        return DbCreateException(
          errorCategory: errorCategory,
          message: 'Failed to create record${tableName != null ? ' in table $tableName' : ''}',
          tableName: tableName,
          columnName: columnName,
          originalException: originalException,
          context: context,
        );
    }
  }

  static DbReadException _createReadException(
    DbErrorCategory errorCategory,
    Exception originalException,
    String? tableName,
    String? columnName,
    Map<String, Object?>? context,
  ) {
    switch (errorCategory) {
      case DbErrorCategory.notFound:
        return DbReadException.notFound(
          message: 'Record or resource not found${tableName != null ? ' in table $tableName' : ''}',
          tableName: tableName,
          originalException: originalException,
          context: context,
        );

      case DbErrorCategory.accessDenied:
        return DbReadException.accessDenied(
          message: 'Access denied when reading${tableName != null ? ' from table $tableName' : ''}',
          tableName: tableName,
          originalException: originalException,
          context: context,
        );

      default:
        return DbReadException(
          errorCategory: errorCategory,
          message: 'Failed to read record${tableName != null ? ' from table $tableName' : ''}',
          tableName: tableName,
          columnName: columnName,
          originalException: originalException,
          context: context,
        );
    }
  }

  static DbUpdateException _createUpdateException(
    DbErrorCategory errorCategory,
    Exception originalException,
    String? tableName,
    String? columnName,
    Map<String, Object?>? context,
  ) {
    switch (errorCategory) {
      case DbErrorCategory.constraintViolation:
        return DbUpdateException.constraintViolation(
          message: _getConstraintViolationMessage(originalException, tableName, columnName),
          tableName: tableName,
          columnName: columnName,
          originalException: originalException,
          context: context,
        );

      case DbErrorCategory.concurrencyConflict:
        return DbUpdateException.concurrencyConflict(
          message: 'Concurrency conflict when updating${tableName != null ? ' table $tableName' : ''}',
          tableName: tableName,
          originalException: originalException,
          context: context,
        );

      case DbErrorCategory.notFound:
        return DbUpdateException.notFound(
          message: 'Record to update not found${tableName != null ? ' in table $tableName' : ''}',
          tableName: tableName,
          originalException: originalException,
          context: context,
        );

      default:
        return DbUpdateException(
          errorCategory: errorCategory,
          message: 'Failed to update record${tableName != null ? ' in table $tableName' : ''}',
          tableName: tableName,
          columnName: columnName,
          originalException: originalException,
          context: context,
        );
    }
  }

  static DbDeleteException _createDeleteException(
    DbErrorCategory errorCategory,
    Exception originalException,
    String? tableName,
    Map<String, Object?>? context,
  ) {
    switch (errorCategory) {
      case DbErrorCategory.constraintViolation:
        return DbDeleteException.constraintViolation(
          message: 'Cannot delete record due to foreign key constraint${tableName != null ? ' in table $tableName' : ''}',
          tableName: tableName,
          originalException: originalException,
          context: context,
        );

      case DbErrorCategory.notFound:
        return DbDeleteException.notFound(
          message: 'Record to delete not found${tableName != null ? ' in table $tableName' : ''}',
          tableName: tableName,
          originalException: originalException,
          context: context,
        );

      default:
        return DbDeleteException(
          errorCategory: errorCategory,
          message: 'Failed to delete record${tableName != null ? ' from table $tableName' : ''}',
          tableName: tableName,
          originalException: originalException,
          context: context,
        );
    }
  }

  static DbTransactionException _createTransactionException(
    DbErrorCategory errorCategory,
    Exception originalException,
    Map<String, Object?>? context,
  ) {
    switch (errorCategory) {
      case DbErrorCategory.databaseLocked:
        return DbTransactionException.databaseLocked(
          message: 'Database is locked and transaction cannot proceed',
          originalException: originalException,
          context: context,
        );

      default:
        return DbTransactionException.rollback(
          message: 'Transaction failed and was rolled back',
          originalException: originalException,
          context: context,
        );
    }
  }

  static DbConnectionException _createConnectionException(
    DbErrorCategory errorCategory,
    Exception originalException,
    Map<String, Object?>? context,
  ) {
    switch (errorCategory) {
      case DbErrorCategory.corruption:
        return DbConnectionException.corruption(
          message: 'Database file is corrupted and cannot be opened',
          originalException: originalException,
          context: context,
        );

      default:
        return DbConnectionException.connectionFailed(
          message: 'Failed to establish database connection',
          originalException: originalException,
          context: context,
        );
    }
  }

  static DbMigrationException _createMigrationException(
    DbErrorCategory errorCategory,
    Exception originalException,
    Map<String, Object?>? context,
  ) {
    return DbMigrationException.schemaMismatch(
      message: 'Database schema migration failed',
      originalException: originalException,
      context: context,
    );
  }

  static String _getConstraintViolationMessage(
    Exception originalException,
    String? tableName,
    String? columnName,
  ) {
    final errorMessage = originalException.toString().toLowerCase();
    
    if (errorMessage.contains('unique')) {
      return 'Unique constraint violation${columnName != null ? ' on column $columnName' : ''}${tableName != null ? ' in table $tableName' : ''}';
    }
    
    if (errorMessage.contains('foreign key')) {
      return 'Foreign key constraint violation${tableName != null ? ' in table $tableName' : ''}';
    }
    
    if (errorMessage.contains('primary key')) {
      return 'Primary key constraint violation${tableName != null ? ' in table $tableName' : ''}';
    }
    
    if (errorMessage.contains('check')) {
      return 'Check constraint violation${columnName != null ? ' on column $columnName' : ''}${tableName != null ? ' in table $tableName' : ''}';
    }
    
    return 'Constraint violation${tableName != null ? ' in table $tableName' : ''}';
  }

  static String _getInvalidDataMessage(
    Exception originalException,
    String? tableName,
    String? columnName,
  ) {
    final errorMessage = originalException.toString().toLowerCase();
    
    if (errorMessage.contains('datatype mismatch')) {
      return 'Data type mismatch${columnName != null ? ' for column $columnName' : ''}${tableName != null ? ' in table $tableName' : ''}';
    }
    
    if (errorMessage.contains('syntax error')) {
      return 'Invalid SQL syntax in query';
    }
    
    return 'Invalid data provided${tableName != null ? ' for table $tableName' : ''}';
  }
}
<!-- END FILE: declarative_sqlite/lib/src/exceptions/db_exception_mapper.dart -->

<!-- BEGIN FILE: declarative_sqlite/lib/src/exceptions/db_exception_wrapper.dart -->
import 'dart:async';
import 'db_exceptions.dart';
import 'db_exception_mapper.dart';

/// Utility class for wrapping database operations with exception handling
/// 
/// Automatically catches platform-specific exceptions and converts them
/// to developer-friendly DbException types.
class DbExceptionWrapper {
  /// Wraps a database create operation with exception handling
  static Future<T> wrapCreate<T>(
    Future<T> Function() operation, {
    String? tableName,
    String? columnName,
    Map<String, Object?>? context,
  }) async {
    try {
      return await operation();
    } on DbException {
      // Re-throw already wrapped exceptions
      rethrow;
    } on Exception catch (e) {
      throw DbExceptionMapper.mapException(
        e,
        DbOperationType.create,
        tableName: tableName,
        columnName: columnName,
        context: context,
      );
    }
  }

  /// Wraps a database read operation with exception handling
  static Future<T> wrapRead<T>(
    Future<T> Function() operation, {
    String? tableName,
    String? columnName,
    Map<String, Object?>? context,
  }) async {
    try {
      return await operation();
    } on DbException {
      // Re-throw already wrapped exceptions
      rethrow;
    } on Exception catch (e) {
      throw DbExceptionMapper.mapException(
        e,
        DbOperationType.read,
        tableName: tableName,
        columnName: columnName,
        context: context,
      );
    }
  }

  /// Wraps a database update operation with exception handling
  static Future<T> wrapUpdate<T>(
    Future<T> Function() operation, {
    String? tableName,
    String? columnName,
    Map<String, Object?>? context,
  }) async {
    try {
      return await operation();
    } on DbException {
      // Re-throw already wrapped exceptions
      rethrow;
    } on Exception catch (e) {
      throw DbExceptionMapper.mapException(
        e,
        DbOperationType.update,
        tableName: tableName,
        columnName: columnName,
        context: context,
      );
    }
  }

  /// Wraps a database delete operation with exception handling
  static Future<T> wrapDelete<T>(
    Future<T> Function() operation, {
    String? tableName,
    Map<String, Object?>? context,
  }) async {
    try {
      return await operation();
    } on DbException {
      // Re-throw already wrapped exceptions
      rethrow;
    } on Exception catch (e) {
      throw DbExceptionMapper.mapException(
        e,
        DbOperationType.delete,
        tableName: tableName,
        context: context,
      );
    }
  }

  /// Wraps a database transaction operation with exception handling
  static Future<T> wrapTransaction<T>(
    Future<T> Function() operation, {
    Map<String, Object?>? context,
  }) async {
    try {
      return await operation();
    } on DbException {
      // Re-throw already wrapped exceptions
      rethrow;
    } on Exception catch (e) {
      throw DbExceptionMapper.mapException(
        e,
        DbOperationType.transaction,
        context: context,
      );
    }
  }

  /// Wraps a database connection operation with exception handling
  static Future<T> wrapConnection<T>(
    Future<T> Function() operation, {
    Map<String, Object?>? context,
  }) async {
    try {
      return await operation();
    } on DbException {
      // Re-throw already wrapped exceptions
      rethrow;
    } on Exception catch (e) {
      throw DbExceptionMapper.mapException(
        e,
        DbOperationType.connection,
        context: context,
      );
    }
  }

  /// Wraps a database migration operation with exception handling
  static Future<T> wrapMigration<T>(
    Future<T> Function() operation, {
    Map<String, Object?>? context,
  }) async {
    try {
      return await operation();
    } on DbException {
      // Re-throw already wrapped exceptions
      rethrow;
    } on Exception catch (e) {
      throw DbExceptionMapper.mapException(
        e,
        DbOperationType.migration,
        context: context,
      );
    }
  }

  /// Generic wrapper that can handle any operation type
  static Future<T> wrap<T>(
    Future<T> Function() operation,
    DbOperationType operationType, {
    String? tableName,
    String? columnName,
    Map<String, Object?>? context,
  }) async {
    try {
      return await operation();
    } on DbException {
      // Re-throw already wrapped exceptions
      rethrow;
    } on Exception catch (e) {
      throw DbExceptionMapper.mapException(
        e,
        operationType,
        tableName: tableName,
        columnName: columnName,
        context: context,
      );
    }
  }

  /// Synchronous wrapper for operations that don't return Future
  static T wrapSync<T>(
    T Function() operation,
    DbOperationType operationType, {
    String? tableName,
    String? columnName,
    Map<String, Object?>? context,
  }) {
    try {
      return operation();
    } on DbException {
      // Re-throw already wrapped exceptions
      rethrow;
    } on Exception catch (e) {
      throw DbExceptionMapper.mapException(
        e,
        operationType,
        tableName: tableName,
        columnName: columnName,
        context: context,
      );
    }
  }
}
<!-- END FILE: declarative_sqlite/lib/src/exceptions/db_exception_wrapper.dart -->

<!-- BEGIN FILE: declarative_sqlite/lib/src/exceptions/db_exceptions.dart -->
/// Enumeration of database operation types that can fail
enum DbOperationType {
  create,
  read,
  update,
  delete,
  transaction,
  migration,
  connection,
}

/// Enumeration of database error categories
enum DbErrorCategory {
  /// Constraint violation (unique, foreign key, check, etc.)
  constraintViolation,
  
  /// Resource not found (table, column, record, etc.)
  notFound,
  
  /// Invalid data or operation
  invalidData,
  
  /// Permission or access denied
  accessDenied,
  
  /// Database is locked or busy
  databaseLocked,
  
  /// Connection issues
  connectionError,
  
  /// Database corruption
  corruption,
  
  /// Schema mismatch or migration issues
  schemaMismatch,
  
  /// Concurrency conflict (optimistic locking, etc.)
  concurrencyConflict,
  
  /// Unknown or unexpected error
  unknown,
}

/// Base class for all database exceptions
/// 
/// Provides a developer-friendly interface similar to REST API status codes
/// for handling database operations failures.
abstract class DbException implements Exception {
  /// The operation that failed
  final DbOperationType operationType;
  
  /// The category of error
  final DbErrorCategory errorCategory;
  
  /// Human-readable error message
  final String message;
  
  /// Optional table name related to the error
  final String? tableName;
  
  /// Optional column name related to the error
  final String? columnName;
  
  /// The original platform-specific exception that caused this error
  final Exception? originalException;
  
  /// Additional context information
  final Map<String, Object?>? context;

  const DbException({
    required this.operationType,
    required this.errorCategory,
    required this.message,
    this.tableName,
    this.columnName,
    this.originalException,
    this.context,
  });

  @override
  String toString() {
    final buffer = StringBuffer();
    buffer.write('$runtimeType: $message');
    
    if (tableName != null) {
      buffer.write(' (table: $tableName');
      if (columnName != null) {
        buffer.write(', column: $columnName');
      }
      buffer.write(')');
    }
    
    if (originalException != null) {
      buffer.write(' [Original: ${originalException.runtimeType}]');
    }
    
    return buffer.toString();
  }
}

/// Exception thrown when a record cannot be created
class DbCreateException extends DbException {
  const DbCreateException({
    required super.errorCategory,
    required super.message,
    super.tableName,
    super.columnName,
    super.originalException,
    super.context,
  }) : super(
          operationType: DbOperationType.create,
        );

  /// Creates an exception for constraint violations during insert
  factory DbCreateException.constraintViolation({
    required String message,
    String? tableName,
    String? columnName,
    Exception? originalException,
    Map<String, Object?>? context,
  }) =>
      DbCreateException(
        errorCategory: DbErrorCategory.constraintViolation,
        message: message,
        tableName: tableName,
        columnName: columnName,
        originalException: originalException,
        context: context,
      );

  /// Creates an exception for invalid data during insert
  factory DbCreateException.invalidData({
    required String message,
    String? tableName,
    String? columnName,
    Exception? originalException,
    Map<String, Object?>? context,
  }) =>
      DbCreateException(
        errorCategory: DbErrorCategory.invalidData,
        message: message,
        tableName: tableName,
        columnName: columnName,
        originalException: originalException,
        context: context,
      );
}

/// Exception thrown when a record cannot be read/found
class DbReadException extends DbException {
  const DbReadException({
    required super.errorCategory,
    required super.message,
    super.tableName,
    super.columnName,
    super.originalException,
    super.context,
  }) : super(
          operationType: DbOperationType.read,
        );

  /// Creates an exception for when a record is not found
  factory DbReadException.notFound({
    required String message,
    String? tableName,
    Exception? originalException,
    Map<String, Object?>? context,
  }) =>
      DbReadException(
        errorCategory: DbErrorCategory.notFound,
        message: message,
        tableName: tableName,
        originalException: originalException,
        context: context,
      );

  /// Creates an exception for access denied during read
  factory DbReadException.accessDenied({
    required String message,
    String? tableName,
    Exception? originalException,
    Map<String, Object?>? context,
  }) =>
      DbReadException(
        errorCategory: DbErrorCategory.accessDenied,
        message: message,
        tableName: tableName,
        originalException: originalException,
        context: context,
      );
}

/// Exception thrown when a record cannot be updated
class DbUpdateException extends DbException {
  const DbUpdateException({
    required super.errorCategory,
    required super.message,
    super.tableName,
    super.columnName,
    super.originalException,
    super.context,
  }) : super(
          operationType: DbOperationType.update,
        );

  /// Creates an exception for constraint violations during update
  factory DbUpdateException.constraintViolation({
    required String message,
    String? tableName,
    String? columnName,
    Exception? originalException,
    Map<String, Object?>? context,
  }) =>
      DbUpdateException(
        errorCategory: DbErrorCategory.constraintViolation,
        message: message,
        tableName: tableName,
        columnName: columnName,
        originalException: originalException,
        context: context,
      );

  /// Creates an exception for concurrency conflicts during update
  factory DbUpdateException.concurrencyConflict({
    required String message,
    String? tableName,
    Exception? originalException,
    Map<String, Object?>? context,
  }) =>
      DbUpdateException(
        errorCategory: DbErrorCategory.concurrencyConflict,
        message: message,
        tableName: tableName,
        originalException: originalException,
        context: context,
      );

  /// Creates an exception for when the record to update is not found
  factory DbUpdateException.notFound({
    required String message,
    String? tableName,
    Exception? originalException,
    Map<String, Object?>? context,
  }) =>
      DbUpdateException(
        errorCategory: DbErrorCategory.notFound,
        message: message,
        tableName: tableName,
        originalException: originalException,
        context: context,
      );
}

/// Exception thrown when a record cannot be deleted
class DbDeleteException extends DbException {
  const DbDeleteException({
    required super.errorCategory,
    required super.message,
    super.tableName,
    super.originalException,
    super.context,
  }) : super(
          operationType: DbOperationType.delete,
        );

  /// Creates an exception for constraint violations during delete
  factory DbDeleteException.constraintViolation({
    required String message,
    String? tableName,
    Exception? originalException,
    Map<String, Object?>? context,
  }) =>
      DbDeleteException(
        errorCategory: DbErrorCategory.constraintViolation,
        message: message,
        tableName: tableName,
        originalException: originalException,
        context: context,
      );

  /// Creates an exception for when the record to delete is not found
  factory DbDeleteException.notFound({
    required String message,
    String? tableName,
    Exception? originalException,
    Map<String, Object?>? context,
  }) =>
      DbDeleteException(
        errorCategory: DbErrorCategory.notFound,
        message: message,
        tableName: tableName,
        originalException: originalException,
        context: context,
      );
}

/// Exception thrown when a transaction fails
class DbTransactionException extends DbException {
  const DbTransactionException({
    required super.errorCategory,
    required super.message,
    super.originalException,
    super.context,
  }) : super(
          operationType: DbOperationType.transaction,
        );

  /// Creates an exception for when a transaction is rolled back
  factory DbTransactionException.rollback({
    required String message,
    Exception? originalException,
    Map<String, Object?>? context,
  }) =>
      DbTransactionException(
        errorCategory: DbErrorCategory.concurrencyConflict,
        message: message,
        originalException: originalException,
        context: context,
      );

  /// Creates an exception for when a database is locked during transaction
  factory DbTransactionException.databaseLocked({
    required String message,
    Exception? originalException,
    Map<String, Object?>? context,
  }) =>
      DbTransactionException(
        errorCategory: DbErrorCategory.databaseLocked,
        message: message,
        originalException: originalException,
        context: context,
      );
}

/// Exception thrown when database connection fails
class DbConnectionException extends DbException {
  const DbConnectionException({
    required super.errorCategory,
    required super.message,
    super.originalException,
    super.context,
  }) : super(
          operationType: DbOperationType.connection,
        );

  /// Creates an exception for connection failures
  factory DbConnectionException.connectionFailed({
    required String message,
    Exception? originalException,
    Map<String, Object?>? context,
  }) =>
      DbConnectionException(
        errorCategory: DbErrorCategory.connectionError,
        message: message,
        originalException: originalException,
        context: context,
      );

  /// Creates an exception for database corruption
  factory DbConnectionException.corruption({
    required String message,
    Exception? originalException,
    Map<String, Object?>? context,
  }) =>
      DbConnectionException(
        errorCategory: DbErrorCategory.corruption,
        message: message,
        originalException: originalException,
        context: context,
      );
}

/// Exception thrown when database migration fails
class DbMigrationException extends DbException {
  const DbMigrationException({
    required super.errorCategory,
    required super.message,
    super.originalException,
    super.context,
  }) : super(
          operationType: DbOperationType.migration,
        );

  /// Creates an exception for schema mismatch
  factory DbMigrationException.schemaMismatch({
    required String message,
    Exception? originalException,
    Map<String, Object?>? context,
  }) =>
      DbMigrationException(
        errorCategory: DbErrorCategory.schemaMismatch,
        message: message,
        originalException: originalException,
        context: context,
      );
}
<!-- END FILE: declarative_sqlite/lib/src/exceptions/db_exceptions.dart -->

<!-- BEGIN FILE: declarative_sqlite/lib/src/files/file_repository.dart -->
import 'dart:async';

/// Defines the contract for a file repository used to store and retrieve
/// the content of files.
abstract class IFileRepository {
  /// Adds a file's content to a logical container.
  ///
  /// [filesetId] is the ID of the container (e.g., a folder).
  /// [fileId] is the unique ID of the file (e.g., a filename).
  /// [content] is a stream of the file's byte content.
  ///
  /// Returns the path where the file was stored.
  Future<String> addFile(
    String filesetId,
    String fileId,
    Stream<List<int>> content,
  );

  /// Removes a file's content.
  ///
  /// [filesetId] is the ID of the container.
  /// [fileId] is the ID of the file to remove.
  Future<void> removeFile(String filesetId, String fileId);

  /// Retrieves the content of a specific file.
  ///
  /// [filesetId] is the ID of the container.
  /// [fileId] is the ID of the file to retrieve.
  ///
  /// Returns a stream of the file's byte content.
  Future<Stream<List<int>>> getFileContent(String filesetId, String fileId);

  /// Performs garbage collection on filesets.
  ///
  /// Removes all fileset directories on disk that are not in the provided
  /// [validFilesetIds] list. This helps clean up orphaned filesets that
  /// may have been left behind when database records were deleted.
  ///
  /// [validFilesetIds] is the list of all valid fileset IDs that should
  /// be preserved. Any fileset directory not in this list will be removed.
  ///
  /// Returns the number of orphaned filesets that were removed.
  Future<int> garbageCollectFilesets(List<String> validFilesetIds);

  /// Performs garbage collection on files within a specific fileset.
  ///
  /// Removes all files on disk in the specified fileset that are not in the
  /// provided [validFileIds] list. This helps clean up orphaned files that
  /// may have been left behind when file records were deleted.
  ///
  /// [filesetId] is the ID of the fileset to clean up.
  /// [validFileIds] is the list of all valid file IDs that should be
  /// preserved within this fileset. Any file not in this list will be removed.
  ///
  /// Returns the number of orphaned files that were removed.
  Future<int> garbageCollectFiles(String filesetId, List<String> validFileIds);
}

<!-- END FILE: declarative_sqlite/lib/src/files/file_repository.dart -->

<!-- BEGIN FILE: declarative_sqlite/lib/src/files/fileset.dart -->
import 'dart:async';
import 'dart:typed_data';

import 'package:declarative_sqlite/src/database.dart';
import 'package:uuid/uuid.dart';

/// Orchestrates file storage and metadata for fileset columns.
class FileSet {
  final DeclarativeDatabase _db;

  FileSet(this._db);

  /// Adds a file to a fileset.
  ///
  /// This creates a record in the `__files` table and stores the file
  /// using the configured [IFileRepository].
  ///
  /// Returns the ID of the newly created file record.
  Future<String> addFile(
    String fileset,
    String fileName,
    Uint8List content,
  ) async {
    final fileId = Uuid().v4();
    final now = _db.hlcClock.now();

    // Store the file content using the repository
    await _db.fileRepository.addFile(fileset, fileId, Stream.value(content));

    // Store the metadata in the database
    await _db.insert('__files', {
      'id': fileId,
      'fileset': fileset,
      'name': fileName,
      'size': content.length,
      'created_at': now.toString(),
      'modified_at': now.toString(),
    });

    return fileId;
  }

  /// Retrieves the content of a file.
  Future<Uint8List?> getFileContent(String fileId) async {
    final fileRecord = await _db.queryTable(
      '__files',
      where: 'id = ?',
      whereArgs: [fileId],
    );

    if (fileRecord.isEmpty) {
      return null;
    }

    final fileset = fileRecord.first['fileset'] as String;
    final contentStream =
        await _db.fileRepository.getFileContent(fileset, fileId);

    final completer = Completer<Uint8List>();
    final builder = BytesBuilder();
    contentStream.listen(
      builder.add,
      onDone: () => completer.complete(builder.toBytes()),
      onError: completer.completeError,
    );
    return completer.future;
  }

  /// Deletes a file from a fileset.
  ///
  /// This removes the file from the [IFileRepository] and deletes its
  /// metadata record from the `__files` table.
  Future<void> deleteFile(String fileId) async {
    final fileRecord = await _db.queryTable(
      '__files',
      where: 'id = ?',
      whereArgs: [fileId],
    );

    if (fileRecord.isNotEmpty) {
      final fileset = fileRecord.first['fileset'] as String;
      await _db.fileRepository.removeFile(fileset, fileId);
      await _db.delete('__files', where: 'id = ?', whereArgs: [fileId]);
    }
  }

  /// Gets all files in a specific fileset.
  ///
  /// Returns a list of file metadata records from the `__files` table
  /// for the given fileset.
  Future<List<Map<String, dynamic>>> getFilesInFileset(String fileset) async {
    return await _db.queryTable(
      '__files',
      where: 'fileset = ?',
      whereArgs: [fileset],
      orderBy: 'created_at DESC',
    );
  }

  /// Gets the count of files in a specific fileset.
  ///
  /// Returns the number of files in the given fileset.
  Future<int> getFileCountInFileset(String fileset) async {
    final result = await _db.queryTable(
      '__files',
      columns: ['COUNT(*) as count'],
      where: 'fileset = ?',
      whereArgs: [fileset],
    );
    return result.first['count'] as int;
  }

  /// Performs garbage collection on fileset directories.
  ///
  /// This method identifies and removes orphaned fileset directories from the
  /// file repository. Orphaned filesets are those that exist on disk but have
  /// no corresponding records in the database.
  ///
  /// Optionally, you can provide [additionalValidFilesets] to preserve specific
  /// filesets that might not be in the database but should be kept.
  ///
  /// Returns the number of orphaned filesets that were removed.
  Future<int> garbageCollectFilesets({
    List<String> additionalValidFilesets = const [],
  }) async {
    // Get all filesets referenced in the database
    final filesetRecords = await _db.queryTable(
      '__files',
      columns: ['DISTINCT fileset'],
    );

    final validFilesets = <String>{
      ...filesetRecords.map((record) => record['fileset'] as String),
      ...additionalValidFilesets,
    };

    return await _db.fileRepository.garbageCollectFilesets(validFilesets.toList());
  }

  /// Performs garbage collection on files within a specific fileset.
  ///
  /// This method identifies and removes orphaned files from the specified
  /// fileset directory. Orphaned files are those that exist on disk but have
  /// no corresponding records in the database.
  ///
  /// [fileset] is the fileset ID to clean up.
  /// Optionally, you can provide [additionalValidFiles] to preserve specific
  /// files that might not be in the database but should be kept.
  ///
  /// Returns the number of orphaned files that were removed.
  Future<int> garbageCollectFilesInFileset(
    String fileset, {
    List<String> additionalValidFiles = const [],
  }) async {
    // Get all file IDs in this fileset from the database
    final fileRecords = await _db.queryTable(
      '__files',
      columns: ['id'],
      where: 'fileset = ?',
      whereArgs: [fileset],
    );

    final validFiles = <String>{
      ...fileRecords.map((record) => record['id'] as String),
      ...additionalValidFiles,
    };

    return await _db.fileRepository.garbageCollectFiles(fileset, validFiles.toList());
  }

  /// Performs a comprehensive garbage collection on both filesets and files.
  ///
  /// This is a convenience method that first cleans up orphaned filesets,
  /// then cleans up orphaned files within the remaining valid filesets.
  ///
  /// Returns a map with 'filesets' and 'files' keys indicating the number
  /// of orphaned items removed in each category.
  Future<Map<String, int>> garbageCollectAll() async {
    int removedFilesets = 0;
    int removedFiles = 0;

    // First, clean up orphaned filesets
    removedFilesets = await garbageCollectFilesets();

    // Then, clean up orphaned files in each remaining valid fileset
    final validFilesetRecords = await _db.queryTable(
      '__files',
      columns: ['DISTINCT fileset'],
    );

    for (final record in validFilesetRecords) {
      final fileset = record['fileset'] as String;
      removedFiles += await garbageCollectFilesInFileset(fileset);
    }

    return {
      'filesets': removedFilesets,
      'files': removedFiles,
    };
  }
}

<!-- END FILE: declarative_sqlite/lib/src/files/fileset.dart -->

<!-- BEGIN FILE: declarative_sqlite/lib/src/files/fileset_field.dart -->
import 'dart:async';
import 'dart:typed_data';

import 'package:declarative_sqlite/src/database.dart';
import 'package:declarative_sqlite/src/files/fileset.dart';

/// Represents a fileset column value with convenient access to file operations.
/// 
/// This class wraps a fileset identifier and provides easy access to file
/// operations for that specific fileset through the database's FileSet instance.
class FilesetField {
  final String? _filesetId;
  final DeclarativeDatabase _database;
  late final FileSet _fileSet;

  /// Creates a new FilesetField with the given fileset identifier and database.
  FilesetField._(this._filesetId, this._database) {
    _fileSet = _database.files;
  }

  /// Creates a FilesetField from a database value.
  /// 
  /// [value] should be the fileset identifier (string) from the database.
  /// [database] is the DeclarativeDatabase instance.
  factory FilesetField.fromDatabaseValue(
    dynamic value,
    DeclarativeDatabase database,
  ) {
    final filesetId = value as String?;
    return FilesetField._(filesetId, database);
  }

  /// Gets the fileset identifier.
  String? get filesetId => _filesetId;

  /// Returns true if this fileset field has a value (is not null or empty).
  bool get hasValue => _filesetId != null && _filesetId.isNotEmpty;

  /// Adds a file to this fileset.
  ///
  /// Returns the ID of the newly created file record.
  /// Throws [StateError] if this fileset field has no value.
  Future<String> addFile(
    String fileName,
    Uint8List content,
  ) async {
    if (!hasValue) {
      throw StateError('Cannot add file to null or empty fileset');
    }
    return await _fileSet.addFile(_filesetId!, fileName, content);
  }

  /// Retrieves the content of a file by its ID.
  /// 
  /// Returns null if the file is not found.
  Future<Uint8List?> getFileContent(String fileId) async {
    return await _fileSet.getFileContent(fileId);
  }

  /// Gets metadata for a specific file by its ID.
  /// 
  /// Returns the file metadata record from the __files table,
  /// or null if the file is not found.
  Future<Map<String, dynamic>?> getFileMetadata(String fileId) async {
    final fileRecords = await _database.queryTable(
      '__files',
      where: 'id = ?',
      whereArgs: [fileId],
    );
    
    if (fileRecords.isEmpty) {
      return null;
    }
    
    return fileRecords.first;
  }

  /// Deletes a file from this fileset.
  /// 
  /// [fileId] is the ID of the file to delete.
  Future<void> deleteFile(String fileId) async {
    await _fileSet.deleteFile(fileId);
  }

  /// Gets all files in this fileset.
  /// 
  /// Returns a list of file metadata maps from the __files table.
  /// Returns an empty list if this fileset field has no value.
  Future<List<Map<String, dynamic>>> getFiles() async {
    if (!hasValue) {
      return [];
    }
    return await _fileSet.getFilesInFileset(_filesetId!);
  }

  /// Gets the count of files in this fileset.
  /// 
  /// Returns 0 if this fileset field has no value.
  Future<int> getFileCount() async {
    if (!hasValue) {
      return 0;
    }
    return await _fileSet.getFileCountInFileset(_filesetId!);
  }

  /// Returns the database value for this fileset field.
  /// 
  /// This is used when converting back to a map for database storage.
  String? toDatabaseValue() => _filesetId;

  @override
  String toString() {
    return 'FilesetField(filesetId: $_filesetId, hasValue: $hasValue)';
  }

  @override
  bool operator ==(Object other) {
    if (identical(this, other)) return true;
    return other is FilesetField && other._filesetId == _filesetId;
  }

  @override
  int get hashCode => _filesetId.hashCode;
}
<!-- END FILE: declarative_sqlite/lib/src/files/fileset_field.dart -->

<!-- BEGIN FILE: declarative_sqlite/lib/src/files/filesystem_file_repository.dart -->
import 'dart:async';
import 'dart:io';
import 'package:path/path.dart' as p;
import 'package:declarative_sqlite/src/files/file_repository.dart';

/// A default implementation of [IFileRepository] that stores files on the
/// local filesystem.
class FilesystemFileRepository implements IFileRepository {
  final String _storagePath;

  /// Creates a new [FilesystemFileRepository].
  ///
  /// [_storagePath] is the root directory where files will be stored.
  FilesystemFileRepository(this._storagePath);

  String _getFolderPath(String filesetId) => p.join(_storagePath, filesetId);
  String _getFilePath(String filesetId, String fileId) =>
      p.join(_getFolderPath(filesetId), fileId);

  @override
  Future<String> addFile(
    String filesetId,
    String fileId,
    Stream<List<int>> content,
  ) async {
    final folderPath = _getFolderPath(filesetId);
    await Directory(folderPath).create(recursive: true);

    final filePath = _getFilePath(filesetId, fileId);
    final file = File(filePath);

    final sink = file.openWrite();
    await content.pipe(sink);
    await sink.close();

    return filePath;
  }

  @override
  Future<void> removeFile(String filesetId, String fileId) async {
    final filePath = _getFilePath(filesetId, fileId);
    final file = File(filePath);
    if (await file.exists()) {
      await file.delete();
    }
  }

  @override
  Future<Stream<List<int>>> getFileContent(
      String filesetId, String fileId) async {
    final filePath = _getFilePath(filesetId, fileId);
    final file = File(filePath);
    if (!await file.exists()) {
      throw Exception('File not found at path: $filePath');
    }
    return file.openRead();
  }

  @override
  Future<int> garbageCollectFilesets(List<String> validFilesetIds) async {
    final storageDir = Directory(_storagePath);
    if (!await storageDir.exists()) {
      return 0; // Nothing to clean up
    }

    final validFilesetSet = validFilesetIds.toSet();
    int removedCount = 0;

    await for (final entity in storageDir.list()) {
      if (entity is Directory) {
        final filesetId = p.basename(entity.path);
        
        // Skip if this fileset ID is valid
        if (validFilesetSet.contains(filesetId)) {
          continue;
        }

        // This is an orphaned fileset directory, remove it
        try {
          await entity.delete(recursive: true);
          removedCount++;
        } catch (e) {
          // Log error but continue with cleanup
          print('Warning: Failed to delete orphaned fileset directory ${entity.path}: $e');
        }
      }
    }

    return removedCount;
  }

  @override
  Future<int> garbageCollectFiles(String filesetId, List<String> validFileIds) async {
    final filesetDir = Directory(_getFolderPath(filesetId));
    if (!await filesetDir.exists()) {
      return 0; // Fileset directory doesn't exist
    }

    final validFileSet = validFileIds.toSet();
    int removedCount = 0;

    await for (final entity in filesetDir.list()) {
      if (entity is File) {
        final fileId = p.basename(entity.path);
        
        // Skip if this file ID is valid
        if (validFileSet.contains(fileId)) {
          continue;
        }

        // This is an orphaned file, remove it
        try {
          await entity.delete();
          removedCount++;
        } catch (e) {
          // Log error but continue with cleanup
          print('Warning: Failed to delete orphaned file ${entity.path}: $e');
        }
      }
    }

    return removedCount;
  }
}

<!-- END FILE: declarative_sqlite/lib/src/files/filesystem_file_repository.dart -->

<!-- BEGIN FILE: declarative_sqlite/lib/src/migration/diff_schemas.dart -->
import 'package:collection/collection.dart';
import 'package:declarative_sqlite/src/migration/schema_diff.dart';
import 'package:declarative_sqlite/src/schema/live_schema.dart';
import 'package:declarative_sqlite/src/schema/table.dart';
import 'package:declarative_sqlite/src/schema/schema.dart';

List<SchemaChange> diffSchemas(
    Schema declarativeSchema, LiveSchema liveSchema) {
  final changes = <SchemaChange>[];

  final declarativeTables = declarativeSchema.tables;
  final liveTables = liveSchema.tables;

  // Compare tables
  for (final declarativeTable in declarativeTables) {
    final liveTable =
        liveTables.firstWhereOrNull((t) => t.name == declarativeTable.name);
    if (liveTable == null) {
      changes.add(CreateTable(declarativeTable));
    } else {
      final columnChanges = _diffColumns(declarativeTable, liveTable);
      final keyChanges = _diffKeys(declarativeTable, liveTable);
      if (columnChanges.isNotEmpty || keyChanges.isNotEmpty) {
        changes.add(
            AlterTable(liveTable, declarativeTable, columnChanges, keyChanges));
      }
    }
  }

  for (final liveTable in liveTables) {
    if (!declarativeTables.any((t) => t.name == liveTable.name)) {
      changes.add(DropTable(liveTable));
    }
  }

  // Compare views
  final declarativeViews = declarativeSchema.views;
  final liveViews = liveSchema.views;

  for (final declarativeView in declarativeViews) {
    final liveView =
        liveViews.firstWhereOrNull((v) => v.name == declarativeView.name);
    if (liveView == null) {
      changes.add(CreateView(declarativeView));
    } else if (liveView.sql != declarativeView.definition) {
      changes.add(AlterView(liveView, declarativeView));
    }
  }

  for (final liveView in liveViews) {
    if (!declarativeViews.any((v) => v.name == liveView.name)) {
      changes.add(DropView(liveView));
    }
  }

  return changes;
}

List<ColumnChange> _diffColumns(Table declarativeTable, LiveTable liveTable) {
  final changes = <ColumnChange>[];
  final declarativeColumns = declarativeTable.columns;
  final liveColumns = liveTable.columns;

  for (final declarativeColumn in declarativeColumns) {
    final liveColumn =
        liveColumns.firstWhereOrNull((c) => c.name == declarativeColumn.name);
    if (liveColumn == null) {
      changes.add(AddColumn(declarativeColumn));
    } else {
      // A simple diff for demonstration. A real implementation would be more robust.
      if (liveColumn.type.toUpperCase() !=
              declarativeColumn.type.toUpperCase() ||
          liveColumn.isNotNull != declarativeColumn.isNotNull) {
        changes.add(AlterColumn(liveColumn, declarativeColumn));
      }
    }
  }

  for (final liveColumn in liveColumns) {
    if (!declarativeColumns.any((c) => c.name == liveColumn.name)) {
      changes.add(DropColumn(liveColumn));
    }
  }

  return changes;
}

List<KeyChange> _diffKeys(Table declarativeTable, LiveTable liveTable) {
  final changes = <KeyChange>[];
  final declarativeKeys = declarativeTable.keys;
  final liveKeys = liveTable.keys;

  for (final declarativeKey in declarativeKeys) {
    final liveKey = liveKeys.firstWhereOrNull(
        (k) => const ListEquality().equals(k.columns, declarativeKey.columns));
    if (liveKey == null) {
      changes.add(AddKey(declarativeKey));
    }
  }

  for (final liveKey in liveKeys) {
    if (!declarativeKeys
        .any((k) => const ListEquality().equals(k.columns, liveKey.columns))) {
      changes.add(DropKey(liveKey));
    }
  }

  return changes;
}


<!-- END FILE: declarative_sqlite/lib/src/migration/diff_schemas.dart -->

<!-- BEGIN FILE: declarative_sqlite/lib/src/migration/generate_migration_scripts.dart -->
import 'dart:convert';

import 'package:collection/collection.dart';
import 'package:crypto/crypto.dart';
import 'package:declarative_sqlite/src/migration/schema_diff.dart';
import 'package:declarative_sqlite/src/schema/key.dart';

List<String> generateMigrationScripts(List<SchemaChange> changes) {
  final scripts = <String>[];
  for (final change in changes) {
    if (change is CreateTable) {
      scripts.addAll(_generateCreateTableScripts(change));
    } else if (change is DropTable) {
      scripts.add('DROP TABLE ${change.table.name};');
    } else if (change is AlterTable) {
      scripts.addAll(_generateAlterTableScripts(change));
    } else if (change is CreateView) {
      scripts
          .add('CREATE VIEW ${change.view.name} AS ${change.view.definition};');
    } else if (change is DropView) {
      scripts.add('DROP VIEW ${change.view.name};');
    } else if (change is AlterView) {
      scripts.add('DROP VIEW ${change.liveView.name};');
      scripts.add(
          'CREATE VIEW ${change.targetView.name} AS ${change.targetView.definition};');
    }
  }
  return scripts;
}

String _generateCreateTableScript(CreateTable change) {
  final table = change.table;
  final columns = table.columns.map((c)=>c.toSql()).join(', ');
  final primaryKeys = table.keys
      .where((k) => k.type == KeyType.primary)
      .map((k) => 'PRIMARY KEY (${k.columns.join(', ')})')
      .join(', ');

  final parts = [
    columns,
    if (primaryKeys.isNotEmpty) primaryKeys,
  ];
  return 'CREATE TABLE ${table.name} (${parts.where((p) => p.isNotEmpty).join(', ')});';
}

List<String> _generateCreateTableScripts(CreateTable change) {
  final scripts = <String>[];
  final table = change.table;
  scripts.add(_generateCreateTableScript(change));

  final indexKeys = table.keys.where((k) => k.type == KeyType.indexed);
  for (final key in indexKeys) {
    var indexName = 'idx_${table.name}_${key.columns.join('_')}';
    if (indexName.length > 62) {
      final hash =
          sha1.convert(utf8.encode(indexName)).toString().substring(0, 10);
      indexName = 'idx_${table.name}_$hash';
    }
    scripts.add(
        'CREATE INDEX $indexName ON ${table.name} (${key.columns.join(', ')});');
  }
  return scripts;
}

List<String> _generateAlterTableScripts(AlterTable change) {
  final scripts = <String>[];
  final addColumnChanges = change.columnChanges.whereType<AddColumn>().toList();
  final dropColumnChanges =
      change.columnChanges.whereType<DropColumn>().toList();
  final alterColumnChanges =
      change.columnChanges.whereType<AlterColumn>().toList();
  final keyChanges = change.keyChanges;

  if (dropColumnChanges.isNotEmpty ||
      alterColumnChanges.isNotEmpty ||
      keyChanges.isNotEmpty) {
    // Recreate table if columns are dropped or altered, or if keys/references change
    final newTable = change.targetTable;
    final oldTable = change.liveTable;
    final tempTableName = 'old_${oldTable.name}';
    final keptColumns = newTable.columns.map((c) => c.name).toList();

    // 1. Rename old table
    scripts.add('ALTER TABLE ${oldTable.name} RENAME TO $tempTableName;');

    // 2. Create new table with original name
    scripts.addAll(_generateCreateTableScripts(CreateTable(newTable)));

    final selectColumns = newTable.columns.map((newCol) {
      final oldCol =
          oldTable.columns.firstWhereOrNull((c) => c.name == newCol.name);
      if (oldCol == null) {
        if (newCol.isNotNull) {
          final defaultValue = newCol.defaultValue;
          if (defaultValue != null) {
            final value =
                defaultValue is String ? "'$defaultValue'" : defaultValue;
            return '$value AS ${newCol.name}';
          }
        }
      } else {
        // The column exists in the old table, so we can select it.
        // We need to handle the case where a column is now NOT NULL,
        // but was previously nullable.
        if (newCol.isNotNull && !oldCol.isNotNull) {
          final defaultValue = newCol.defaultValue;
          final value =
              defaultValue is String ? "'$defaultValue'" : defaultValue;
          return 'IFNULL(${newCol.name}, $value) AS ${newCol.name}';
        }
      }
      return newCol.name;
    }).join(', ');

    // 3. Copy data from old table to new table
    scripts.add(
        'INSERT INTO ${newTable.name} (${keptColumns.join(', ')}) SELECT $selectColumns FROM $tempTableName;');

    // 4. Drop old table
    scripts.add('DROP TABLE $tempTableName;');
  } else {
    // Only handle adding columns if no columns are dropped, altered, or keys/references change
    for (final columnChange in addColumnChanges) {
      final columnDef = columnChange.column.toSql();
      scripts
          .add('ALTER TABLE ${change.liveTable.name} ADD COLUMN $columnDef;');
    }
  }

  // NOTE: This implementation assumes that if any column is dropped or altered,
  // the table is recreated. If columns are only added, it uses ALTER TABLE ADD
  // COLUMN.
  return scripts;
}

<!-- END FILE: declarative_sqlite/lib/src/migration/generate_migration_scripts.dart -->

<!-- BEGIN FILE: declarative_sqlite/lib/src/migration/introspect_schema.dart -->
import 'package:sqflite_common/sqflite.dart' as sqflite;
import 'package:declarative_sqlite/src/schema/live_schema.dart';

Future<LiveSchema> introspectSchema(sqflite.Database db) async {
  final tables = await _introspectTables(db);
  final views = await _introspectViews(db);
  return LiveSchema(tables: tables, views: views);
}

Future<List<LiveTable>> _introspectTables(sqflite.Database db) async {
  final tables = <LiveTable>[];
  final tableRows = await db.rawQuery(
      "SELECT name FROM sqlite_master WHERE type='table' AND name NOT LIKE 'sqlite\\_%' ESCAPE '\\' AND name NOT LIKE 'android\\_metadata' ESCAPE '\\'");
  for (final tableRow in tableRows) {
    final tableName = tableRow['name'] as String;
    final columns = await _introspectColumns(db, tableName);
    final keys = await _introspectKeys(db, tableName);
    tables.add(LiveTable(
      name: tableName,
      columns: columns,
      keys: keys,
    ));
  }
  return tables;
}

Future<List<LiveView>> _introspectViews(sqflite.Database db) async {
  final views = <LiveView>[];
  final viewRows = await db
      .rawQuery("SELECT name, sql FROM sqlite_master WHERE type='view'");
  for (final viewRow in viewRows) {
    views.add(LiveView(
      name: viewRow['name'] as String,
      sql: viewRow['sql'] as String,
    ));
  }
  return views;
}

Future<List<LiveColumn>> _introspectColumns(
    sqflite.Database db, String tableName) async {
  final columns = <LiveColumn>[];
  final columnRows = await db.rawQuery('PRAGMA table_info($tableName)');
  for (final columnRow in columnRows) {
    columns.add(LiveColumn(
      name: columnRow['name'] as String,
      type: columnRow['type'] as String,
      isNotNull: (columnRow['notnull'] as int) == 1,
      isPrimaryKey: (columnRow['pk'] as int) >= 1,
      defaultValue: columnRow['dflt_value'] as String?,
    ));
  }
  return columns;
}

Future<List<LiveKey>> _introspectKeys(
    sqflite.Database db, String tableName) async {
  final keys = <LiveKey>[];
  final indexList = await db.rawQuery('PRAGMA index_list($tableName)');
  for (final indexRow in indexList) {
    final indexName = indexRow['name'] as String;
    final isUnique = (indexRow['unique'] as int) == 1;
    final indexInfo = await db.rawQuery('PRAGMA index_info($indexName)');
    final columns = indexInfo.map((row) => row['name'] as String).toList();
    keys.add(LiveKey(name: indexName, columns: columns, isUnique: isUnique));
  }
  return keys;
}

<!-- END FILE: declarative_sqlite/lib/src/migration/introspect_schema.dart -->

<!-- BEGIN FILE: declarative_sqlite/lib/src/migration/schema_diff.dart -->
import 'package:declarative_sqlite/src/schema/column.dart';
import 'package:declarative_sqlite/src/schema/key.dart';
import 'package:declarative_sqlite/src/schema/live_schema.dart';
import 'package:declarative_sqlite/src/schema/table.dart';
import 'package:declarative_sqlite/src/schema/view.dart';

abstract class SchemaChange {}

// Table changes
class CreateTable extends SchemaChange {
  final Table table;
  CreateTable(this.table);
}

class DropTable extends SchemaChange {
  final LiveTable table;
  DropTable(this.table);
}

class AlterTable extends SchemaChange {
  final LiveTable liveTable;
  final Table targetTable;
  final List<ColumnChange> columnChanges;
  final List<KeyChange> keyChanges;
  AlterTable(
      this.liveTable, this.targetTable, this.columnChanges, this.keyChanges);
}

// Column changes
abstract class ColumnChange {}

class AddColumn extends ColumnChange {
  final Column column;
  AddColumn(this.column);
}

class DropColumn extends ColumnChange {
  final LiveColumn column;
  DropColumn(this.column);
}

class AlterColumn extends ColumnChange {
  final LiveColumn liveColumn;
  final Column targetColumn;
  AlterColumn(this.liveColumn, this.targetColumn);
}

// Key changes
abstract class KeyChange {}

class AddKey extends KeyChange {
  final Key key;
  AddKey(this.key);
}

class DropKey extends KeyChange {
  final LiveKey key;
  DropKey(this.key);
}

// View changes
abstract class ViewChange extends SchemaChange {}

class CreateView extends ViewChange {
  final View view;
  CreateView(this.view);
}

class AlterView extends ViewChange {
  final LiveView liveView;
  final View targetView;
  AlterView(this.liveView, this.targetView);
}

class DropView extends ViewChange {
  final LiveView view;
  DropView(this.view);
}
<!-- END FILE: declarative_sqlite/lib/src/migration/schema_diff.dart -->

<!-- BEGIN FILE: declarative_sqlite/lib/src/record.dart -->
import 'package:collection/collection.dart';
import 'package:declarative_sqlite/src/database.dart';
import 'package:declarative_sqlite/src/files/fileset_field.dart';
import 'package:declarative_sqlite/src/schema/column.dart';
import 'package:declarative_sqlite/src/schema/table.dart';
import 'package:declarative_sqlite/src/sync/hlc.dart';

/// Base class for typed database records.
/// 
/// Provides typed getters and setters with automatic conversion between
/// database values and Dart types, including special handling for:
/// - DateTime serialization/deserialization
/// - FilesetField conversion
/// - LWW (Last-Write-Wins) column updates
/// - Automatic dirty tracking for updates
/// - Read-only vs CRUD differentiation
abstract class DbRecord {
  final Map<String, Object?> _data;
  final String _tableName;
  final DeclarativeDatabase _database;
  final Table? _tableDefinition;
  final String? _updateTableName; // Table to target for CRUD operations
  final bool _isReadOnly;
  
  /// Map to track which fields have been modified since creation
  final Set<String> _modifiedFields = <String>{};
  
  /// Creates a DbRecord from a table (CRUD-enabled by default)
  DbRecord.fromTable(this._data, this._tableName, this._database) 
      : _tableDefinition = _database.schema.userTables.firstWhere(
          (table) => table.name == _tableName,
          orElse: () => throw ArgumentError('Table $_tableName not found in schema'),
        ),
        _updateTableName = _tableName,
        _isReadOnly = false;

  /// Creates a DbRecord from a view or query (read-only by default)
  DbRecord.fromQuery(this._data, this._tableName, this._database, {String? updateTable}) 
      : _tableDefinition = updateTable != null 
          ? _database.schema.userTables.firstWhere(
              (table) => table.name == updateTable,
              orElse: () => throw ArgumentError('Update table $updateTable not found in schema'),
            )
          : null,
        _updateTableName = updateTable,
        _isReadOnly = updateTable == null;

  /// Creates a generic DbRecord (for backward compatibility)
  DbRecord(this._data, this._tableName, this._database)
      : _tableDefinition = _database.schema.userTables
            .firstWhereOrNull((table) => table.name == _tableName),
        _updateTableName = _tableName,
        _isReadOnly = !_database.schema.userTables
            .any((table) => table.name == _tableName);

  /// Gets the table name for this record
  String get tableName => _tableName;

  /// Gets the table name that will be used for CRUD operations
  String? get updateTableName => _updateTableName;

  /// Whether this record is read-only (cannot be updated/deleted)
  bool get isReadOnly => _isReadOnly;

  /// Whether this record supports CRUD operations
  bool get isCrudEnabled => !_isReadOnly && _updateTableName != null;

  /// Gets the underlying data map (read-only copy)
  Map<String, Object?> get data => Map.unmodifiable(_data);

  /// Gets the set of fields that have been modified (read-only copy)
  Set<String> get modifiedFields => Set.unmodifiable(_modifiedFields);

  /// Gets the system_id for this record
  String? get systemId => getRawValue('system_id') as String?;

  /// Gets the system_created_at timestamp for this record
  DateTime? get systemCreatedAt {
    final value = getRawValue('system_created_at');
    return value != null ? _parseDateTime(value) : null;
  }

  /// Gets the system_version HLC for this record
  Hlc? get systemVersion {
    final value = getRawValue('system_version');
    return value != null ? Hlc.parse(value as String) : null;
  }

  /// Gets a raw value from the data map without type conversion
  Object? getRawValue(String columnName) {
    return _data[columnName];
  }

  /// Gets a typed value with automatic conversion based on column definition
  T? getValue<T>(String columnName) {
    final rawValue = _data[columnName];
    if (rawValue == null) return null;

    final column = _getColumn(columnName);
    if (column == null) {
      // Fallback for views or complex queries without schema info
      if (T == DateTime) {
        return _parseDateTime(rawValue) as T?;
      }
      if (T == FilesetField) {
        return _parseFilesetField(rawValue) as T?;
      }
      return rawValue as T?;
    }

    switch (column.logicalType) {
      case 'text':
      case 'guid':
        return rawValue as T;
      case 'integer':
        return rawValue as T;
      case 'real':
        return rawValue as T;
      case 'date':
        return _parseDateTime(rawValue) as T;
      case 'fileset':
        return _parseFilesetField(rawValue) as T;
      default:
        return rawValue as T;
    }
  }

  /// Sets a value with automatic conversion and LWW handling
  /// Throws StateError if the record is read-only
  void setValue<T>(String columnName, T? value) {
    if (_isReadOnly) {
      throw StateError('Cannot modify read-only record from $_tableName');
    }

    // Validate that the column exists in the update table schema
    if (_tableDefinition != null) {
      final column = _getColumn(columnName);
      if (column == null) {
        throw ArgumentError('Column $columnName does not exist in update table $_updateTableName');
      }
    }

    final column = _getColumn(columnName);
    Object? databaseValue;
    
    switch (column?.logicalType ?? 'unknown') {
      case 'text':
      case 'guid':
      case 'integer':
      case 'real':
        databaseValue = value;
        break;
      case 'date':
        databaseValue = value != null ? _serializeDateTime(value as DateTime) : null;
        break;
      case 'fileset':
        databaseValue = value != null ? (value as FilesetField).toDatabaseValue() : null;
        break;
      default:
        databaseValue = value;
    }

    _data[columnName] = databaseValue;
    _modifiedFields.add(columnName);

    // Handle LWW column HLC updates
    if (column?.isLww == true) {
      final hlcColumnName = '${columnName}__hlc';
      final currentHlc = _database.hlcClock.now();
      _data[hlcColumnName] = currentHlc.toString();
      _modifiedFields.add(hlcColumnName);
    }
  }

  // Typed helper methods for generated code

  /// Gets a String value from the specified column.
  /// Returns null if the column value is null.
  String? getText(String columnName) => getValue<String>(columnName);

  /// Gets a non-null String value from the specified column.
  /// Throws if the column value is null.
  String getTextNotNull(String columnName) {
    final value = getText(columnName);
    if (value == null) {
      throw StateError('Column $columnName is null but expected to be non-null');
    }
    return value;
  }

  /// Gets an int value from the specified column.
  /// Returns null if the column value is null.
  int? getInteger(String columnName) => getValue<int>(columnName);

  /// Gets a non-null int value from the specified column.
  /// Throws if the column value is null.
  int getIntegerNotNull(String columnName) {
    final value = getInteger(columnName);
    if (value == null) {
      throw StateError('Column $columnName is null but expected to be non-null');
    }
    return value;
  }

  /// Gets a double value from the specified column.
  /// Returns null if the column value is null.
  double? getReal(String columnName) => getValue<double>(columnName);

  /// Gets a non-null double value from the specified column.
  /// Throws if the column value is null.
  double getRealNotNull(String columnName) {
    final value = getReal(columnName);
    if (value == null) {
      throw StateError('Column $columnName is null but expected to be non-null');
    }
    return value;
  }

  /// Gets a DateTime value from the specified column.
  /// Returns null if the column value is null.
  DateTime? getDateTime(String columnName) => getValue<DateTime>(columnName);

  /// Gets a non-null DateTime value from the specified column.
  /// Throws if the column value is null.
  DateTime getDateTimeNotNull(String columnName) {
    final value = getDateTime(columnName);
    if (value == null) {
      throw StateError('Column $columnName is null but expected to be non-null');
    }
    return value;
  }

  /// Gets a FilesetField value from the specified column.
  /// Returns null if the column value is null.
  FilesetField? getFilesetField(String columnName) => getValue<FilesetField>(columnName);

  /// Gets a non-null FilesetField value from the specified column.
  /// Throws if the column value is null.
  FilesetField getFilesetFieldNotNull(String columnName) {
    final value = getFilesetField(columnName);
    if (value == null) {
      throw StateError('Column $columnName is null but expected to be non-null');
    }
    return value;
  }

  // Typed setter methods for generated code

  /// Sets a String value for the specified column.
  void setText(String columnName, String? value) => setValue(columnName, value);

  /// Sets an int value for the specified column.
  void setInteger(String columnName, int? value) => setValue(columnName, value);

  /// Sets a double value for the specified column.
  void setReal(String columnName, double? value) => setValue(columnName, value);

  /// Sets a DateTime value for the specified column.
  void setDateTime(String columnName, DateTime? value) => setValue(columnName, value);

  /// Sets a FilesetField value for the specified column.
  void setFilesetField(String columnName, FilesetField? value) => setValue(columnName, value);

  /// Saves any modified fields back to the database
  /// Throws StateError if the record is read-only
  Future<void> save() async {
    if (_isReadOnly) {
      throw StateError('Cannot save read-only record from $_tableName');
    }

    if (_modifiedFields.isEmpty) return;

    final systemId = this.systemId;
    if (systemId == null) {
      throw StateError('Cannot save record without system_id');
    }

    final systemVersion = this.systemVersion;
    if (systemVersion == null) {
      throw StateError('Cannot save record without system_version');
    }

    // Build update map with only modified fields (excluding system columns)
    final updateData = <String, Object?>{};
    for (final fieldName in _modifiedFields) {
      // Skip system columns - they're managed by the database layer
      if (!fieldName.startsWith('system_')) {
        updateData[fieldName] = _data[fieldName];
      }
    }

    if (updateData.isNotEmpty) {
      await _database.update(
        _updateTableName ?? _tableName,
        updateData,
        where: 'system_id = ?',
        whereArgs: [systemId],
      );
    }

    // Clear modified fields after successful save
    _modifiedFields.clear();
  }

  /// Creates a new record in the database with the current data
  /// Throws StateError if the record is read-only
  Future<void> insert() async {
    if (_isReadOnly) {
      throw StateError('Cannot insert read-only record from $_tableName');
    }

    // Remove system columns - they'll be added by the database layer
    final insertData = Map<String, Object?>.from(_data);
    insertData.removeWhere((key, value) => key.startsWith('system_'));

    await _database.insert(_updateTableName ?? _tableName, insertData);
    
    // Clear modified fields since this is a new record
    _modifiedFields.clear();
  }

  /// Deletes this record from the database
  /// Throws StateError if the record is read-only
  Future<void> delete() async {
    if (_isReadOnly) {
      throw StateError('Cannot delete read-only record from $_tableName');
    }

    final systemId = this.systemId;
    if (systemId == null) {
      throw StateError('Cannot delete record without system_id');
    }

    await _database.delete(
      _updateTableName ?? _tableName,
      where: 'system_id = ?',
      whereArgs: [systemId],
    );
  }

  /// Reloads this record from the database
  /// Only available for CRUD-enabled records as views cannot guarantee uniqueness
  Future<void> reload() async {
    if (_isReadOnly) {
      throw StateError('Cannot reload read-only record from $_tableName');
    }

    final systemId = this.systemId;
    if (systemId == null) {
      throw StateError('Cannot reload record without system_id');
    }

    final results = await _database.queryTable(
      _updateTableName ?? _tableName,
      where: 'system_id = ?',
      whereArgs: [systemId],
    );

    if (results.isEmpty) {
      throw StateError('Record with system_id $systemId not found in table ${_updateTableName ?? _tableName}');
    }

    // Update the data map with fresh data
    _data.clear();
    _data.addAll(results.first);
    
    // Clear modified fields since we have fresh data
    _modifiedFields.clear();
  }

  /// Gets the column definition for the specified column name
  Column? _getColumn(String columnName) {
    return _tableDefinition?.columns.firstWhereOrNull(
      (col) => col.name == columnName,
    );
  }

  /// Parses a database value into a DateTime
  DateTime _parseDateTime(Object? value) {
    if (value == null) throw ArgumentError('Cannot parse null as DateTime');
    if (value is DateTime) return value;
    if (value is String) return DateTime.parse(value);
    if (value is int) return DateTime.fromMillisecondsSinceEpoch(value);
    throw ArgumentError('Cannot parse $value as DateTime');
  }

  /// Serializes a DateTime for database storage
  String _serializeDateTime(DateTime dateTime) {
    return dateTime.toIso8601String();
  }

  /// Parses a database value into a FilesetField
  FilesetField? _parseFilesetField(Object? value) {
    if (value == null) return null;
    return FilesetField.fromDatabaseValue(value, _database);
  }

  @override
  String toString() {
    return '$runtimeType($_tableName: $_data)';
  }

  @override
  bool operator ==(Object other) {
    if (identical(this, other)) return true;
    return other is DbRecord &&
        other._tableName == _tableName &&
        other._data.toString() == _data.toString();
  }

  @override
  int get hashCode => _tableName.hashCode ^ _data.toString().hashCode;

  Object? operator [](String key) {
    return data[key];
  }
}
<!-- END FILE: declarative_sqlite/lib/src/record.dart -->

<!-- BEGIN FILE: declarative_sqlite/lib/src/record_factory.dart -->
import 'package:declarative_sqlite/src/database.dart';
import 'package:declarative_sqlite/src/record.dart';

/// Factory for creating DbRecord instances from database query results.
class RecordFactory {
  static DbRecord fromMap(
    Map<String, Object?> data,
    String tableName,
    DeclarativeDatabase database, {
    String? updateTable,
  }) {
    return _GenericRecord(data, tableName, database, updateTable: updateTable);
  }

  /// Creates a DbRecord from a table query (CRUD-enabled by default)
  static DbRecord fromTable(
    Map<String, Object?> data,
    String tableName,
    DeclarativeDatabase database,
  ) {
    return _GenericRecord.fromTable(data, tableName, database);
  }

  /// Creates a DbRecord from a view or complex query (read-only by default)
  static DbRecord fromQuery(
    Map<String, Object?> data,
    String tableName,
    DeclarativeDatabase database, {
    String? updateTable,
  }) {
    return _GenericRecord.fromQuery(data, tableName, database, updateTable: updateTable);
  }

  /// Creates a list of records from query results
  static List<DbRecord> fromMapList(
    List<Map<String, Object?>> dataList,
    String tableName,
    DeclarativeDatabase database, {
    String? updateTable,
  }) {
    return dataList
        .map((data) => fromMap(data, tableName, database, updateTable: updateTable))
        .toList();
  }
}

/// Generic implementation of DbRecord for any table
class _GenericRecord extends DbRecord {
  _GenericRecord(
    super.data,
    super.tableName,
    super.database, {
    super.updateTable,
  }) : super.fromQuery();

  _GenericRecord.fromTable(
    super.data,
    super.tableName,
    super.database,
  ) : super.fromTable();

  _GenericRecord.fromQuery(
    super.data,
    super.tableName,
    super.database, {
    super.updateTable,
  }) : super.fromQuery();

  /// Provides dynamic property access via noSuchMethod
  @override
  dynamic noSuchMethod(Invocation invocation) {
    final name = invocation.memberName.toString();
    
    // Handle getters (property access)
    if (invocation.isGetter) {
      // Remove 'Symbol("' and '")' from the symbol name
      final propertyName = name.substring(8, name.length - 2);
      
      // Handle special getters
      if (propertyName == 'tableName') return tableName;
      if (propertyName == 'data') return data;
      if (propertyName == 'modifiedFields') return modifiedFields;
      if (propertyName == 'systemId') return systemId;
      if (propertyName == 'systemCreatedAt') return systemCreatedAt;
      if (propertyName == 'systemVersion') return systemVersion;
      if (propertyName == 'isReadOnly') return isReadOnly;
      if (propertyName == 'isCrudEnabled') return isCrudEnabled;
      if (propertyName == 'updateTableName') return updateTableName;
      
      // Handle regular column getters
      return getValue(propertyName);
    }
    
    // Handle setters (property assignment)
    if (invocation.isSetter) {
      // Remove 'Symbol("' and '=")' from the symbol name
      final propertyName = name.substring(8, name.length - 3);
      final value = invocation.positionalArguments.first;
      
      setValue(propertyName, value);
      return;
    }
    
    // Handle method calls
    if (invocation.isMethod) {
      final methodName = name.substring(8, name.length - 2);
      
      switch (methodName) {
        case 'save':
          return save();
        case 'insert':
          return insert();
        case 'delete':
          return delete();
        case 'reload':
          return reload();
        case 'toString':
          return toString();
        default:
          return super.noSuchMethod(invocation);
      }
    }
    
    return super.noSuchMethod(invocation);
  }
}
<!-- END FILE: declarative_sqlite/lib/src/record_factory.dart -->

<!-- BEGIN FILE: declarative_sqlite/lib/src/record_map_factory_registry.dart -->
import 'package:declarative_sqlite/src/database.dart';
import 'package:declarative_sqlite/src/record.dart';

typedef RecordFactoryFunction<T extends DbRecord> = T Function(
    Map<String, Object?> data, DeclarativeDatabase database);

/// Registry for typed record factory functions.
///
/// This allows registering fromMap factory functions for specific record types
/// and looking them up by Type, eliminating the need for mapper parameters
/// in query methods.
class RecordMapFactoryRegistry {
  static final Map<Type, RecordFactoryFunction<DbRecord>> _factories = {};

  /// Registers a fromMap factory for the given record type.
  ///
  /// Example:
  /// ```dart
  /// RecordMapFactoryRegistry.register<User>(User.fromMap);
  /// ```
  static void register<T extends DbRecord>(
      T Function(Map<String, Object?> data, DeclarativeDatabase database)
          factory) {
    _factories[T] = factory;
  }

  /// Gets the factory for the given record type.
  ///
  /// Throws [ArgumentError] if no factory is registered for the type.
  static RecordFactoryFunction<T> getFactory<T extends DbRecord>() {
    final factory = _factories[T];
    if (factory == null) {
      throw ArgumentError('No factory registered for type $T. '
          'Call RecordMapFactoryRegistry.register<$T>(factory) first.');
    }
    return factory as RecordFactoryFunction<T>;
  }

  /// Checks if a factory is registered for the given type.
  static bool hasFactory<T extends DbRecord>() {
    return _factories.containsKey(T);
  }

  /// Checks if a factory is registered for the given type by Type object.
  static bool hasFactoryForType(Type type) {
    return _factories.containsKey(type);
  }

  /// Gets all registered types.
  static Set<Type> get registeredTypes => Set.unmodifiable(_factories.keys);

  /// Clears all registered factories. Useful for testing.
  static void clear() {
    _factories.clear();
  }

  /// Creates an instance using the registered factory for the given type.
  ///
  /// This is a convenience method that combines getFactory and calling it.
  static T create<T extends DbRecord>(
      Map<String, Object?> data, DeclarativeDatabase database) {
    final factory = getFactory<T>();
    return factory(data, database);
  }
}
<!-- END FILE: declarative_sqlite/lib/src/record_map_factory_registry.dart -->

<!-- BEGIN FILE: declarative_sqlite/lib/src/scheduling/database_maintenance_tasks.dart -->
import 'package:declarative_sqlite/src/scheduling/task_scheduler.dart';
import 'package:declarative_sqlite/src/sync/server_sync_manager.dart';

/// Built-in database maintenance tasks
class DatabaseMaintenanceTasks {
  /// Schedule fileset garbage collection
  static Future<String> scheduleFilesetGarbageCollection({
    required Future<Map<String, int>> Function() garbageCollectTask,
    Duration interval = const Duration(hours: 6),
    TaskPriority priority = TaskPriority.low,
  }) async {
    return TaskScheduler.instance.scheduleRecurringTask(
      name: 'Fileset Garbage Collection',
      task: garbageCollectTask,
      interval: interval,
      priority: priority,
      timeout: const Duration(minutes: 30),
    );
  }
  
  /// Schedule database optimization
  static Future<String> scheduleDatabaseOptimization({
    required Future<void> Function() optimizeTask,
    Duration interval = const Duration(days: 1),
    TaskPriority priority = TaskPriority.low,
  }) async {
    return TaskScheduler.instance.scheduleRecurringTask(
      name: 'Database Optimization',
      task: optimizeTask,
      interval: interval,
      priority: priority,
      timeout: const Duration(minutes: 10),
    );
  }
  
  /// Schedule sync operations using ServerSyncManager
  /// 
  /// This integrates with TaskScheduler instead of using internal timers
  /// for better resource management and fair scheduling.
  static Future<String> scheduleSyncOperation({
    required ServerSyncManager syncManager,
    Duration interval = const Duration(minutes: 15),
    TaskPriority priority = TaskPriority.normal,
  }) async {
    return TaskScheduler.instance.scheduleRecurringTask(
      name: 'Server Synchronization',
      task: () => syncManager.performSync(),
      interval: interval,
      priority: priority,
      timeout: const Duration(minutes: 5),
    );
  }
  
  /// Schedule backup operations
  static Future<String> scheduleBackup({
    required Future<void> Function() backupTask,
    Duration interval = const Duration(hours: 12),
    TaskPriority priority = TaskPriority.normal,
  }) async {
    return TaskScheduler.instance.scheduleRecurringTask(
      name: 'Database Backup',
      task: backupTask,
      interval: interval,
      priority: priority,
      timeout: const Duration(minutes: 15),
    );
  }
  
  /// Schedule cleanup of old records
  static Future<String> scheduleDataCleanup({
    required Future<void> Function() cleanupTask,
    Duration interval = const Duration(days: 7),
    TaskPriority priority = TaskPriority.low,
  }) async {
    return TaskScheduler.instance.scheduleRecurringTask(
      name: 'Data Cleanup',
      task: cleanupTask,
      interval: interval,
      priority: priority,
      timeout: const Duration(minutes: 20),
    );
  }
  
  /// Schedule health checks
  static Future<String> scheduleHealthCheck({
    required Future<void> Function() healthCheckTask,
    Duration interval = const Duration(hours: 1),
    TaskPriority priority = TaskPriority.high,
  }) async {
    return TaskScheduler.instance.scheduleRecurringTask(
      name: 'Database Health Check',
      task: healthCheckTask,
      interval: interval,
      priority: priority,
      timeout: const Duration(minutes: 2),
    );
  }

  /// Schedule comprehensive database maintenance.
  /// 
  /// This is a convenience method that schedules multiple common maintenance
  /// tasks with sensible defaults for intervals and priorities.
  static Future<Map<String, String>> scheduleComprehensiveMaintenance({
    required ServerSyncManager syncManager,
    required Future<Map<String, int>> Function() garbageCollectTask,
    required Future<void> Function() optimizationTask,
    Duration syncInterval = const Duration(minutes: 15),
    Duration garbageCollectionInterval = const Duration(hours: 6),
    Duration optimizationInterval = const Duration(days: 1),
  }) async {
    final taskIds = <String, String>{};

    // Schedule sync operations
    taskIds['sync'] = await scheduleSyncOperation(
      syncManager: syncManager,
      interval: syncInterval,
      priority: TaskPriority.normal,
    );

    // Schedule fileset garbage collection
    taskIds['garbage_collection'] = await scheduleFilesetGarbageCollection(
      garbageCollectTask: garbageCollectTask,
      interval: garbageCollectionInterval,
      priority: TaskPriority.low,
    );

    // Schedule database optimization
    taskIds['optimization'] = await scheduleDatabaseOptimization(
      optimizeTask: optimizationTask,
      interval: optimizationInterval,
      priority: TaskPriority.idle,
    );

    return taskIds;
  }
}

/// Helper for device-specific scheduler configuration
class DeviceOptimizedScheduler {
  /// Initialize scheduler with device-appropriate settings
  static void initialize({bool isResourceConstrained = false}) {
    final config = isResourceConstrained 
      ? TaskSchedulerConfig.resourceConstrained
      : TaskSchedulerConfig.highPerformance;
      
    TaskScheduler.withConfig(config);
    TaskScheduler.instance.start();
  }
  
  /// Auto-detect device capabilities and initialize
  static void autoInitialize() {
    // Simple heuristic - could be enhanced with actual device detection
    final isResourceConstrained = _isResourceConstrainedDevice();
    initialize(isResourceConstrained: isResourceConstrained);
  }
  
  static bool _isResourceConstrainedDevice() {
    // Simple heuristic - in a real implementation you might check:
    // - Available RAM
    // - CPU cores
    // - Platform type (mobile vs desktop)
    // - Battery status
    // For now, assume mobile platforms are more constrained
    try {
      // This is a simplified check - real implementation would be more sophisticated
      return false; // Default to not constrained
    } catch (e) {
      return true; // If we can't determine, assume constrained
    }
  }
}
<!-- END FILE: declarative_sqlite/lib/src/scheduling/database_maintenance_tasks.dart -->

<!-- BEGIN FILE: declarative_sqlite/lib/src/scheduling/task_scheduler.dart -->
import 'dart:async';
import 'dart:collection';
import 'dart:math';
import 'package:declarative_sqlite/declarative_sqlite.dart';
import 'package:pool/pool.dart';
import 'package:meta/meta.dart';

/// Priority levels for scheduled tasks
enum TaskPriority {
  /// Highest priority - critical tasks that should run immediately
  critical(4),
  
  /// High priority - important tasks that should run soon
  high(3),
  
  /// Normal priority - regular tasks (default)
  normal(2),
  
  /// Low priority - background tasks that can be deferred
  low(1),
  
  /// Lowest priority - tasks that only run when system is idle
  idle(0);

  const TaskPriority(this.value);
  final int value;
}

/// Configuration for resource management
class TaskSchedulerConfig {
  /// Maximum number of concurrent tasks
  final int maxConcurrentTasks;
  
  /// Maximum CPU usage percentage (0.0 to 1.0)
  final double maxCpuUsage;
  
  /// Time slice duration for each task in milliseconds
  final int timeSliceMs;
  
  /// Minimum delay between task executions in milliseconds
  final int minTaskDelayMs;
  
  /// Whether to use adaptive scheduling based on system load
  final bool adaptiveScheduling;

  const TaskSchedulerConfig({
    this.maxConcurrentTasks = 2,
    this.maxCpuUsage = 0.7,
    this.timeSliceMs = 100,
    this.minTaskDelayMs = 10,
    this.adaptiveScheduling = true,
  });
  
  /// Default configuration for resource-constrained devices
  static const TaskSchedulerConfig resourceConstrained = TaskSchedulerConfig(
    maxConcurrentTasks: 1,
    maxCpuUsage: 0.5,
    timeSliceMs: 50,
    minTaskDelayMs: 20,
    adaptiveScheduling: true,
  );
  
  /// Default configuration for high-performance devices
  static const TaskSchedulerConfig highPerformance = TaskSchedulerConfig(
    maxConcurrentTasks: 4,
    maxCpuUsage: 0.8,
    timeSliceMs: 200,
    minTaskDelayMs: 5,
    adaptiveScheduling: true,
  );
}

/// Represents a scheduled task
class ScheduledTask {
  final String id;
  final String name;
  final TaskPriority priority;
  final Future<void> Function() task;
  final DateTime? scheduledTime;
  final Duration? interval;
  final int maxRetries;
  final Duration? timeout;
  
  int _retryCount = 0;
  DateTime? _lastExecution;
  bool _isRunning = false;
  
  ScheduledTask({
    required this.id,
    required this.name,
    required this.task,
    this.priority = TaskPriority.normal,
    this.scheduledTime,
    this.interval,
    this.maxRetries = 3,
    this.timeout,
  });
  
  /// Whether this is a recurring task
  bool get isRecurring => interval != null;
  
  /// Whether the task is currently running
  bool get isRunning => _isRunning;
  
  /// Number of retry attempts made
  int get retryCount => _retryCount;
  
  /// When the task was last executed
  DateTime? get lastExecution => _lastExecution;
  
  /// When the task should next run
  DateTime? get nextRunTime {
    if (scheduledTime != null && _lastExecution == null) {
      return scheduledTime;
    }
    if (isRecurring && _lastExecution != null) {
      return _lastExecution!.add(interval!);
    }
    return null;
  }
  
  /// Whether the task is ready to run
  bool get isReady {
    if (_isRunning) return false;
    final nextRun = nextRunTime;
    return nextRun == null || DateTime.now().isAfter(nextRun);
  }
  
  /// Whether the task has exceeded maximum retries
  bool get hasExceededRetries => _retryCount >= maxRetries;
}

/// Task execution result
class TaskExecutionResult {
  final ScheduledTask task;
  final bool success;
  final Duration executionTime;
  final Object? error;
  final StackTrace? stackTrace;
  
  const TaskExecutionResult({
    required this.task,
    required this.success,
    required this.executionTime,
    this.error,
    this.stackTrace,
  });
}

/// Callback for task execution events
typedef TaskExecutionCallback = void Function(TaskExecutionResult result);

/// Fair task scheduler for background operations
class TaskScheduler {
  static TaskScheduler? _instance;
  
  /// Get the singleton instance
  static TaskScheduler get instance {
    _instance ??= TaskScheduler._internal();
    return _instance!;
  }
  
  /// Reset the singleton (for testing)
  static void resetInstance() {
    _instance?._shutdown();
    _instance = null;
  }
  
  final TaskSchedulerConfig _config;
  final Queue<ScheduledTask> _taskQueue = Queue<ScheduledTask>();
  final Map<String, ScheduledTask> _tasks = <String, ScheduledTask>{};
  final Set<String> _runningTasks = <String>{};

  /// Pool for managing concurrent task execution
  late final Pool _concurrencyPool;

  /// Database for storing task execution history
  DeclarativeDatabase? _database;
  
  Timer? _schedulerTimer;
  bool _isRunning = false;
  TaskExecutionCallback? _onTaskComplete;
  
  // Performance monitoring
  int _totalTasksExecuted = 0;
  int _totalTasksFailed = 0;
  Duration _totalExecutionTime = Duration.zero;

  @visibleForTesting
  TaskScheduler.internal([TaskSchedulerConfig? config])
      : _config = config ?? const TaskSchedulerConfig() {
    _concurrencyPool = Pool(_config.maxConcurrentTasks);
  }

  TaskScheduler._internal([TaskSchedulerConfig? config])
      : _config = config ?? const TaskSchedulerConfig() {
    _concurrencyPool = Pool(_config.maxConcurrentTasks);
  }
  
  /// Initialize with custom configuration
  factory TaskScheduler.withConfig(TaskSchedulerConfig config) {
    _instance = TaskScheduler._internal(config);
    return _instance!;
  }
  
  /// Initialize with database for persistent task tracking
  void initializeWithDatabase(DeclarativeDatabase database) {
    _database = database;
    _ensureTaskHistoryTable();
  }
  
  /// Set callback for task completion events
  void setTaskExecutionCallback(TaskExecutionCallback callback) {
    _onTaskComplete = callback;
  }
  
  /// Start the scheduler
  void start() {
    if (_isRunning) return;
    
    _isRunning = true;
    _schedulerTimer = Timer.periodic(
      Duration(milliseconds: _config.timeSliceMs),
      (_) => _processTasks(),
    );
  }
  
  /// Stop the scheduler
  void stop() {
    _isRunning = false;
    _schedulerTimer?.cancel();
    _schedulerTimer = null;
  }
  
  /// Schedule a one-time task
  String scheduleTask({
    required String name,
    required Future<void> Function() task,
    TaskPriority priority = TaskPriority.normal,
    DateTime? runAt,
    int maxRetries = 3,
    Duration? timeout,
  }) {
    final taskId = _generateTaskId();
    final scheduledTask = ScheduledTask(
      id: taskId,
      name: name,
      task: task,
      priority: priority,
      scheduledTime: runAt,
      maxRetries: maxRetries,
      timeout: timeout,
    );
    
    _addTask(scheduledTask);
    return taskId;
  }
  
  /// Schedule a recurring task with persistent tracking
  String scheduleRecurringTask({
    required String name,
    required Future<void> Function() task,
    required Duration interval,
    TaskPriority priority = TaskPriority.normal,
    DateTime? firstRun,
    int maxRetries = 3,
    Duration? timeout,
  }) {
    final taskId = _generateTaskId();

    // Check last run time from database if available
    DateTime? effectiveFirstRun = firstRun;
    if (_database != null && effectiveFirstRun == null) {
      _getNextRunTimeFromHistory(name, interval).then((nextRunTime) {
        final scheduledTask = ScheduledTask(
          id: taskId,
          name: name,
          task: task,
          priority: priority,
          scheduledTime: nextRunTime,
          interval: interval,
          maxRetries: maxRetries,
          timeout: timeout,
        );
        _addTask(scheduledTask);
      });
      return taskId;
    }

    final scheduledTask = ScheduledTask(
      id: taskId,
      name: name,
      task: task,
      priority: priority,
      scheduledTime: firstRun,
      interval: interval,
      maxRetries: maxRetries,
      timeout: timeout,
    );

    _addTask(scheduledTask);
    return taskId;
  }
  
  /// Cancel a scheduled task
  bool cancelTask(String taskId) {
    final task = _tasks.remove(taskId);
    if (task != null) {
      _taskQueue.remove(task);
      return true;
    }
    return false;
  }
  
  /// Get task status
  ScheduledTask? getTask(String taskId) {
    return _tasks[taskId];
  }
  
  /// Get all scheduled tasks
  List<ScheduledTask> getAllTasks() {
    return _tasks.values.toList();
  }
  
  /// Get scheduler statistics
  Map<String, dynamic> getStatistics() {
    return {
      'totalTasksExecuted': _totalTasksExecuted,
      'totalTasksFailed': _totalTasksFailed,
      'averageExecutionTime': _totalTasksExecuted > 0 
        ? _totalExecutionTime.inMilliseconds / _totalTasksExecuted 
        : 0,
      'activeTasks': _taskQueue.length,
      'runningTasks': _runningTasks.length,
      'maxConcurrentTasks': _config.maxConcurrentTasks,
    };
  }
  
  void _addTask(ScheduledTask task) {
    _tasks[task.id] = task;
    _insertTaskByPriority(task);
    
    // Start scheduler if not running
    if (!_isRunning) {
      start();
    }
  }
  
  void _insertTaskByPriority(ScheduledTask task) {
    // Insert task in priority order (higher priority first)
    var inserted = false;
    final queue = _taskQueue.toList();
    _taskQueue.clear();
    
    for (var existingTask in queue) {
      if (!inserted && task.priority.value > existingTask.priority.value) {
        _taskQueue.add(task);
        inserted = true;
      }
      _taskQueue.add(existingTask);
    }
    
    if (!inserted) {
      _taskQueue.add(task);
    }
  }
  
  void _processTasks() {
    if (!_isRunning) return;
    
    // Check if we can run more tasks
    if (_runningTasks.length >= _config.maxConcurrentTasks) {
      return;
    }
    
    // Find next ready task
    final readyTasks = _taskQueue.where((task) => task.isReady).toList();
    if (readyTasks.isEmpty) {
      return;
    }
    
    // Sort by priority and next run time
    readyTasks.sort((a, b) {
      final priorityCompare = b.priority.value.compareTo(a.priority.value);
      if (priorityCompare != 0) return priorityCompare;
      
      final aNext = a.nextRunTime ?? DateTime.now();
      final bNext = b.nextRunTime ?? DateTime.now();
      return aNext.compareTo(bNext);
    });
    
    final task = readyTasks.first;
    _runTask(task);
  }
  
  void _runTask(ScheduledTask task) async {
    if (task._isRunning || _runningTasks.contains(task.id)) {
      return;
    }

    await _concurrencyPool.withResource(() async {
      try {
        task._isRunning = true;
        _runningTasks.add(task.id);
        _taskQueue.remove(task);

        final startTime = DateTime.now();
        bool success = false;
        Object? error;
        StackTrace? stackTrace;

        try {
          // Apply timeout if specified
          if (task.timeout != null) {
            await task.task().timeout(task.timeout!);
          } else {
            await task.task();
          }
          success = true;
        } catch (e, st) {
          error = e;
          stackTrace = st;
          task._retryCount++;
        }

        final executionTime = DateTime.now().difference(startTime);
        task._lastExecution = DateTime.now();
        task._isRunning = false;
        _runningTasks.remove(task.id);

        // Update statistics
        _totalTasksExecuted++;
        _totalExecutionTime += executionTime;
        if (!success) {
          _totalTasksFailed++;
        }

        // Create execution result
        final result = TaskExecutionResult(
          task: task,
          success: success,
          executionTime: executionTime,
          error: error,
          stackTrace: stackTrace,
        );

        // Notify callback
        _onTaskComplete?.call(result);

        // Handle task completion
        if (success) {
          // Reset retry count on success
          task._retryCount = 0;

          // Update task history in database
          if (task.isRecurring) {
            await _updateTaskHistory(task.name);
          }

          // Reschedule if recurring
          if (task.isRecurring) {
            _insertTaskByPriority(task);
          } else {
            // Remove one-time completed task
            _tasks.remove(task.id);
          }
        } else {
          // Handle failure
          if (task.hasExceededRetries) {
            // Remove failed task
            _tasks.remove(task.id);
          } else {
            // Reschedule for retry with exponential backoff
            final delay = Duration(
              milliseconds:
                  _config.minTaskDelayMs * pow(2, task._retryCount).toInt(),
            );
            Timer(delay, () {
              if (_tasks.containsKey(task.id)) {
                _insertTaskByPriority(task);
              }
            });
          }
        }

        // Add small delay to prevent overwhelming the system
        await Future.delayed(Duration(milliseconds: _config.minTaskDelayMs));
      } finally {
        // The pool manages the resource, so no manual release needed
      }
    });
  }

  String _generateTaskId() {
    return 'task_${DateTime.now().millisecondsSinceEpoch}_${Random().nextInt(1000)}';
  }
  
  void _shutdown() {
    stop();
    _taskQueue.clear();
    _tasks.clear();
    _runningTasks.clear();
  }

  // ==========================================================================
  // Database persistence for task history
  // ==========================================================================

  static const String _taskHistoryTable = '_task_history';

  Future<void> _ensureTaskHistoryTable() async {
    await _database?.execute('''
      CREATE TABLE IF NOT EXISTS $_taskHistoryTable (
        name TEXT PRIMARY KEY,
        last_run TEXT NOT NULL
      )
    ''');
  }

  Future<void> _updateTaskHistory(String taskName) async {
    await _database?.execute('''
      INSERT OR REPLACE INTO $_taskHistoryTable (name, last_run)
      VALUES (?, ?)
    ''', [taskName, DateTime.now().toIso8601String()]);
  }

  Future<DateTime?> _getLastRunTimeFromHistory(String taskName) async {
    final result = await _database?.queryMaps(
      (q) => q
          .from(_taskHistoryTable)
          .select('last_run')
          .where(col('name').eq(taskName)),
    );

    if (result != null && result.isNotEmpty) {
      final lastRunString = result.first['last_run'] as String?;
      if (lastRunString != null) {
        return DateTime.tryParse(lastRunString);
      }
    }
    return null;
  }

  Future<DateTime> _getNextRunTimeFromHistory(
      String taskName, Duration interval) async {
    final lastRun = await _getLastRunTimeFromHistory(taskName);
    if (lastRun != null) {
      return lastRun.add(interval);
    }
    return DateTime.now();
  }
}
<!-- END FILE: declarative_sqlite/lib/src/scheduling/task_scheduler.dart -->

<!-- BEGIN FILE: declarative_sqlite/lib/src/schema/column.dart -->
import 'package:declarative_sqlite/src/utils/sql_escaping_utils.dart';

class Column {
  final String name;
  final String logicalType;
  final String type; // The actual DB type (e.g., TEXT, INTEGER)
  final bool isNotNull;
  final num? minValue;
  final num? maxValue;
  final int? maxLength;
  final bool isParent;
  final bool isSequence;
  final bool sequencePerParent;
  final bool isLww;
  final Object? defaultValue;

  const Column({
    required this.name,
    required this.logicalType,
    required this.type,
    this.isNotNull = false,
    this.minValue,
    this.maxValue,
    this.maxLength,
    this.isParent = false,
    this.isSequence = false,
    this.sequencePerParent = false,
    this.isLww = false,
    this.defaultValue,
  });

  String toSql() {
    final parts = [name, type];
    if (isNotNull) {
      parts.add('NOT NULL');
    }
    if (defaultValue != null) {
      if (defaultValue is String) {
        parts.add("DEFAULT '${escapeSingleQuotes(defaultValue as String)}'");
      } else {
        parts.add('DEFAULT $defaultValue');
      }
    }
  if (minValue != null) {
    parts.add('CHECK($name >= $minValue)');
  }
  if (maxLength != null) {
    parts.add('CHECK(length($name) <= $maxLength)');
  }

    return parts.join(' ');
  }

  Map<String, dynamic> toMap() {
    return {
      'name': name,
      'logicalType': logicalType,
      'type': type,
      'isNotNull': isNotNull,
      'minValue': minValue,
      'maxValue': maxValue,
      'maxLength': maxLength,
      'isParent': isParent,
      'isSequence': isSequence,
      'sequencePerParent': sequencePerParent,
      'isLww': isLww,
      'defaultValue': defaultValue,
    };
  }
}

<!-- END FILE: declarative_sqlite/lib/src/schema/column.dart -->

<!-- BEGIN FILE: declarative_sqlite/lib/src/schema/key.dart -->
enum KeyType { primary, indexed, unique, foreign }

class Key {
  final List<String> columns;
  final KeyType type;
  final String? foreignTable;
  final List<String>? foreignColumns;

  const Key({
    required this.columns,
    required this.type,
    this.foreignTable,
    this.foreignColumns,
  });

  bool get isPrimary => type == KeyType.primary;
  bool get isUnique => type == KeyType.unique;
  bool get isForeign => type == KeyType.foreign;

  Map<String, dynamic> toMap() {
    return {
      'columns': columns,
      'type': type.toString(),
      'foreignTable': foreignTable,
      'foreignColumns': foreignColumns,
    };
  }
}

<!-- END FILE: declarative_sqlite/lib/src/schema/key.dart -->

<!-- BEGIN FILE: declarative_sqlite/lib/src/schema/live_schema.dart -->
class LiveSchema {
  final List<LiveTable> tables;
  final List<LiveView> views;

  Iterable<LiveTable> get userTables => tables.where((t) => !t.isSystem);
  Iterable<LiveTable> get systemTables => tables.where((t) => t.isSystem);

  LiveSchema({required this.tables, required this.views});
}

class LiveTable {
  final String name;
  final List<LiveColumn> columns;
  final List<LiveKey> keys;

  bool get isSystem => name.startsWith('__');

  LiveTable({
    required this.name,
    required this.columns,
    required this.keys,
  });
}

class LiveView {
  final String name;
  final String sql;

  LiveView({required this.name, required this.sql});
}

class LiveColumn {
  final String name;
  final String type;
  final bool isNotNull;
  final bool isPrimaryKey;
  final String? defaultValue;

  LiveColumn({
    required this.name,
    required this.type,
    required this.isNotNull,
    required this.isPrimaryKey,
    this.defaultValue,
  });
}

class LiveKey {
  final String name;
  final List<String> columns;
  final bool isUnique;

  LiveKey({required this.name, required this.columns, required this.isUnique});
}

<!-- END FILE: declarative_sqlite/lib/src/schema/live_schema.dart -->

<!-- BEGIN FILE: declarative_sqlite/lib/src/schema/schema.dart -->
import 'dart:convert';
import 'package:crypto/crypto.dart';
import 'package:declarative_sqlite/src/schema/table.dart';
import 'package:declarative_sqlite/src/schema/view.dart';

class Schema {
  final List<Table> tables;
  final List<View> views;

  Iterable<Table> get userTables => tables.where((t) => !t.isSystem);
  Iterable<Table> get systemTables => tables.where((t) => t.isSystem);


  const Schema({
    required this.tables,
    required this.views,
  });

  String toHash() {
    final schemaMap = {
      'tables': tables.map((t) => t.toMap()).toList(),
      'views': views.map((v) => v.toMap()).toList(),
    };
    final jsonString = jsonEncode(schemaMap);
    return sha256.convert(utf8.encode(jsonString)).toString();
  }
}

<!-- END FILE: declarative_sqlite/lib/src/schema/schema.dart -->

<!-- BEGIN FILE: declarative_sqlite/lib/src/schema/table.dart -->
import 'package:declarative_sqlite/src/schema/column.dart';
import 'package:declarative_sqlite/src/schema/key.dart';

class Table {
  final String name;
  final List<Column> columns;
  final List<Key> keys;

  bool get isSystem => name.startsWith('__');

  const Table({
    required this.name,
    required this.columns,
    required this.keys,
  });

  Table copyWith({
    String? name,
    List<Column>? columns,
    List<Key>? keys,
  }) {
    return Table(
      name: name ?? this.name,
      columns: columns ?? this.columns,
      keys: keys ?? this.keys,
    );
  }

  Map<String, dynamic> toMap() {
    return {
      'name': name,
      'columns': columns.map((c) => c.toMap()).toList(),
      'keys': keys.map((k) => k.toMap()).toList(),
    };
  }
}

<!-- END FILE: declarative_sqlite/lib/src/schema/table.dart -->

<!-- BEGIN FILE: declarative_sqlite/lib/src/schema/view.dart -->
class View {
  final String name;
  final String definition;

  const View({
    required this.name,
    required this.definition,
  });

  String toSql() {
    return 'CREATE VIEW $name AS $definition';
  }

  Map<String, dynamic> toMap() {
    return {
      'name': name,
      'definition': definition,
    };
  }
}

<!-- END FILE: declarative_sqlite/lib/src/schema/view.dart -->

<!-- BEGIN FILE: declarative_sqlite/lib/src/streaming/advanced_streaming_query.dart -->
import 'dart:async';
import '../builders/query_builder.dart';
import '../database.dart';
import 'query_dependency_analyzer.dart';

/// Advanced streaming query manager that handles smart lifecycle management
/// with query equality checking and cache invalidation
class AdvancedStreamingQuery<T> {
  final String _id;
  late QueryBuilder _builder;
  late QueryDependencies _dependencies;
  final DeclarativeDatabase _database;
  late T Function(Map<String, Object?>) _mapper;
  
  late final StreamController<List<T>> _controller;
  bool _isActive = false;

  /// Cache of previously mapped results indexed by their system_id
  final Map<String, _CachedResult<T>> _resultCache = {};
  
  /// System IDs of the last emitted result set for fast comparison
  List<String>? _lastResultSystemIds;
  
  /// Reference to the last mapper function for change detection
  T Function(Map<String, Object?>)? _lastMapper;

  AdvancedStreamingQuery._({
    required String id,
    required QueryBuilder builder,
    required DeclarativeDatabase database,
    required T Function(Map<String, Object?>) mapper,
  })  : _id = id,
        _database = database {
    _builder = builder;
    _mapper = mapper;
    _lastMapper = mapper;
    
    // Analyze dependencies
    final analyzer = QueryDependencyAnalyzer(database.schema);
    _dependencies = analyzer.analyze(builder);
    
    _controller = StreamController<List<T>>.broadcast(
      onListen: _onListen,
      onCancel: _onCancel,
    );
  }

  /// Factory constructor to create an advanced streaming query
  factory AdvancedStreamingQuery.create({
    required String id,
    required QueryBuilder builder,
    required DeclarativeDatabase database,
    required T Function(Map<String, Object?>) mapper,
  }) {
    return AdvancedStreamingQuery._(
      id: id,
      builder: builder,
      database: database,
      mapper: mapper,
    );
  }

  /// The unique identifier for this streaming query
  String get id => _id;

  /// The dependencies this query has on database entities
  QueryDependencies get dependencies => _dependencies;

  /// The stream of query results
  Stream<List<T>> get stream => _controller.stream;

  /// Whether this query is currently active (has listeners)
  bool get isActive => _isActive;

  /// Updates the query builder and mapper with smart lifecycle management
  Future<void> updateQuery({
    QueryBuilder? newBuilder,
    T Function(Map<String, Object?>)? newMapper,
  }) async {
    bool needsRefresh = false;
    bool needsCacheInvalidation = false;

    // Check if query builder changed (using Equatable value equality)
    if (newBuilder != null && newBuilder != _builder) {
      _builder = newBuilder;
      
      // Re-analyze dependencies for the new query
      final analyzer = QueryDependencyAnalyzer(_database.schema);
      _dependencies = analyzer.analyze(newBuilder);
      
      needsRefresh = true;
    }

    // Check if mapper function changed (using reference equality)
    if (newMapper != null && !identical(newMapper, _lastMapper)) {
      _mapper = newMapper;
      _lastMapper = newMapper;
      needsCacheInvalidation = true;
      needsRefresh = true;
    }

    // Invalidate cache if mapper changed
    if (needsCacheInvalidation) {
      _resultCache.clear();
      _lastResultSystemIds = null;
    }

    // Execute new query if needed
    if (needsRefresh && _isActive) {
      await refresh();
    }
  }

  /// Returns true if this query might be affected by changes to the given table
  bool isAffectedByTable(String tableName) {
    return _dependencies.isAffectedByTable(tableName);
  }

  /// Returns true if this query might be affected by changes to the given column
  bool isAffectedByColumn(String tableName, String columnName) {
    return _dependencies.isAffectedByColumn(tableName, columnName);
  }

  /// Manually trigger a refresh of this query with hash-based optimization
  Future<void> refresh() async {
    if (!_isActive) return;

    try {
      final rawResults = await _database.queryMapsWith(_builder);

      // Extract system IDs and versions for all raw results
      final newResultSystemIds = <String>[];
      final systemIdToVersion = <String, String>{};
      
      for (final rawRow in rawResults) {
        final systemId = rawRow['system_id'] as String?;
        final systemVersion = rawRow['system_version'] as String?;

        if (systemId != null && systemVersion != null) {
          newResultSystemIds.add(systemId);
          systemIdToVersion[systemId] = systemVersion;
        } else {
          // Fallback for rows without system columns: generate unique identifier
          final fallbackId = 'fallback_${newResultSystemIds.length}';
          newResultSystemIds.add(fallbackId);
          systemIdToVersion[fallbackId] = DateTime.now().millisecondsSinceEpoch.toString();
        }
      }
      
      // Quick check: if system ID sequence is identical, check for version changes
      bool hasChanges = !_areSystemIdSequencesEqual(newResultSystemIds, _lastResultSystemIds);
      if (!hasChanges && _lastResultSystemIds != null) {
        // Check if any system versions have changed
        for (final systemId in newResultSystemIds) {
          final cached = _resultCache[systemId];
          final currentVersion = systemIdToVersion[systemId];
          if (cached == null || cached.systemVersion != currentVersion) {
            hasChanges = true;
            break;
          }
        }
      }
      
      if (!hasChanges) {
        return; // No changes, no emission needed
      }
      
      // Build the new result list using cache optimization
      final mappedResults = <T>[];
      
      for (int i = 0; i < rawResults.length; i++) {
        final rawRow = rawResults[i];
        final systemId = newResultSystemIds[i];
        final systemVersion = systemIdToVersion[systemId]!;

        // Check if we have this row cached with same version
        final cached = _resultCache[systemId];
        if (cached != null && cached.systemVersion == systemVersion) {
          // Use cached mapped object (reference equality maintained)
          mappedResults.add(cached.object);
        } else {
          // Map new row and cache it
          final mappedRow = _mapper(rawRow);
          final cachedResult =
              _CachedResult(mappedRow, systemVersion);
          _resultCache[systemId] = cachedResult;
          mappedResults.add(mappedRow);
        }
      }

      // Clean up cache: remove entries not in current result set
      _cleanupCache(newResultSystemIds.toSet());
      
      // Update cached state and emit
      _controller.add(mappedResults);
      
    } catch (error) {
      _controller.addError(error);
    }
  }

  /// Compares two system ID sequences for equality
  bool _areSystemIdSequencesEqual(List<String>? a, List<String>? b) {
    if (a == null && b == null) return true;
    if (a == null || b == null) return false;
    if (a.length != b.length) return false;
    
    for (int i = 0; i < a.length; i++) {
      if (a[i] != b[i]) return false;
    }
    
    return true;
  }

  /// Removes cached entries that are no longer in the current result set
  void _cleanupCache(Set<String> currentSystemIds) {
    // Only keep cache entries that are still relevant to prevent infinite growth
    _resultCache.removeWhere((systemId, _) => !currentSystemIds.contains(systemId));
  }

  /// Called when the first listener subscribes
  Future<void> _onListen() async {
    _isActive = true;
    await refresh();
  }

  /// Called when the last listener unsubscribes
  void _onCancel() {
    _isActive = false;
    _lastResultSystemIds = null;
    _resultCache.clear();
  }

  /// Dispose of this streaming query
  void dispose() {
    _isActive = false;
    _resultCache.clear();
    _controller.close();
  }

  @override
  String toString() {
    return 'AdvancedStreamingQuery(id: $_id, dependencies: $_dependencies, active: $_isActive, cached: ${_resultCache.length})';
  }
}

/// A cached result entry containing the mapped object and its hash
class _CachedResult<T> {
  final T object;
  final String systemVersion;

  const _CachedResult(this.object, this.systemVersion);
}
<!-- END FILE: declarative_sqlite/lib/src/streaming/advanced_streaming_query.dart -->

<!-- BEGIN FILE: declarative_sqlite/lib/src/streaming/query_dependency_analyzer.dart -->
import '../builders/query_builder.dart';
import '../schema/schema.dart';
import '../schema/table.dart';
import '../schema/view.dart';

/// Represents the dependencies of a query on database entities
class QueryDependencies {
  /// Tables that this query depends on
  final Set<String> tables;
  
  /// Specific columns that this query depends on (format: "table.column")
  final Set<String> columns;
  
  /// Whether this query uses wildcard selects (*)
  final bool usesWildcard;

  const QueryDependencies({
    required this.tables,
    required this.columns,
    required this.usesWildcard,
  });

  /// Returns true if this query might be affected by changes to the given table
  bool isAffectedByTable(String tableName) {
    return tables.contains(tableName);
  }

  /// Returns true if this query might be affected by changes to the given column
  bool isAffectedByColumn(String tableName, String columnName) {
    return usesWildcard && tables.contains(tableName) ||
           columns.contains('$tableName.$columnName');
  }

  @override
  String toString() {
    return 'QueryDependencies(tables: $tables, columns: $columns, usesWildcard: $usesWildcard)';
  }
}

/// Analyzes queries to determine their dependencies on database entities using schema metadata
/// 
/// This analyzer uses a recursive approach to analyze both QueryBuilder objects and View definitions:
/// 1. QueryBuilder analysis: Directly examines the builder's internal structure (FROM, SELECT, JOIN clauses)
/// 2. View analysis: Recursively analyzes view definitions to find underlying table dependencies
/// 3. Dependency union: Combines dependencies from both analyses into a unified set
/// 
/// This approach treats views as "stored queries" and applies the same recursive analysis
/// methodology to both QueryBuilders and Views, ensuring complete dependency detection.
class QueryDependencyAnalyzer {
  final Schema _schema;
  
  QueryDependencyAnalyzer(this._schema);

  /// Analyzes a QueryBuilder to extract its dependencies using schema metadata
  QueryDependencies analyze(QueryBuilder builder) {
    final dependencies = <String>{};
    final columns = <String>{};
    bool usesWildcard = false;

    // Collect dependencies recursively from the query builder's structure
    _collectQueryBuilderDependencies(builder, dependencies, columns);
    
    // Check if wildcard is used by examining the query structure
    usesWildcard = _detectWildcardUsage(builder);

    // For each dependency found, recursively analyze if it's a view
    final currentDeps = Set<String>.from(dependencies);
    for (final tableName in currentDeps) {
      _collectViewDependencies(tableName, dependencies, columns);
    }

    return QueryDependencies(
      tables: dependencies,
      columns: columns,
      usesWildcard: usesWildcard,
    );
  }

  /// Recursively collects dependencies from a QueryBuilder by analyzing its internal structure
  void _collectQueryBuilderDependencies(
    QueryBuilder builder, 
    Set<String> dependencies, 
    Set<String> columns
  ) {
    // Access QueryBuilder's internal fields directly
    final from = _getFromTable(builder);
    final selectColumns = _getSelectColumns(builder);
    final joins = _getJoinTables(builder);
    final whereColumns = _getWhereColumns(builder);
    
    // Collect FROM table dependencies
    if (from != null) {
      final tableName = _extractTableName(from);
      if (_isValidTableOrView(tableName)) {
        dependencies.add(tableName);
      }
    }
    
    // Collect JOIN table dependencies
    for (final join in joins) {
      final tableName = _extractTableName(join);
      if (_isValidTableOrView(tableName)) {
        dependencies.add(tableName);
      }
    }
    
    // Collect column dependencies from SELECT clause
    for (final column in selectColumns) {
      _analyzeColumnReference(column, dependencies, columns);
    }
    
    // Collect column dependencies from WHERE clause
    for (final column in whereColumns) {
      _analyzeColumnReference(column, dependencies, columns);
    }
    
    // Handle nested QueryBuilders in subqueries
    _collectSubQueryDependencies(builder, dependencies, columns);
  }

  /// Extracts the FROM table from a QueryBuilder using reflection
  String? _getFromTable(QueryBuilder builder) {
    // We need to access QueryBuilder's private _from field
    // Since we can't access private fields directly in Dart, we'll use the build() method
    // and extract the FROM clause. This is still better than full SQL parsing as we're
    // analyzing specific components.
    try {
      final (sql, _) = builder.build();
      final fromMatch = RegExp(r'FROM\s+(\w+)(?:\s+AS\s+\w+)?', caseSensitive: false).firstMatch(sql);
      return fromMatch?.group(1);
    } catch (e) {
      return null;
    }
  }

  /// Extracts SELECT columns from a QueryBuilder
  List<String> _getSelectColumns(QueryBuilder builder) {
    try {
      final (sql, _) = builder.build();
      final selectMatch = RegExp(r'SELECT\s+(.*?)\s+FROM', caseSensitive: false).firstMatch(sql);
      if (selectMatch != null) {
        final selectClause = selectMatch.group(1)!;
        if (selectClause.trim() == '*') {
          return ['*'];
        }
        // Split by comma but be careful with nested parentheses in subqueries
        return _splitSelectColumns(selectClause);
      }
      return [];
    } catch (e) {
      return [];
    }
  }

  /// Extracts JOIN tables from a QueryBuilder
  List<String> _getJoinTables(QueryBuilder builder) {
    try {
      final (sql, _) = builder.build();
      final joinMatches = RegExp(r'(?:INNER|LEFT|RIGHT|CROSS|FULL\s+OUTER)?\s*JOIN\s+(\w+)', caseSensitive: false).allMatches(sql);
      return joinMatches.map((match) => match.group(1)!).toList();
    } catch (e) {
      return [];
    }
  }

  /// Extracts column references from WHERE clauses
  List<String> _getWhereColumns(QueryBuilder builder) {
    try {
      final (sql, _) = builder.build();
      final whereMatch = RegExp(r'WHERE\s+(.*?)(?:\s+(?:GROUP\s+BY|ORDER\s+BY|LIMIT)|$)', caseSensitive: false).firstMatch(sql);
      if (whereMatch != null) {
        final whereClause = whereMatch.group(1)!;
        final columnMatches = RegExp(r'(\w+)\.(\w+)|(\w+)').allMatches(whereClause);
        return columnMatches.map((match) => match.group(0)!).toList();
      }
      return [];
    } catch (e) {
      return [];
    }
  }

  /// Analyzes a column reference and adds appropriate dependencies
  void _analyzeColumnReference(String columnRef, Set<String> dependencies, Set<String> columns) {
    if (columnRef == '*') {
      return; // Wildcard handling is done separately
    }
    
    // Handle qualified column references (table.column)
    final qualifiedMatch = RegExp(r'(\w+)\.(\w+)').firstMatch(columnRef);
    if (qualifiedMatch != null) {
      final table = qualifiedMatch.group(1)!;
      final column = qualifiedMatch.group(2)!;
      
      if (_isValidTableOrView(table) && _isValidColumn(table, column)) {
        dependencies.add(table);
        columns.add('$table.$column');
      }
      return;
    }
    
    // Handle unqualified column references
    final columnMatch = RegExp(r'\b(\w+)\b').firstMatch(columnRef);
    if (columnMatch != null) {
      final column = columnMatch.group(1)!;
      if (!_isSQLKeyword(column)) {
        // Find the main table from dependencies to qualify this column
        final mainTable = dependencies.isNotEmpty ? dependencies.first : '';
        if (mainTable.isNotEmpty && _isValidColumn(mainTable, column)) {
          columns.add('$mainTable.$column');
        }
      }
    }
  }

  /// Handles nested QueryBuilders in subqueries
  void _collectSubQueryDependencies(QueryBuilder builder, Set<String> dependencies, Set<String> columns) {
    // Check for subqueries in SELECT clause by looking for patterns like "(...) AS alias"
    try {
      final (sql, _) = builder.build();
      final subQueryMatches = RegExp(r'\(([^)]+)\)\s+AS\s+\w+').allMatches(sql);
      
      for (final match in subQueryMatches) {
        final subQuerySQL = match.group(1)!;
        // If this looks like a SELECT statement, it's a subquery
        if (subQuerySQL.toUpperCase().contains('SELECT')) {
          // Extract dependencies from the subquery SQL
          _extractDependenciesFromSQL(subQuerySQL, dependencies, columns);
        }
      }
    } catch (e) {
      // If subquery analysis fails, continue with other dependencies
    }
  }

  /// Splits SELECT columns while respecting nested parentheses
  List<String> _splitSelectColumns(String selectClause) {
    final columns = <String>[];
    var current = '';
    var parenDepth = 0;
    
    for (var i = 0; i < selectClause.length; i++) {
      final char = selectClause[i];
      
      if (char == '(') {
        parenDepth++;
        current += char;
      } else if (char == ')') {
        parenDepth--;
        current += char;
      } else if (char == ',' && parenDepth == 0) {
        columns.add(current.trim());
        current = '';
      } else {
        current += char;
      }
    }
    
    if (current.trim().isNotEmpty) {
      columns.add(current.trim());
    }
    
    return columns;
  }

  /// Extracts table name from a table reference (handles aliases)
  String _extractTableName(String tableRef) {
    // Handle "table AS alias" or just "table"
    final parts = tableRef.split(RegExp(r'\s+'));
    return parts.first;
  }

  /// Collects dependencies from views recursively
  void _collectViewDependencies(
    String entityName, 
    Set<String> dependencies, 
    Set<String> columns
  ) {
    // Check if this entity is a view in our schema
    final view = _findViewByName(entityName);
    if (view != null) {
      // Recursively analyze the view's definition
      _extractDependenciesFromSQL(view.definition, dependencies, columns);
      
      // Recursively process any views that this view depends on
      final newDeps = Set<String>.from(dependencies);
      for (final dep in newDeps) {
        if (dep != entityName) { // Avoid infinite recursion
          _collectViewDependencies(dep, dependencies, columns);
        }
      }
    }
  }

  /// Extracts dependencies from SQL using schema metadata for validation
  void _extractDependenciesFromSQL(
    String sql, 
    Set<String> dependencies, 
    Set<String> columns
  ) {
    final normalizedSQL = sql.toLowerCase().replaceAll(RegExp(r'\s+'), ' ').trim();

    // Extract tables from FROM clauses
    final fromMatches = RegExp(r'from\s+(\w+)(?:\s+as\s+\w+)?').allMatches(normalizedSQL);
    for (final match in fromMatches) {
      final tableName = match.group(1)!;
      if (_isValidTableOrView(tableName)) {
        dependencies.add(tableName);
      }
    }

    // Extract tables from JOIN clauses
    final joinMatches = RegExp(r'(?:inner\s+|left\s+|right\s+|cross\s+)?join\s+(\w+)(?:\s+as\s+\w+)?').allMatches(normalizedSQL);
    for (final match in joinMatches) {
      final tableName = match.group(1)!;
      if (_isValidTableOrView(tableName)) {
        dependencies.add(tableName);
      }
    }

    // Extract qualified column references
    final columnMatches = RegExp(r'(\w+)\.(\w+)').allMatches(normalizedSQL);
    for (final match in columnMatches) {
      final table = match.group(1)!;
      final column = match.group(2)!;
      if (_isValidTableOrView(table) && _isValidColumn(table, column)) {
        dependencies.add(table);
        columns.add('$table.$column');
      }
    }

    // Extract unqualified columns from SELECT clause and validate against schema
    final selectMatch = RegExp(r'select\s+(.*?)\s+from').firstMatch(normalizedSQL);
    if (selectMatch != null) {
      final selectClause = selectMatch.group(1)!;
      if (!selectClause.contains('*')) {
        final mainTable = dependencies.isNotEmpty ? dependencies.first : '';
        final unqualifiedMatches = RegExp(r'\b(\w+)(?!\s*\()').allMatches(selectClause);
        
        for (final match in unqualifiedMatches) {
          final column = match.group(1)!;
          if (mainTable.isNotEmpty && 
              !_isSQLKeyword(column) && 
              _isValidColumn(mainTable, column)) {
            columns.add('$mainTable.$column');
          }
        }
      }
    }
  }

  /// Detects wildcard usage in the query by examining QueryBuilder structure
  bool _detectWildcardUsage(QueryBuilder builder) {
    try {
      final selectColumns = _getSelectColumns(builder);
      return selectColumns.contains('*');
    } catch (e) {
      // Fallback to SQL-based detection
      final (sql, _) = builder.build();
      return sql.toLowerCase().contains('select *');
    }
  }

  /// Validates if a name corresponds to a table or view in the schema
  bool _isValidTableOrView(String name) {
    return _findTableByName(name) != null || _findViewByName(name) != null;
  }

  /// Validates if a column exists in the specified table or view
  bool _isValidColumn(String tableName, String columnName) {
    final table = _findTableByName(tableName);
    if (table != null) {
      return table.columns.any((col) => col.name == columnName) ||
             _isSystemColumn(columnName);
    }
    
    // For views, we'd need to analyze their structure more deeply
    // For now, we'll be permissive with view columns
    final view = _findViewByName(tableName);
    return view != null;
  }

  /// Checks if a column is a system column (system_id, system_version, etc.)
  bool _isSystemColumn(String columnName) {
    return columnName.startsWith('system_') || columnName.endsWith('__hlc');
  }

  /// Finds a table by name in the schema
  Table? _findTableByName(String name) {
    try {
      return _schema.tables.firstWhere((table) => table.name == name);
    } catch (e) {
      return null;
    }
  }

  /// Finds a view by name in the schema
  View? _findViewByName(String name) {
    try {
      return _schema.views.firstWhere((view) => view.name == name);
    } catch (e) {
      return null;
    }
  }

  static bool _isSQLKeyword(String word) {
    const keywords = {
      'select', 'from', 'where', 'join', 'inner', 'left', 'right', 'cross',
      'on', 'and', 'or', 'not', 'in', 'like', 'between', 'null', 'is',
      'group', 'by', 'order', 'having', 'limit', 'offset', 'distinct',
      'as', 'asc', 'desc', 'count', 'sum', 'avg', 'min', 'max'
    };
    return keywords.contains(word.toLowerCase());
  }

  /// Analyzes raw SQL to extract dependencies (fallback method for backward compatibility)
  @deprecated
  static QueryDependencies analyzeSQL(String sql) {
    // This method is kept for backward compatibility but should not be used
    // when schema metadata is available
    final tables = <String>{};
    final columns = <String>{};
    bool usesWildcard = false;

    try {
      final normalizedSQL = sql.toLowerCase().replaceAll(RegExp(r'\s+'), ' ').trim();

      // Basic regex-based parsing as fallback
      final fromMatches = RegExp(r'from\s+(\w+)(?:\s+as\s+\w+)?').allMatches(normalizedSQL);
      for (final match in fromMatches) {
        final tableName = match.group(1)!;
        if (tableName.isNotEmpty && !_isSQLKeyword(tableName)) {
          tables.add(tableName);
        }
      }

      final joinMatches = RegExp(r'(?:inner\s+|left\s+|right\s+|cross\s+)?join\s+(\w+)(?:\s+as\s+\w+)?').allMatches(normalizedSQL);
      for (final match in joinMatches) {
        final tableName = match.group(1)!;
        if (tableName.isNotEmpty && !_isSQLKeyword(tableName)) {
          tables.add(tableName);
        }
      }

      if (normalizedSQL.contains('select *')) {
        usesWildcard = true;
      }
    } catch (e) {
      // If parsing fails, return safe defaults
    }

    return QueryDependencies(
      tables: tables,
      columns: columns,
      usesWildcard: usesWildcard,
    );
  }
}
<!-- END FILE: declarative_sqlite/lib/src/streaming/query_dependency_analyzer.dart -->

<!-- BEGIN FILE: declarative_sqlite/lib/src/streaming/query_stream_manager.dart -->
import 'dart:async';
import 'streaming_query.dart';

/// Manages multiple streaming queries and coordinates their updates
class QueryStreamManager {
  final Map<String, StreamingQuery> _activeQueries = {};
  
  /// Registers a streaming query with the manager
  void register(StreamingQuery query) {
    _activeQueries[query.id] = query;
  }

  /// Unregisters a streaming query from the manager
  void unregister(String queryId) {
    final query = _activeQueries.remove(queryId);
    query?.dispose();
  }

  /// Notifies all relevant queries that a table has been modified
  Future<void> notifyTableChanged(String tableName) async {
    final affectedQueries = _activeQueries.values
        .where((query) => query.isActive && query.isAffectedByTable(tableName))
        .toList();

    // Refresh all affected queries concurrently
    await Future.wait(
      affectedQueries.map((query) => query.refresh()),
    );
  }

  /// Notifies all relevant queries that a specific column has been modified
  Future<void> notifyColumnChanged(String tableName, String columnName) async {
    final affectedQueries = _activeQueries.values
        .where((query) => 
            query.isActive && 
            query.isAffectedByColumn(tableName, columnName))
        .toList();

    // Refresh all affected queries concurrently
    await Future.wait(
      affectedQueries.map((query) => query.refresh()),
    );
  }

  /// Returns the number of active streaming queries
  int get activeQueryCount => _activeQueries.values.where((q) => q.isActive).length;

  /// Returns the total number of registered queries
  int get totalQueryCount => _activeQueries.length;

  /// Clean up inactive queries
  void cleanup() {
    final inactiveQueries = _activeQueries.entries
        .where((entry) => !entry.value.isActive)
        .map((entry) => entry.key)
        .toList();

    for (final queryId in inactiveQueries) {
      unregister(queryId);
    }
  }

  /// Dispose of all queries and clean up
  void dispose() {
    for (final query in _activeQueries.values) {
      query.dispose();
    }
    _activeQueries.clear();
  }

  @override
  String toString() {
    return 'QueryStreamManager(active: $activeQueryCount, total: $totalQueryCount)';
  }
}
<!-- END FILE: declarative_sqlite/lib/src/streaming/query_stream_manager.dart -->

<!-- BEGIN FILE: declarative_sqlite/lib/src/streaming/streaming_query.dart -->
import 'dart:async';
import '../builders/query_builder.dart';
import '../database.dart';
import 'query_dependency_analyzer.dart';

/// A cached result entry containing the mapped object and its system version
class _CachedResult<T> {
  final T object;
  final String systemVersion;
  
  const _CachedResult(this.object, this.systemVersion);
}

/// A streaming query that emits new results whenever the underlying data changes
class StreamingQuery<T> {
  final String _id;
  final QueryBuilder _builder;
  final QueryDependencies _dependencies;
  final DeclarativeDatabase _database;
  final T Function(Map<String, Object?>) _mapper;
  
  late final StreamController<List<T>> _controller;
  bool _isActive = false;
  
  /// Cache of previously mapped results indexed by their system_id
  final Map<String, _CachedResult<T>> _resultCache = {};
  
  /// System IDs of the last emitted result set for fast comparison
  List<String>? _lastResultSystemIds;

  StreamingQuery._({
    required String id,
    required QueryBuilder builder,
    required QueryDependencies dependencies,
    required DeclarativeDatabase database,
    required T Function(Map<String, Object?>) mapper,
  })  : _id = id,
        _builder = builder,
        _dependencies = dependencies,
        _database = database,
        _mapper = mapper {
    _controller = StreamController<List<T>>.broadcast(
      onListen: _onListen,
      onCancel: _onCancel,
    );
  }

  /// Factory constructor to create a streaming query
  factory StreamingQuery.create({
    required String id,
    required QueryBuilder builder,
    required DeclarativeDatabase database,
    required T Function(Map<String, Object?>) mapper,
  }) {
    // Use schema-aware dependency analysis
    final analyzer = QueryDependencyAnalyzer(database.schema);
    final dependencies = analyzer.analyze(builder);
    return StreamingQuery._(
      id: id,
      builder: builder,
      dependencies: dependencies,
      database: database,
      mapper: mapper,
    );
  }

  /// The unique identifier for this streaming query
  String get id => _id;

  /// The dependencies this query has on database entities
  QueryDependencies get dependencies => _dependencies;

  /// The stream of query results
  Stream<List<T>> get stream => _controller.stream;

  /// Whether this query is currently active (has listeners)
  bool get isActive => _isActive;

  /// Returns true if this query might be affected by changes to the given table
  bool isAffectedByTable(String tableName) {
    return _dependencies.isAffectedByTable(tableName);
  }

  /// Returns true if this query might be affected by changes to the given column
  bool isAffectedByColumn(String tableName, String columnName) {
    return _dependencies.isAffectedByColumn(tableName, columnName);
  }

  /// Manually trigger a refresh of this query with hash-based optimization
  Future<void> refresh() async {
    if (!_isActive) return;
    
    try {
      final rawResults = await _database.queryMapsWith(_builder);
      
      // Extract system IDs and versions for all raw results
      final newResultSystemIds = <String>[];
      final systemIdToVersion = <String, String>{};
      
      for (final rawRow in rawResults) {
        final systemId = rawRow['system_id'] as String?;
        final systemVersion = rawRow['system_version'] as String?;
        
        if (systemId != null && systemVersion != null) {
          newResultSystemIds.add(systemId);
          systemIdToVersion[systemId] = systemVersion;
        } else {
          // Fallback for rows without system columns: generate unique identifier
          final fallbackId = 'fallback_${newResultSystemIds.length}';
          newResultSystemIds.add(fallbackId);
          systemIdToVersion[fallbackId] = DateTime.now().millisecondsSinceEpoch.toString();
        }
      }
      
      // Quick check: if system ID sequence is identical, check for version changes
      bool hasChanges = !_areSystemIdSequencesEqual(newResultSystemIds, _lastResultSystemIds);
      if (!hasChanges && _lastResultSystemIds != null) {
        // Check if any system versions have changed
        for (final systemId in newResultSystemIds) {
          final cached = _resultCache[systemId];
          final currentVersion = systemIdToVersion[systemId];
          if (cached == null || cached.systemVersion != currentVersion) {
            hasChanges = true;
            break;
          }
        }
      }
      
      if (!hasChanges) {
        return; // No changes, no emission needed
      }
      
      // Build the new result list using cache optimization
      final mappedResults = <T>[];
      
      for (int i = 0; i < rawResults.length; i++) {
        final rawRow = rawResults[i];
        final systemId = newResultSystemIds[i];
        final systemVersion = systemIdToVersion[systemId]!;
        
        // Check if we have this row cached with same version
        final cached = _resultCache[systemId];
        if (cached != null && cached.systemVersion == systemVersion) {
          // Use cached mapped object (reference equality maintained)
          mappedResults.add(cached.object);
        } else {
          // Map new row and cache it
          final mappedRow = _mapper(rawRow);
          final cachedResult = _CachedResult(mappedRow, systemVersion);
          _resultCache[systemId] = cachedResult;
          mappedResults.add(mappedRow);
        }
      }
      
      // Clean up cache: remove entries not in current result set
      _cleanupCache(newResultSystemIds.toSet());
      
      // Update cached state and emit
      _lastResultSystemIds = newResultSystemIds;
      _controller.add(mappedResults);
      
    } catch (error) {
      _controller.addError(error);
    }
  }

  /// Compares two system ID sequences for equality
  bool _areSystemIdSequencesEqual(List<String>? a, List<String>? b) {
    if (a == null && b == null) return true;
    if (a == null || b == null) return false;
    if (a.length != b.length) return false;
    
    for (int i = 0; i < a.length; i++) {
      if (a[i] != b[i]) return false;
    }
    
    return true;
  }

  /// Removes cached entries that are no longer in the current result set
  void _cleanupCache(Set<String> currentSystemIds) {
    // Only keep cache entries that are still relevant to prevent infinite growth
    _resultCache.removeWhere((systemId, _) => !currentSystemIds.contains(systemId));
  }

  /// Called when the first listener subscribes
  Future<void> _onListen() async {
    _isActive = true;
    await refresh();
  }

  /// Called when the last listener unsubscribes  
  void _onCancel() {
    _isActive = false;
    _lastResultSystemIds = null;
    _resultCache.clear();
  }

  /// Dispose of this streaming query
  void dispose() {
    _isActive = false;
    _resultCache.clear();
    _controller.close();
  }

  @override
  String toString() {
    return 'StreamingQuery(id: $_id, dependencies: $_dependencies, active: $_isActive, cached: ${_resultCache.length})';
  }
}
<!-- END FILE: declarative_sqlite/lib/src/streaming/streaming_query.dart -->

<!-- BEGIN FILE: declarative_sqlite/lib/src/sync/dirty_row.dart -->
import 'package:declarative_sqlite/src/sync/hlc.dart';
import 'package:equatable/equatable.dart';

class DirtyRow extends Equatable {
  final String tableName;
  final String rowId;
  final Hlc hlc;

  @override
  List<Object?> get props => [tableName, rowId, hlc];

  const DirtyRow({
    required this.tableName,
    required this.rowId,
    required this.hlc,
  });
}

<!-- END FILE: declarative_sqlite/lib/src/sync/dirty_row.dart -->

<!-- BEGIN FILE: declarative_sqlite/lib/src/sync/dirty_row_store.dart -->
import 'package:declarative_sqlite/src/sync/hlc.dart';
import 'package:declarative_sqlite/src/sync/dirty_row.dart';
import 'package:sqflite_common/sqflite.dart';

/// Abstract base class for a data store that holds pending operations.
abstract class DirtyRowStore {
  /// Initializes the store with the [DatabaseExecutor].
  Future<void> init(DatabaseExecutor db);

  /// Adds an operation to the store.
  Future<void> add(String tableName, String rowId, Hlc hlc);

  /// Retrieves all pending operations from the store.
  Future<List<DirtyRow>> getAll();

  /// Removes a list of operations from the store, usually after they have been
  /// successfully synchronized.
  Future<void> remove(List<DirtyRow> operations);

  /// Clears all pending operations from the store.
  Future<void> clear();
}

<!-- END FILE: declarative_sqlite/lib/src/sync/dirty_row_store.dart -->

<!-- BEGIN FILE: declarative_sqlite/lib/src/sync/hlc.dart -->
import 'package:equatable/equatable.dart';
import 'package:uuid/uuid.dart';

/// A Hybrid Logical Clock (HLC) timestamp.
///
/// HLCs combine physical time (wall-clock) with a logical counter to create
/// a partially ordered, sortable, and conflict-free timestamp across
/// distributed nodes.
///
/// The format is: `<milliseconds>:<counter>:<nodeId>`
/// - `milliseconds`: Milliseconds since the Unix epoch, left-padded with zeros.
/// - `counter`: A logical counter, left-padded with zeros, to resolve ties
///   when events occur in the same millisecond.
/// - `nodeId`: A unique identifier for the node that generated the timestamp.
///
/// The padding ensures that HLC timestamps can be lexically sorted.
class Hlc extends Equatable implements Comparable<Hlc> {
  final int milliseconds;
  final int counter;
  final String nodeId;

  @override
  List<Object?> get props =>
      [milliseconds.hashCode, counter.hashCode, nodeId.hashCode];

  @override
  bool? get stringify => false;

  static Hlc min = const Hlc(0, 0, '0');

  const Hlc(this.milliseconds, this.counter, this.nodeId);

  /// Creates an HLC timestamp from a string representation.
  factory Hlc.parse(String encoded) {
    final parts = encoded.split(':');
    if (parts.length != 3) {
      throw FormatException('Invalid HLC string format', encoded);
    }
    return Hlc(
      int.parse(parts[0]),
      int.parse(parts[1]),
      parts[2],
    );
  }

  @override
  String toString() {
    // Pad to ensure lexical sortability.
    // Milliseconds: 15 digits (supports dates far into the future)
    // Counter: 5 digits (allows for 100,000 events per millisecond)
    return '${milliseconds.toString().padLeft(15, '0')}:'
        '${counter.toString().padLeft(5, '0')}:'
        '$nodeId';
  }

  @override
  int compareTo(Hlc other) {
    if (milliseconds != other.milliseconds) {
      return milliseconds.compareTo(other.milliseconds);
    }
    if (counter != other.counter) {
      return counter.compareTo(other.counter);
    }
    return nodeId.compareTo(other.nodeId);
  }
}

/// A clock that generates Hybrid Logical Clock timestamps.
/// 
/// This is a singleton to ensure causal ordering is preserved throughout
/// the entire application. All database instances should use the same
/// HLC clock instance.
class HlcClock {
  static HlcClock? _instance;
  
  int _lastMilliseconds;
  int _lastCounter;
  final String nodeId;

  HlcClock._internal({String? nodeId})
      : _lastMilliseconds = DateTime.now().millisecondsSinceEpoch,
        _lastCounter = 0,
        nodeId = nodeId ?? const Uuid().v4();

  /// Gets the singleton instance of the HLC clock.
  /// 
  /// If [nodeId] is provided on first access, it will be used as the node ID.
  /// Subsequent calls with different node IDs will be ignored.
  factory HlcClock({String? nodeId}) {
    return _instance ??= HlcClock._internal(nodeId: nodeId);
  }

  /// Gets the singleton instance without creating it.
  /// Throws if the instance hasn't been created yet.
  static HlcClock get instance {
    if (_instance == null) {
      throw StateError('HlcClock instance not initialized. Call HlcClock() first.');
    }
    return _instance!;
  }

  /// Resets the singleton instance. Used primarily for testing.
  static void resetInstance() {
    _instance = null;
  }

  /// Generates a new HLC timestamp.
  Hlc now() {
    final wallClock = DateTime.now().millisecondsSinceEpoch;

    if (wallClock > _lastMilliseconds) {
      _lastMilliseconds = wallClock;
      _lastCounter = 0;
    } else {
      _lastCounter++;
    }

    return Hlc(_lastMilliseconds, _lastCounter, nodeId);
  }

  /// Updates the clock based on a received HLC timestamp from another node.
  /// This is crucial for keeping clocks synchronized in a distributed system.
  void update(Hlc received) {
    final wallClock = DateTime.now().millisecondsSinceEpoch;

    if (wallClock > _lastMilliseconds && wallClock > received.milliseconds) {
      // Case 1: Local and received time are both in the past.
      // The physical clock is authoritative.
      _lastMilliseconds = wallClock;
      _lastCounter = 0;
    } else if (_lastMilliseconds == received.milliseconds) {
      // Case 2: Same millisecond, update to the higher counter.
      _lastCounter =
          (received.counter > _lastCounter ? received.counter : _lastCounter) +
              1;
    } else if (_lastMilliseconds > received.milliseconds) {
      // Case 3: Local clock is ahead. Increment counter.
      _lastCounter++;
    } else {
      // Case 4: Received clock is ahead. Adopt its time.
      _lastMilliseconds = received.milliseconds;
      _lastCounter = received.counter + 1;
    }
  }
}

<!-- END FILE: declarative_sqlite/lib/src/sync/hlc.dart -->

<!-- BEGIN FILE: declarative_sqlite/lib/src/sync/server_sync_manager.dart -->
import 'package:declarative_sqlite/src/database.dart';
import 'package:declarative_sqlite/src/sync/hlc.dart';

import 'dirty_row.dart';

/// Callback for fetching all data from the server.
/// 
/// The [tableTimestamps] map contains the latest server HLC timestamp
/// for each table that this client has received. The server should return
/// all records that have a server timestamp newer than these values.
typedef OnFetch = Future<void> Function(
    DeclarativeDatabase database, Map<String, Hlc?> tableTimestamps);

typedef OnSend = Future<bool> Function(List<DirtyRow> operations);

/// Manages server synchronization without internal timers.
/// 
/// Timer responsibility has been moved to TaskScheduler for better
/// resource management and fair scheduling.
class ServerSyncManager {
  final DeclarativeDatabase _db;
  final OnFetch onFetch;
  final OnSend onSend;
  final dynamic retryStrategy;

  bool _isSyncing = false;

  ServerSyncManager({
    required DeclarativeDatabase db,
    required this.onFetch,
    required this.onSend,
    this.retryStrategy,
  }) : _db = db;

  /// Performs a complete sync cycle.
  /// 
  /// This should be called by the TaskScheduler at regular intervals.
  Future<void> performSync() async {
    if (_isSyncing) {
      return;
    }
    _isSyncing = true;

    try {
      // 1. Send pending operations
      final pendingOperations = await _db.dirtyRowStore?.getAll();
      if (pendingOperations != null && pendingOperations.isNotEmpty) {
        final success = await onSend(pendingOperations);
        if (success) {
          await _db.dirtyRowStore?.remove(pendingOperations);
        }
      }

      // 2. Fetch new data from the server with delta timestamps
      final tableTimestamps = await _getTableTimestamps();
      await onFetch(_db, tableTimestamps);
    } catch (e) {
      // Handle errors, potentially using the retryStrategy
      rethrow;
    } finally {
      _isSyncing = false;
    }
  }

  /// Gets the latest server timestamp for each table to enable delta sync.
  Future<Map<String, Hlc?>> _getTableTimestamps() async {
    final timestamps = <String, Hlc?>{};
    
    try {
      // Get the latest server timestamp for each table
      for (final table in _db.schema.userTables) {
        final result = await _db.queryTable(
          'sync_server_timestamps',
          columns: ['server_timestamp'],
          where: 'table_name = ?',
          whereArgs: [table.name],
          limit: 1,
        );
        
        if (result.isNotEmpty) {
          final timestampStr = result.first['server_timestamp'] as String?;
          timestamps[table.name] = timestampStr != null ? Hlc.parse(timestampStr) : null;
        } else {
          timestamps[table.name] = null;
        }
      }
    } catch (e) {
      // If sync_server_timestamps table doesn't exist yet, return null timestamps
      for (final table in _db.schema.userTables) {
        timestamps[table.name] = null;
      }
    }
    
    return timestamps;
  }

  /// Updates the server timestamp for a table after successful fetch.
  /// 
  /// This should be called after processing records from the server
  /// to track the latest server timestamp received.
  Future<void> updateTableTimestamp(String tableName, Hlc serverTimestamp) async {
    await _ensureTimestampTableExists();

    await _db.rawInsert(
      'INSERT OR REPLACE INTO sync_server_timestamps (table_name, server_timestamp, updated_at) VALUES (?, ?, ?)',
      [
        tableName,
        serverTimestamp.toString(),
        DateTime.now().toIso8601String(),
      ],
    );
  }

  /// Ensures the sync_server_timestamps table exists.
  Future<void> _ensureTimestampTableExists() async {
    try {
      await _db.rawUpdate('''
        CREATE TABLE IF NOT EXISTS sync_server_timestamps (
          table_name TEXT PRIMARY KEY,
          server_timestamp TEXT NOT NULL,
          updated_at TEXT NOT NULL
        )
      ''');
    } catch (e) {
      // Table might already exist
    }
  }

  /// Manually triggers a sync cycle.
  /// 
  /// Deprecated: Use TaskScheduler.triggerTask() instead for better resource management.
  @Deprecated('Use TaskScheduler for triggering sync operations')
  Future<void> triggerSync() => performSync();
}

<!-- END FILE: declarative_sqlite/lib/src/sync/server_sync_manager.dart -->

<!-- BEGIN FILE: declarative_sqlite/lib/src/sync/sqlite_dirty_row_store.dart -->
import 'package:declarative_sqlite/src/sync/dirty_row.dart';
import 'package:declarative_sqlite/src/sync/dirty_row_store.dart';
import 'package:declarative_sqlite/src/sync/hlc.dart';
import 'package:sqflite_common/sqflite.dart';

/// An implementation of [DirtyRowStore] that uses a SQLite table.
class SqliteDirtyRowStore implements DirtyRowStore {
  late final DatabaseExecutor _db;
  final String _tableName = '__dirty_rows';

  SqliteDirtyRowStore();

  @override
  Future<void> init(DatabaseExecutor db) async {
    _db = db;
  }

  @override
  Future<void> add(String tableName, String rowId, Hlc hlc) async {
    await _db.rawInsert('''
      INSERT OR REPLACE INTO $_tableName (table_name, row_id, hlc)
      VALUES (?, ?, ?)
    ''', [tableName, rowId, hlc.toString()]);
  }

  @override
  Future<List<DirtyRow>> getAll() async {
    final results = await _db.query(
      _tableName,
      columns: ['table_name', 'row_id', 'hlc'],
    );
    return results.map((row) {
      return DirtyRow(
        tableName: row['table_name'] as String,
        rowId: row['row_id'] as String,
        hlc: Hlc.parse(row['hlc'] as String),
      );
    }).toList();
  }

  /// Removes a list of rows from the dirty rows log.
  ///
  /// This should be called after successfully syncing rows with a server.
  /// It uses a lock-free approach to only remove rows that have not been
  /// modified again since the sync started.
  @override
  Future<void> remove(List<DirtyRow> operations) async {
    for (final operation in operations) {
      await _db.delete(
        _tableName,
        where: 'table_name = ? AND row_id = ? AND hlc = ?',
        whereArgs: [
          operation.tableName,
          operation.rowId,
          operation.hlc.toString()
        ],
      );
    }
  }

  @override
  Future<void> clear() async {
    await _db.delete(_tableName);
  }
}

<!-- END FILE: declarative_sqlite/lib/src/sync/sqlite_dirty_row_store.dart -->

<!-- BEGIN FILE: declarative_sqlite/lib/src/utils/sql_escaping_utils.dart -->
String escapeSingleQuotes(String value) {
  return value.replaceAll("'", "''");
}

<!-- END FILE: declarative_sqlite/lib/src/utils/sql_escaping_utils.dart -->

<!-- BEGIN FILE: declarative_sqlite/pubspec.yaml -->
name: declarative_sqlite
description: A dart package for declaratively creating SQLite tables and automatically migrating them.
version: 1.0.1
repository: https://github.com/graknol/declarative_sqlite

environment:
  sdk: ^3.5.3

dependencies:
  flutter:
    sdk: flutter
  path: ^1.9.1
  meta: ^1.11.0
  equatable: ^2.0.5
  uuid: ^4.0.0
  sqflite_common: ^2.5.4+3
  path_provider: ">1.0.0 <2.3.0-beta"
  crypto: ^3.0.6
  collection: ^1.19.1
  async: ^2.11.0
  pool: ^1.5.1
  async_locks: ^1.0.0

dev_dependencies:
  flutter_test:
    sdk: flutter
  lints: ^4.0.0
  test: ^1.24.0
  sqflite: ^2.3.3+1
  sqflite_common_ffi: ^2.3.6
  build_runner: ^2.4.10
  declarative_sqlite_generator:
    path: ../declarative_sqlite_generator

flutter: {}

<!-- END FILE: declarative_sqlite/pubspec.yaml -->

<!-- BEGIN FILE: declarative_sqlite_flutter/lib/declarative_sqlite_flutter.dart -->
library declarative_sqlite_flutter;

export 'src/database_provider.dart';
export 'src/server_sync_manager.dart';
export 'src/query_list_view.dart';

<!-- END FILE: declarative_sqlite_flutter/lib/declarative_sqlite_flutter.dart -->

<!-- BEGIN FILE: declarative_sqlite_flutter/lib/src/database_provider.dart -->
import 'package:declarative_sqlite/declarative_sqlite.dart';
import 'package:flutter/widgets.dart';
import 'package:sqflite/sqflite.dart';
import 'package:path_provider/path_provider.dart';
import 'package:path/path.dart' as path;

/// An inherited widget that provides access to a [DeclarativeDatabase] instance
/// throughout the widget tree.
class _DatabaseInheritedWidget extends InheritedWidget {
  final DeclarativeDatabase database;

  const _DatabaseInheritedWidget({
    required this.database,
    required super.child,
  });

  @override
  bool updateShouldNotify(_DatabaseInheritedWidget oldWidget) {
    return database != oldWidget.database;
  }

  static DeclarativeDatabase? maybeOf(BuildContext context) {
    final widget =
        context.dependOnInheritedWidgetOfExactType<_DatabaseInheritedWidget>();
    return widget?.database;
  }

  static DeclarativeDatabase of(BuildContext context) {
    final database = maybeOf(context);
    if (database == null) {
      throw FlutterError(
        'DatabaseProvider.of() called with a context that does not contain a DatabaseProvider.\n'
        'No DatabaseProvider ancestor could be found starting from the context that was passed '
        'to DatabaseProvider.of(). This usually happens when the context provided is from a widget '
        'that is not a descendant of a DatabaseProvider widget.\n'
        'The context used was:\n'
        '  $context',
      );
    }
    return database;
  }
}

/// A widget that initializes and provides a [DeclarativeDatabase] to its descendants.
///
/// This widget manages the lifecycle of the database connection and provides it
/// through an [InheritedWidget] for efficient access throughout the widget tree.
///
/// Example:
/// ```dart
/// DatabaseProvider(
///   schema: (builder) {
///     builder.table('users', (table) {
///       table.guid('id').notNull();
///       table.text('name').notNull();
///     });
///   },
///   databaseName: 'my_app.db',
///   child: MyApp(),
/// )
/// ```
class DatabaseProvider extends StatefulWidget {
  final void Function(SchemaBuilder builder) schema;
  final String databaseName;
  final Widget child;
  final String? databasePath;

  const DatabaseProvider({
    super.key,
    required this.schema,
    required this.databaseName,
    required this.child,
    this.databasePath,
  });

  /// Access the database from anywhere in the widget tree.
  static DeclarativeDatabase of(BuildContext context) {
    return _DatabaseInheritedWidget.of(context);
  }

  /// Access the database from anywhere in the widget tree, returning null if not found.
  static DeclarativeDatabase? maybeOf(BuildContext context) {
    return _DatabaseInheritedWidget.maybeOf(context);
  }

  @override
  State<DatabaseProvider> createState() => _DatabaseProviderState();
}

class _DatabaseProviderState extends State<DatabaseProvider> {
  DeclarativeDatabase? _database;
  bool _isInitializing = true;
  Object? _initializationError;

  @override
  void initState() {
    super.initState();
    _initializeDatabase();
  }

  @override
  void didUpdateWidget(DatabaseProvider oldWidget) {
    super.didUpdateWidget(oldWidget);

    // If schema or database name changed, reinitialize
    if (widget.databaseName != oldWidget.databaseName ||
        widget.databasePath != oldWidget.databasePath) {
      _disposeDatabase();
      _initializeDatabase();
    }
  }

  @override
  void dispose() {
    _disposeDatabase();
    super.dispose();
  }

  void _disposeDatabase() {
    _database?.close();
    _database = null;
  }

  Future<void> _initializeDatabase() async {
    _setInitializationState(isInitializing: true, error: null);

    try {
      final schema = _buildDatabaseSchema();
      final database = await _createDatabaseInstance(schema);
      _setInitializationState(isInitializing: false, database: database);
    } catch (error) {
      _setInitializationState(isInitializing: false, error: error);
    }
  }

  Schema _buildDatabaseSchema() {
    final schemaBuilder = SchemaBuilder();
    widget.schema(schemaBuilder);
    return schemaBuilder.build();
  }

  Future<DeclarativeDatabase> _createDatabaseInstance(Schema schema) async {
    final libraryDirectory = await getLibraryDirectory();
    final fileRepositoryPath =
        path.join(libraryDirectory.path, 'file_repository');

    return await DeclarativeDatabase.open(
      widget.databasePath ?? widget.databaseName,
      databaseFactory: databaseFactory,
      schema: schema,
      fileRepository: FilesystemFileRepository(fileRepositoryPath),
    );
  }

  void _setInitializationState({
    required bool isInitializing,
    Object? error,
    DeclarativeDatabase? database,
  }) {
    if (mounted) {
      setState(() {
        _isInitializing = isInitializing;
        _initializationError = error;
        if (database != null) {
          _database = database;
        }
      });
    }
  }

  @override
  Widget build(BuildContext context) {
    // Show error if database initialization failed
    if (_initializationError != null) {
      return ErrorWidget(_initializationError!);
    }

    // Show loading while initializing
    if (_isInitializing || _database == null) {
      return const SizedBox.shrink();
    }

    // Provide database to descendants
    return _DatabaseInheritedWidget(
      database: _database!,
      child: widget.child,
    );
  }
}

<!-- END FILE: declarative_sqlite_flutter/lib/src/database_provider.dart -->

<!-- BEGIN FILE: declarative_sqlite_flutter/lib/src/query_list_view.dart -->
import 'package:declarative_sqlite/declarative_sqlite.dart';
import 'package:flutter/gestures.dart';
import 'package:flutter/material.dart';
import 'dart:async';

class QueryListView<T> extends StatefulWidget {
  final DeclarativeDatabase? database;
  final void Function(QueryBuilder query) query;
  final T Function(Map<String, Object?>) mapper;
  final Widget Function(BuildContext context) loadingBuilder;
  final Widget Function(BuildContext context, Object error) errorBuilder;
  final Widget Function(BuildContext context, T record) itemBuilder;
  
  // ListView properties for Flutter SDK compatibility
  final Axis scrollDirection;
  final bool reverse;
  final ScrollController? controller;
  final bool? primary;
  final ScrollPhysics? physics;
  final bool shrinkWrap;
  final EdgeInsetsGeometry? padding;
  final double? itemExtent;
  final Widget? prototypeItem;
  final bool addAutomaticKeepAlives;
  final bool addRepaintBoundaries;
  final bool addSemanticIndexes;
  final double? cacheExtent;
  final int? semanticChildCount;
  final DragStartBehavior dragStartBehavior;
  final ScrollViewKeyboardDismissBehavior keyboardDismissBehavior;
  final String? restorationId;
  final Clip clipBehavior;

  const QueryListView({
    super.key,
    this.database,
    required this.query,
    required this.mapper,
    required this.loadingBuilder,
    required this.errorBuilder,
    required this.itemBuilder,
    // ListView properties with Flutter SDK defaults
    this.scrollDirection = Axis.vertical,
    this.reverse = false,
    this.controller,
    this.primary,
    this.physics,
    this.shrinkWrap = false,
    this.padding,
    this.itemExtent,
    this.prototypeItem,
    this.addAutomaticKeepAlives = true,
    this.addRepaintBoundaries = true,
    this.addSemanticIndexes = true,
    this.cacheExtent,
    this.semanticChildCount,
    this.dragStartBehavior = DragStartBehavior.start,
    this.keyboardDismissBehavior = ScrollViewKeyboardDismissBehavior.manual,
    this.restorationId,
    this.clipBehavior = Clip.hardEdge,
  });

  @override
  State<QueryListView<T>> createState() => _QueryListViewState<T>();
}

class _QueryListViewState<T> extends State<QueryListView<T>> {
  AdvancedStreamingQuery<T>? _streamingQuery;
  StreamSubscription<List<T>>? _subscription;
  List<T>? _currentData;
  Object? _currentError;
  bool _isLoading = true;

  @override
  void initState() {
    super.initState();
    _initializeStream();
  }

  @override
  void didUpdateWidget(QueryListView<T> oldWidget) {
    super.didUpdateWidget(oldWidget);
    
    // Check if database changed
    if (_hasDatabaseChanged(oldWidget)) {
      _handleDatabaseChange();
      return;
    }
    
    // Update query if we have an active streaming query
    _updateQueryIfNeeded();
  }

  bool _hasDatabaseChanged(QueryListView<T> oldWidget) {
    return widget.database != oldWidget.database;
  }

  void _handleDatabaseChange() {
    _disposeStream();
    _initializeStream();
  }

  void _updateQueryIfNeeded() {
    if (_streamingQuery != null && widget.database != null) {
      final newBuilder = _buildNewQuery();
      _updateStreamingQuery(newBuilder);
    }
  }

  QueryBuilder _buildNewQuery() {
    final newBuilder = QueryBuilder();
    widget.query(newBuilder);
    return newBuilder;
  }

  void _updateStreamingQuery(QueryBuilder newBuilder) {
    _streamingQuery!.updateQuery(
      newBuilder: newBuilder,
      newMapper: widget.mapper,
    );
  }

  void _initializeStream() {
    if (!_canInitializeStream()) {
      _setLoadingComplete();
      return;
    }

    final builder = _buildQuery();
    _createStreamingQuery(builder);
    _subscribeToStream();
  }

  bool _canInitializeStream() {
    return widget.database != null;
  }

  void _setLoadingComplete() {
    setState(() {
      _isLoading = false;
    });
  }

  QueryBuilder _buildQuery() {
    final builder = QueryBuilder();
    widget.query(builder);
    return builder;
  }

  void _createStreamingQuery(QueryBuilder builder) {
    _streamingQuery = AdvancedStreamingQuery.create(
      id: 'query_list_view_${DateTime.now().millisecondsSinceEpoch}',
      builder: builder,
      database: widget.database!,
      mapper: widget.mapper,
    );
  }

  void _subscribeToStream() {
    _subscription = _streamingQuery!.stream.listen(
      _handleStreamData,
      onError: _handleStreamError,
    );
  }

  void _handleStreamData(List<T> data) {
    if (mounted) {
      setState(() {
        _currentData = data;
        _currentError = null;
        _isLoading = false;
      });
    }
  }

  void _handleStreamError(Object error) {
    if (mounted) {
      setState(() {
        _currentData = null;
        _currentError = error;
        _isLoading = false;
      });
    }
  }

  void _disposeStream() {
    _subscription?.cancel();
    _subscription = null;
    _streamingQuery?.dispose();
    _streamingQuery = null;
    _currentData = null;
    _currentError = null;
    _isLoading = true;
  }

  @override
  void dispose() {
    _disposeStream();
    super.dispose();
  }

  @override
  Widget build(BuildContext context) {
    return _buildStateBasedWidget(context);
  }

  Widget _buildStateBasedWidget(BuildContext context) {
    // If no database is provided, show loading state
    if (widget.database == null) {
      return widget.loadingBuilder(context);
    }

    // Handle error state
    if (_currentError != null) {
      return widget.errorBuilder(context, _currentError!);
    }

    // Handle loading state
    if (_isLoading || _currentData == null) {
      return widget.loadingBuilder(context);
    }

    // Build the list with current data
    return _buildListView();
  }

  Widget _buildListView() {
    final items = _currentData!;
    return ListView.builder(
      // Core ListView.builder properties
      itemCount: items.length,
      itemBuilder: (context, index) => widget.itemBuilder(context, items[index]),
      
      // Pass through all ListView properties to maintain Flutter SDK compatibility
      scrollDirection: widget.scrollDirection,
      reverse: widget.reverse,
      controller: widget.controller,
      primary: widget.primary,
      physics: widget.physics,
      shrinkWrap: widget.shrinkWrap,
      padding: widget.padding,
      itemExtent: widget.itemExtent,
      prototypeItem: widget.prototypeItem,
      addAutomaticKeepAlives: widget.addAutomaticKeepAlives,
      addRepaintBoundaries: widget.addRepaintBoundaries,
      addSemanticIndexes: widget.addSemanticIndexes,
      cacheExtent: widget.cacheExtent,
      semanticChildCount: widget.semanticChildCount,
      dragStartBehavior: widget.dragStartBehavior,
      keyboardDismissBehavior: widget.keyboardDismissBehavior,
      restorationId: widget.restorationId,
      clipBehavior: widget.clipBehavior,
    );
  }
}

<!-- END FILE: declarative_sqlite_flutter/lib/src/query_list_view.dart -->

<!-- BEGIN FILE: declarative_sqlite_flutter/lib/src/server_sync_manager.dart -->
import 'package:declarative_sqlite/declarative_sqlite.dart';
import 'package:flutter/widgets.dart';
import 'database_provider.dart';

/// A widget that manages server synchronization using TaskScheduler.
/// 
/// This widget registers sync operations with the TaskScheduler for better
/// resource management and fair scheduling with other background tasks.
/// 
/// Example:
/// ```dart
/// ServerSyncManagerWidget(
///   retryStrategy: ExponentialBackoffRetry(),
///   syncInterval: Duration(minutes: 5),
///   onFetch: (database, tableTimestamps) async {
///     // Fetch data from server using delta timestamps
///   },
///   onSend: (operations) async {
///     // Send changes to server
///     return true; // Success
///   },
///   child: MyApp(),
/// )
/// ```
class ServerSyncManagerWidget extends StatefulWidget {
  final dynamic retryStrategy;
  final Duration syncInterval;
  final OnFetch onFetch;
  final OnSend onSend;
  final Widget child;
  final DeclarativeDatabase? database;
  final TaskScheduler? taskScheduler;

  const ServerSyncManagerWidget({
    super.key,
    required this.retryStrategy,
    this.syncInterval = const Duration(minutes: 5),
    required this.onFetch,
    required this.onSend,
    required this.child,
    this.database,
    this.taskScheduler,
  });

  @override
  State<ServerSyncManagerWidget> createState() => _ServerSyncManagerWidgetState();
}

class _ServerSyncManagerWidgetState extends State<ServerSyncManagerWidget> {
  ServerSyncManager? _syncManager;
  TaskScheduler? _scheduler;
  String? _syncTaskName;

  @override
  void initState() {
    super.initState();
    WidgetsBinding.instance.addPostFrameCallback((_) {
      _initializeSyncManager();
    });
  }

  @override
  void didUpdateWidget(ServerSyncManagerWidget oldWidget) {
    super.didUpdateWidget(oldWidget);
    
    // If configuration changed, restart sync manager
    if (_shouldRestartSyncManager(oldWidget)) {
      _disposeSyncManager();
      _initializeSyncManager();
    }
  }

  bool _shouldRestartSyncManager(ServerSyncManagerWidget oldWidget) {
    return widget.syncInterval != oldWidget.syncInterval ||
        widget.onFetch != oldWidget.onFetch ||
        widget.onSend != oldWidget.onSend ||
        widget.database != oldWidget.database ||
        widget.taskScheduler != oldWidget.taskScheduler;
  }

  @override
  void dispose() {
    _disposeSyncManager();
    super.dispose();
  }

  void _initializeSyncManager() {
    final database = _getDatabaseInstance();
    
    if (database == null) {
      // No database available, can't initialize sync
      return;
    }

    try {
      _createSyncManagerAndScheduleTask(database);
    } catch (error) {
      _handleSyncManagerError(error);
    }
  }

  DeclarativeDatabase? _getDatabaseInstance() {
    return widget.database ?? DatabaseProvider.maybeOf(context);
  }

  void _createSyncManagerAndScheduleTask(DeclarativeDatabase database) {
    // Create sync manager without internal timer
    _syncManager = ServerSyncManager(
      db: database,
      retryStrategy: widget.retryStrategy,
      onFetch: widget.onFetch,
      onSend: widget.onSend,
    );

    // Get or create task scheduler
    _scheduler = widget.taskScheduler ?? TaskScheduler.withConfig(
      TaskSchedulerConfig.resourceConstrained
    );

    // Initialize scheduler with database for persistent tracking
    _scheduler!.initializeWithDatabase(database);

    // Schedule recurring sync task
    _syncTaskName = 'server_sync_${database.hashCode}';
    _scheduler!.scheduleRecurringTask(
      name: _syncTaskName!,
      task: () => _syncManager!.performSync(),
      interval: widget.syncInterval,
      priority: TaskPriority.normal,
    );

    // Perform initial sync
    _syncManager!.performSync();
  }

  void _handleSyncManagerError(Object error) {
    debugPrint('Failed to initialize ServerSyncManager: $error');
  }

  void _disposeSyncManager() {
    if (_syncTaskName != null && _scheduler != null) {
      _scheduler!.cancelTask(_syncTaskName!);
    }
    _syncManager = null;
    _scheduler = null;
    _syncTaskName = null;
  }

  @override
  Widget build(BuildContext context) {
    return widget.child;
  }
}

<!-- END FILE: declarative_sqlite_flutter/lib/src/server_sync_manager.dart -->

<!-- BEGIN FILE: declarative_sqlite_flutter/pubspec.yaml -->
name: declarative_sqlite_flutter
description: A Flutter package that provides seamless integration of declarative_sqlite with Flutter widgets, forms, and UI patterns.
version: 1.0.0
publish_to: none
repository: https://github.com/graknol/declarative_sqlite

environment:
  sdk: ^3.5.3
  flutter: ">=3.10.0"

dependencies:
  flutter:
    sdk: flutter
  declarative_sqlite:
    path: ../declarative_sqlite
  sqflite: ^2.3.4
  equatable: ^2.0.5

dev_dependencies:
  flutter_test:
    sdk: flutter
  flutter_lints: ^4.0.0
  # Testing dependencies
  test: ^1.24.0
  mockito: ^5.4.4
  build_runner: ^2.4.13
  sqflite_common_ffi: ^2.3.6

flutter:
  {}
  # This package is a Flutter library

<!-- END FILE: declarative_sqlite_flutter/pubspec.yaml -->

<!-- BEGIN FILE: declarative_sqlite_generator/build.yaml -->
builders:
  declarative_sqlite_generator:
    import: "package:declarative_sqlite_generator/src/builder.dart"
    builder_factories: ["declarativeSqliteGenerator"]
    build_extensions: { ".dart": [".g.dart"] }
    auto_apply: dependents
    build_to: source

  registration_collect_builder:
    import: "package:declarative_sqlite_generator/src/builder.dart"
    builder_factories: ["registrationCollectBuilder"]
    build_extensions: { ".dart": [".registration.json"] }
    auto_apply: dependents
    build_to: cache

  registration_aggregate_builder:
    import: "package:declarative_sqlite_generator/src/builder.dart"
    builder_factories: ["registrationAggregateBuilder"]
    build_extensions: { r"$package$": ["lib/generated_registrations.dart"] }
    auto_apply: root_package
    build_to: source

<!-- END FILE: declarative_sqlite_generator/build.yaml -->

<!-- BEGIN FILE: declarative_sqlite_generator/lib/declarative_sqlite_generator.dart -->
library declarative_sqlite_generator;

export 'src/builder.dart';
export 'src/registration_builder.dart';

<!-- END FILE: declarative_sqlite_generator/lib/declarative_sqlite_generator.dart -->

<!-- BEGIN FILE: declarative_sqlite_generator/lib/src/builder.dart -->
import 'package:analyzer/dart/element/element.dart';
import 'package:build/build.dart';
import 'package:declarative_sqlite/declarative_sqlite.dart';
import 'package:source_gen/source_gen.dart';

import 'registration_builder.dart';

Builder declarativeSqliteGenerator(BuilderOptions options) =>
    PartBuilder([DeclarativeSqliteGenerator()], '.g.dart');

Builder registrationCollectBuilder(BuilderOptions options) =>
    RegistrationCollectBuilder();

Builder registrationAggregateBuilder(BuilderOptions options) =>
    RegistrationAggregateBuilder();

class DeclarativeSqliteGenerator extends GeneratorForAnnotation<GenerateDbRecord> {
  @override
  String generateForAnnotatedElement(
      Element element, ConstantReader annotation, BuildStep buildStep) {
    if (element is! ClassElement) {
      throw InvalidGenerationSourceError(
        '`@GenerateDbRecord` can only be used on classes.',
        element: element,
      );
    }

    final buffer = StringBuffer();
    final tableName = annotation.read('tableName').stringValue;

    // This is a placeholder. A real implementation would need a way
    // to access the schema definition. For this example, we'll
    // assume a function `createAppSchema()` exists and can be used.
    // This part of the logic is complex and would require more robust
    // schema discovery.
    final schema = createAppSchema();
    final table = schema.tables.firstWhere((t) => t.name == tableName,
        orElse: () => throw InvalidGenerationSourceError(
            'Table "$tableName" not found in schema.',
            element: element));

    buffer.writeln(_generateRecordClass(element, table));
    buffer.writeln();

    return buffer.toString();
  }

  /// Generates typed properties extension and simple fromMap method
  String _generateRecordClass(ClassElement element, Table schemaTable) {
    final className = element.name;
    final buffer = StringBuffer();

    // Generate extension for typed properties
    buffer.writeln('/// Generated typed properties for $className');
    buffer.writeln('extension ${className}Generated on $className {');

    _generateGettersAndSetters(buffer, schemaTable);

    // Add the fromMap method directly in the extension
    buffer.writeln();
    buffer.writeln('  /// Generated fromMap factory method');
    buffer.writeln(
        '  static $className fromMap(Map<String, Object?> data, DeclarativeDatabase database) {');
    buffer.writeln('    return $className(data, database);');
    buffer.writeln('  }');

    buffer.writeln('}');

    return buffer.toString();
  }

  /// Generates getters and setters based on the actual schema table
  void _generateGettersAndSetters(StringBuffer buffer, Table table) {
    final primaryKeyColumns =
        table.keys.where((k) => k.isPrimary).expand((k) => k.columns).toSet();

    buffer.writeln('  // Generated getters and setters');
    for (final col in table.columns) {
      final propertyName = _camelCase(col.name);
      final dartType = _getDartTypeForColumn(col.logicalType, col.isNotNull);
      final getterMethod =
          _getGetterMethodForColumn(col.logicalType, col.isNotNull);

      buffer.writeln('  /// Gets the ${col.name} column value.');
      buffer.writeln(
          '  $dartType get $propertyName => $getterMethod(\'${col.name}\');');

      // Make properties from primary keys immutable (no setter)
      if (primaryKeyColumns.contains(col.name)) {
        continue;
      }

      final setterMethod = _getSetterMethodForColumn(col.logicalType);
      buffer.writeln('  /// Sets the ${col.name} column value.');
      buffer.writeln(
          '  set $propertyName($dartType value) => $setterMethod(\'${col.name}\', value);');
      buffer.writeln();
    }
  }

  /// Gets the Dart type for a column type
  String _getDartTypeForColumn(String logicalType, bool notNull) {
    final baseType = switch (logicalType) {
      'text' || 'guid' => 'String',
      'integer' => 'int',
      'real' => 'double',
      'date' => 'DateTime',
      'fileset' => 'FilesetField',
      _ => 'Object',
    };

    return notNull ? baseType : '$baseType?';
  }

  /// Gets the getter method name for a column type
  String _getGetterMethodForColumn(String logicalType, bool notNull) {
    return switch (logicalType) {
      'text' || 'guid' => notNull ? 'getTextNotNull' : 'getText',
      'integer' => notNull ? 'getIntegerNotNull' : 'getInteger',
      'real' => notNull ? 'getRealNotNull' : 'getReal',
      'date' => notNull ? 'getDateTimeNotNull' : 'getDateTime',
      'fileset' => notNull ? 'getFilesetFieldNotNull' : 'getFilesetField',
      _ => 'getValue',
    };
  }

  /// Gets the setter method name for a column type
  String _getSetterMethodForColumn(String logicalType) {
    return switch (logicalType) {
      'text' || 'guid' => 'setText',
      'integer' => 'setInteger',
      'real' => 'setReal',
      'date' => 'setDateTime',
      'fileset' => 'setFilesetField',
      _ => 'setValue',
    };
  }

  /// Converts snake_case to camelCase
  String _camelCase(String input) {
    final parts = input.split('_');
    if (parts.isEmpty) return input;

    final result = parts[0].toLowerCase() +
        parts.skip(1)
            .map((word) => word.isEmpty ? '' : word[0].toUpperCase() + word.substring(1).toLowerCase())
            .join('');

    return result;
  }
}

// A placeholder function to make the generator compile.
// In a real-world scenario, schema information would be accessed differently,
// possibly by analyzing the source code where the schema is defined.
Schema createAppSchema() {
  final builder = SchemaBuilder();
  builder.table('users', (table) {
    table.integer('id').notNull();
    table.text('name').notNull();
    table.text('email');
    table.integer('age');
    table.date('created_at').notNull();
    table.date('updated_at').lww();
    table.key(['id']).primary();
  });
  builder.table('posts', (table) {
    table.integer('id').notNull();
    table.integer('user_id').notNull();
    table.text('title').notNull();
    table.text('content');
    table.date('published_at');
    table.integer('is_published').defaultsTo(0);
    table.key(['id']).primary();
  });
  builder.table('comments', (table) {
    table.integer('id').notNull();
    table.integer('post_id').notNull();
    table.integer('user_id').notNull();
    table.text('comment').notNull();
    table.date('created_at').notNull();
    table.key(['id']).primary();
  });
  return builder.build();
}

<!-- END FILE: declarative_sqlite_generator/lib/src/builder.dart -->

<!-- BEGIN FILE: declarative_sqlite_generator/lib/src/registration_builder.dart -->
import 'dart:async';
import 'dart:convert';

import 'package:analyzer/dart/constant/value.dart';
import 'package:analyzer/dart/element/element.dart';
import 'package:build/build.dart';
import 'package:glob/glob.dart';

/// Builder that collects all @RegisterFactory classes and generates a single registration file
class RegistrationCollectBuilder implements Builder {
  @override
  final buildExtensions = const {
    '.dart': ['.registration.json']
  };

  @override
  Future<void> build(BuildStep buildStep) async {
    final registeredClasses = <RegistrationInfo>[];
    final library = await buildStep.inputLibrary;

    // Look for classes with @RegisterFactory annotation
    for (final element in library.topLevelElements.whereType<ClassElement>()) {
      if (_extendsDbRecord(element)) {
        final dbRecordAnnotation = _getDbRecordAnnotation(element);
        final registerFactoryAnnotation = _getRegisterFactoryAnnotation(element);
        
        if (dbRecordAnnotation != null && registerFactoryAnnotation != null) {
          final tableName = _getTableNameFromAnnotation(dbRecordAnnotation);
          if (tableName != null) {
            registeredClasses.add(RegistrationInfo(
              className: element.name,
              tableName: tableName,
              libraryUri: library.identifier,
            ));
          }
        }
      }
    }
    
    // Only create output if we found registered classes
    if (registeredClasses.isNotEmpty) {
      final output = registeredClasses.map((info) => info.toJson()).toList();
      final outputId = buildStep.inputId.changeExtension('.registration.json');
      await buildStep.writeAsString(outputId, jsonEncode(output));
    }
  }

  /// Checks if the class extends DbRecord
  bool _extendsDbRecord(ClassElement element) {
    ClassElement? current = element;
    while (current != null) {
      if (current.supertype?.element?.name == 'DbRecord') {
        return true;
      }
      final supertypeElement = current.supertype?.element;
      if (supertypeElement is ClassElement) {
        current = supertypeElement;
      } else {
        current = null;
      }
    }
    return false;
  }

  /// Gets the @GenerateDbRecord annotation
  DartObject? _getDbRecordAnnotation(ClassElement element) {
    for (final metadata in element.metadata) {
      final annotation = metadata.computeConstantValue();
      if (annotation?.type?.element?.name == 'GenerateDbRecord') {
        return annotation;
      }
    }
    return null;
  }

  /// Gets the @RegisterFactory annotation
  DartObject? _getRegisterFactoryAnnotation(ClassElement element) {
    for (final metadata in element.metadata) {
      final annotation = metadata.computeConstantValue();
      if (annotation?.type?.element?.name == 'RegisterFactory') {
        return annotation;
      }
    }
    return null;
  }

  /// Extracts the table name from @GenerateDbRecord annotation
  String? _getTableNameFromAnnotation(DartObject annotation) {
    return annotation.getField('tableName')?.toStringValue();
  }
}

/// Builder that aggregates all registration info and generates a single registration file
class RegistrationAggregateBuilder implements Builder {
  @override
  final buildExtensions = const {
    r'$lib$': ['generated_registrations.dart']
  };

  @override
  Future<void> build(BuildStep buildStep) async {
    final allRegistrations = <RegistrationInfo>{};
    
    // Find all registration JSON files across the entire project
    await for (final input in buildStep.findAssets(Glob('**/*.registration.json'))) {
      final content = await buildStep.readAsString(input);
      final List<dynamic> registrations = jsonDecode(content);
      
      for (final reg in registrations) {
        allRegistrations.add(RegistrationInfo.fromJson(reg));
      }
    }
    
    if (allRegistrations.isNotEmpty) {
      final generatedContent = generateRegistrationFile(allRegistrations);
      final outputId = AssetId(buildStep.inputId.package, 'lib/generated_registrations.dart');
      await buildStep.writeAsString(outputId, generatedContent);
    }
  }

  String generateRegistrationFile(Set<RegistrationInfo> registrations) {
    final buffer = StringBuffer();
    
    // Add imports
    buffer.writeln('// GENERATED CODE - DO NOT MODIFY BY HAND');
    buffer.writeln('// Generated by declarative_sqlite_generator');
    buffer.writeln();
    buffer.writeln("import 'package:declarative_sqlite/declarative_sqlite.dart';");
    
    // Add imports for each registered class
    final importedLibraries = <String>{};
    for (final reg in registrations) {
      // Convert library identifier to a package import if possible
      String importPath = reg.libraryUri;
      if (importPath.startsWith('asset:')) {
        // Example: asset:my_package/lib/src/models.dart -> package:my_package/src/models.dart
        final parts = importPath.split('/');
        if (parts.length > 2 && parts[1] == 'lib') {
          importPath = 'package:${parts[0].substring('asset:'.length)}/${parts.sublist(2).join('/')}';
        }
      }
      
      if (importedLibraries.add(importPath)) {
        buffer.writeln("import '$importPath';");
      }
    }
    buffer.writeln();
    
    // Generate the registration function
    buffer.writeln('/// Auto-generated factory registration function');
    buffer.writeln('/// Call this function to register all annotated record factories');
    buffer.writeln('void registerAllGeneratedFactories(DeclarativeDatabase database) {');
    
    for (final reg in registrations) {
      buffer.writeln('  RecordMapFactoryRegistry.register<${reg.className}>((data) => ${reg.className}(data, database));');
    }
    
    buffer.writeln('}');
    
    return buffer.toString();
  }
}

/// Information about a class that should be registered
class RegistrationInfo {
  final String className;
  final String tableName;
  final String libraryUri;

  RegistrationInfo({
    required this.className,
    required this.tableName,
    required this.libraryUri,
  });

  Map<String, dynamic> toJson() => {
    'className': className,
    'tableName': tableName,
    'libraryUri': libraryUri,
  };

  factory RegistrationInfo.fromJson(Map<String, dynamic> json) => RegistrationInfo(
    className: json['className'],
    tableName: json['tableName'],
    libraryUri: json['libraryUri'],
  );
}
<!-- END FILE: declarative_sqlite_generator/lib/src/registration_builder.dart -->

<!-- BEGIN FILE: declarative_sqlite_generator/pubspec.yaml -->
name: declarative_sqlite_generator
description: A build generator that generates data classes for interacting with table rows and view rows from declarative_sqlite schemas.
version: 1.0.0
repository: https://github.com/graknol/declarative_sqlite
publish_to: none

environment:
  sdk: ^3.5.3

dependencies:
  # Core build system dependencies
  build: ^2.4.1
  build_config: ^1.1.1
  source_gen: ^1.5.0
  analyzer: ^6.4.1
  glob: ^2.1.2

  # Code generation utilities
  code_builder: ^4.10.0
  dart_style: ^2.3.6

  # Reference to the main library for schema metadata
  declarative_sqlite:
    path: ../declarative_sqlite

dev_dependencies:
  lints: ^4.0.0
  test: ^1.24.0
  build_runner: ^2.4.7
  build_test: ^2.2.0
  sqflite_common_ffi: ^2.3.4+4 # For examples

<!-- END FILE: declarative_sqlite_generator/pubspec.yaml -->

<!-- BEGIN FILE: ifs_cloud_auth/lib/ifs_cloud_auth.dart -->
library ifs_cloud_auth;

export 'src/ifs_cloud_auth_config.dart';
export 'src/ifs_cloud_auth_provider.dart';

<!-- END FILE: ifs_cloud_auth/lib/ifs_cloud_auth.dart -->

<!-- BEGIN FILE: ifs_cloud_auth/lib/src/ifs_cloud_auth_config.dart -->
class IfsCloudAuthConfig {
  final String clientId;
  final String domain;
  final String realm;

  const IfsCloudAuthConfig({
    required this.clientId,
    required this.domain,
    required this.realm,
  });
}

<!-- END FILE: ifs_cloud_auth/lib/src/ifs_cloud_auth_config.dart -->

<!-- BEGIN FILE: ifs_cloud_auth/lib/src/ifs_cloud_auth_provider.dart -->
import 'package:flutter/widgets.dart';
import 'package:ifs_cloud_auth/src/ifs_cloud_auth_config.dart';

class IfsCloudAuthProvider extends StatelessWidget {
  final IfsCloudAuthConfig config;
  final Widget child;

  const IfsCloudAuthProvider({
    super.key,
    required this.config,
    required this.child,
  });

  @override
  Widget build(BuildContext context) {
    // Authentication logic will be added later
    return child;
  }
}

<!-- END FILE: ifs_cloud_auth/lib/src/ifs_cloud_auth_provider.dart -->

<!-- BEGIN FILE: ifs_cloud_auth/pubspec.yaml -->
name: ifs_cloud_auth
description: A new Flutter package for IFS Cloud authentication.
version: 0.0.1
publish_to: "none"

environment:
  sdk: ">=3.0.0 <4.0.0"
  flutter: ">=1.17.0"

dependencies:
  flutter:
    sdk: flutter
  flutter_appauth: ^10.0.0

dev_dependencies:
  flutter_test:
    sdk: flutter
  lints: ^4.0.0

<!-- END FILE: ifs_cloud_auth/pubspec.yaml -->

---
Generated with llmifier v0.2.2
Created by Software Engineering Philipp Gerber
Repository: https://github.com/PhilippHGerber/llmifier
Package: https://pub.dev/packages/llmifier
