# Project Documentation

Generated by llmifier on: 2025-09-25T14:07:29
Extraction Mode: full
Project Type: dart

---

<!-- BEGIN FILE: README.md -->
# Declarative SQLite

A comprehensive Dart and Flutter library ecosystem for declarative SQLite schema management and database operations with real-time synchronization capabilities.

## Overview

Declarative SQLite provides a fluent, type-safe API for defining database schemas and managing data with automatic migrations, streaming queries, and built-in synchronization features. The ecosystem consists of two main packages that work together seamlessly.

## Packages

### üì¶ Core Library (`declarative_sqlite`)

The foundation package providing declarative schema definition and database operations.

**Key Features:**
- **Declarative Schema Definition**: Define tables, columns, and relationships using a fluent builder API
- **Automatic Migration**: Schema changes are automatically applied to the database
- **Streaming Queries**: Real-time reactive queries that automatically update when data changes
- **File Management**: Built-in support for file attachments with FilesetField
- **Synchronization**: Conflict-free synchronization with remote servers using Last-Writer-Wins (LWW)
- **Type Safety**: Full type safety with proper column type definitions

### üì± Flutter Integration (`declarative_sqlite_flutter`)

Flutter-specific widgets and utilities that integrate seamlessly with the core library.

**Key Features:**
- **DatabaseProvider**: InheritedWidget for managing database lifecycle
- **QueryListView**: Reactive ListView that automatically updates when database changes
- **ServerSyncManagerWidget**: Widget for managing background synchronization
- **Seamless Integration**: Works with any Flutter app architecture

## Quick Start

### Core Library (Dart)

```dart
import 'package:declarative_sqlite/declarative_sqlite.dart';

// Define your schema
void buildSchema(SchemaBuilder builder) {
  builder.table('users', (table) {
    table.guid('id').notNull();
    table.text('name').notNull();
    table.text('email').notNull();
    table.date('created_at').notNull();
    table.key(['id']).primary();
  });
}

// Initialize database
final database = DeclarativeDatabase(
  schema: buildSchema,
  path: 'my_app.db',
);

// Perform operations
await database.insert('users', {
  'id': 'user-123',
  'name': 'John Doe',
  'email': 'john@example.com',
  'created_at': DateTime.now().toIso8601String(),
});

// Query data
final users = await database.query('users');

// Stream live updates
final userStream = database.streamQuery('users');
userStream.listen((users) {
  print('Users updated: ${users.length} total users');
});
```

### Flutter Integration

```dart
import 'package:flutter/material.dart';
import 'package:declarative_sqlite_flutter/declarative_sqlite_flutter.dart';

class MyApp extends StatelessWidget {
  @override
  Widget build(BuildContext context) {
    return MaterialApp(
      home: DatabaseProvider(
        schema: buildSchema,
        databaseName: 'app.db',
        child: UserListScreen(),
      ),
    );
  }
}

class UserListScreen extends StatelessWidget {
  @override
  Widget build(BuildContext context) {
    return Scaffold(
      appBar: AppBar(title: Text('Users')),
      body: QueryListView<User>(
        database: DatabaseProvider.of(context),
        query: (q) => q.from('users').orderBy('name'),
        mapper: User.fromMap,
        itemBuilder: (context, user) => ListTile(
          title: Text(user.name),
          subtitle: Text(user.email),
        ),
      ),
      floatingActionButton: FloatingActionButton(
        onPressed: () => _addUser(context),
        child: Icon(Icons.add),
      ),
    );
  }
  
  Future<void> _addUser(BuildContext context) async {
    final db = DatabaseProvider.of(context);
    await db.insert('users', {
      'id': 'user-${DateTime.now().millisecondsSinceEpoch}',
      'name': 'New User',
      'email': 'user@example.com',
      'created_at': DateTime.now().toIso8601String(),
    });
  }
}

class User {
  final String id;
  final String name;
  final String email;
  final DateTime createdAt;

  User({required this.id, required this.name, required this.email, required this.createdAt});

  static User fromMap(Map<String, Object?> map) {
    return User(
      id: map['id'] as String,
      name: map['name'] as String,
      email: map['email'] as String,
      createdAt: DateTime.parse(map['created_at'] as String),
    );
  }
}
```

## Schema Definition

The schema builder provides a fluent API for defining your database structure:

```dart
void buildSchema(SchemaBuilder builder) {
  // Define a users table
  builder.table('users', (table) {
    table.guid('id').notNull();
    table.text('name').notNull();
    table.text('email').notNull();
    table.integer('age').min(0);
    table.date('created_at').notNull();
    table.date('updated_at');
    table.key(['id']).primary();
  });

  // Define a posts table with relationships
  builder.table('posts', (table) {
    table.guid('id').notNull();
    table.guid('user_id').notNull();
    table.text('title').notNull();
    table.text('content');
    table.date('created_at').notNull();
    table.key(['id']).primary();
    // Foreign key relationships are handled at the application level
  });

  // Define a view for post summaries
  builder.view('post_summaries', (view) {
    view.select('posts.id, posts.title, users.name as author')
        .from('posts')
        .join('users', 'posts.user_id = users.id');
  });
}
```

## Column Types

The library supports various column types with built-in validation:

- **`text(name)`**: Text/string columns with optional constraints
- **`integer(name)`**: Integer columns with min/max validation
- **`real(name)`**: Real number (double) columns with min/max validation
- **`date(name)`**: DateTime columns (stored as ISO 8601 strings)
- **`guid(name)`**: GUID/UUID columns for unique identifiers
- **`fileset(name)`**: File attachment columns for managing file collections

All columns support:
- **`.notNull()`**: Make column required
- **`.min(value)`** / **`.max(value)`**: Set validation constraints
- **`.defaultValue(value)`**: Set default values

## File Management

FilesetField provides managed file attachments:

```dart
// Define a table with file attachments
builder.table('documents', (table) {
  table.guid('id').notNull();
  table.text('title').notNull();
  table.fileset('attachments').notNull(); // Required fileset
  table.fileset('gallery'); // Optional fileset
  table.key(['id']).primary();
});

// Work with files in your data models
class Document {
  final String id;
  final String title;
  final FilesetField attachments;
  final FilesetField? gallery;

  static Document fromMap(Map<String, Object?> map, DeclarativeDatabase db) {
    return Document(
      id: map['id'] as String,
      title: map['title'] as String,
      attachments: DataMappingUtils.filesetFieldFromValue(map['attachments'], db)!,
      gallery: DataMappingUtils.filesetFieldFromValue(map['gallery'], db),
    );
  }
}

// Use FilesetField methods
final document = documents.first;
final fileId = await document.attachments.addFile('report.pdf', pdfBytes);
final files = await document.attachments.getFiles();
await document.attachments.deleteFile(fileId);
```

## Synchronization

Built-in synchronization with conflict resolution:

```dart
// Setup sync in Flutter
ServerSyncManagerWidget(
  fetchInterval: Duration(minutes: 2),
  onFetch: (database, table, lastSynced) async {
    // Fetch updates from your server
    final updates = await apiClient.fetchUpdates(table, lastSynced);
    for (final update in updates) {
      await database.insert(table, update);
    }
  },
  onSend: (operations) async {
    // Send local changes to server
    return await apiClient.sendChanges(operations);
  },
  child: MyApp(),
)

// Sync operations are automatically tracked
await database.insert('users', userData); // Will be synced automatically
await database.update('users', updates, where: 'id = ?', whereArgs: [userId]);
await database.delete('users', where: 'id = ?', whereArgs: [userId]);
```

## Installation

Add the packages to your `pubspec.yaml`:

```yaml
dependencies:
  # Core library (required)
  declarative_sqlite:
    path: declarative_sqlite
    
  # Flutter integration (for Flutter apps)
  declarative_sqlite_flutter:
    path: declarative_sqlite_flutter
    
  # SQLite driver (choose one)
  sqflite: ^2.3.0  # For Flutter apps
  # OR
  sqflite_common_ffi: ^2.3.0  # For standalone Dart apps
```

## Examples

Complete examples are available in each package:

- **Core Library**: [Core usage examples](declarative_sqlite/example/)
- **Flutter Integration**: [Flutter app examples](declarative_sqlite_flutter/example/)

## Architecture

```
‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
‚îÇ        Flutter Application         ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ    declarative_sqlite_flutter      ‚îÇ
‚îÇ  ‚Ä¢ DatabaseProvider                ‚îÇ
‚îÇ  ‚Ä¢ QueryListView                   ‚îÇ
‚îÇ  ‚Ä¢ ServerSyncManagerWidget         ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ       declarative_sqlite           ‚îÇ
‚îÇ  ‚Ä¢ Schema Definition               ‚îÇ
‚îÇ  ‚Ä¢ DeclarativeDatabase             ‚îÇ
‚îÇ  ‚Ä¢ Streaming Queries               ‚îÇ
‚îÇ  ‚Ä¢ Sync Management                 ‚îÇ
‚îÇ  ‚Ä¢ File Management                 ‚îÇ
‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
‚îÇ          SQLite Database           ‚îÇ
‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò
```

## Development

### Prerequisites
- Dart SDK 3.5.3 or later
- Flutter SDK (for Flutter package)

### Building Core Library
```bash
cd declarative_sqlite
dart pub get
dart test
dart analyze
```

### Building Flutter Library
```bash
cd declarative_sqlite_flutter
flutter pub get
flutter test
flutter analyze
```

## Contributing

1. Fork the repository
2. Create a feature branch
3. Make your changes
4. Add tests for new functionality
5. Ensure all tests pass
6. Submit a pull request

## License

This project is licensed under the MIT License - see the [LICENSE](LICENSE) file for details.
<!-- END FILE: README.md -->

<!-- BEGIN FILE: LICENSE -->
MIT License

Copyright (c) 2025 Sindre van der Linden

Permission is hereby granted, free of charge, to any person obtaining a copy
of this software and associated documentation files (the "Software"), to deal
in the Software without restriction, including without limitation the rights
to use, copy, modify, merge, publish, distribute, sublicense, and/or sell
copies of the Software, and to permit persons to whom the Software is
furnished to do so, subject to the following conditions:

The above copyright notice and this permission notice shall be included in all
copies or substantial portions of the Software.

THE SOFTWARE IS PROVIDED "AS IS", WITHOUT WARRANTY OF ANY KIND, EXPRESS OR
IMPLIED, INCLUDING BUT NOT LIMITED TO THE WARRANTIES OF MERCHANTABILITY,
FITNESS FOR A PARTICULAR PURPOSE AND NONINFRINGEMENT. IN NO EVENT SHALL THE
AUTHORS OR COPYRIGHT HOLDERS BE LIABLE FOR ANY CLAIM, DAMAGES OR OTHER
LIABILITY, WHETHER IN AN ACTION OF CONTRACT, TORT OR OTHERWISE, ARISING FROM,
OUT OF OR IN CONNECTION WITH THE SOFTWARE OR THE USE OR OTHER DEALINGS IN THE
SOFTWARE.

<!-- END FILE: LICENSE -->

<!-- BEGIN FILE: declarative_sqlite/analysis_options.yaml -->
# This file configures the static analysis results for your project (errors,
# warnings, and lints).
#
# This enables the 'recommended' set of lints from `package:lints`.
# This set helps identify many issues that may lead to problems when running
# or consuming Dart code, and enforces writing Dart using a single, idiomatic
# style and format.
#
# If you want a smaller set of lints you can change this to specify
# 'package:lints/core.yaml'. These are just the most critical lints
# (the recommended set includes the core lints).
# The core lints are also what is used by pub.dev for scoring packages.

include: package:lints/recommended.yaml

# Uncomment the following section to specify additional rules.

# linter:
#   rules:
#     - camel_case_types

# analyzer:
#   exclude:
#     - path/to/excluded/files/**

# For more information about the core and recommended set of lints, see
# https://dart.dev/go/core-lints

# For additional information about configuring this file, see
# https://dart.dev/guides/language/analysis-options

<!-- END FILE: declarative_sqlite/analysis_options.yaml -->

<!-- BEGIN FILE: declarative_sqlite/lib/declarative_sqlite.dart -->
/// A declarative SQLite library for Dart.
///
/// This library provides a fluent, declarative, and type-safe way to define
/// and interact with a SQLite database.
library;

// Core annotations
export 'src/annotations/generate_db_record.dart';

// Query builders
export 'src/builders/analysis_context.dart';
export 'src/builders/column_builder.dart';
export 'src/builders/query_column.dart';
export 'src/builders/schema_builder.dart';
export 'src/builders/query_builder.dart';
export 'src/builders/query_dependencies.dart';
export 'src/builders/where_clause.dart';

// Utilities
export 'src/utils/value_serializer.dart';

// Core database classes
export 'src/declarative_database.dart';
export 'src/data_mapping.dart';
export 'src/db_record.dart';
export 'src/record_factory.dart';
export 'src/record_map_factory_registry.dart';
export 'src/files/filesystem_file_repository.dart';

// Schema classes
export 'src/schema/db_table.dart';
export 'src/schema/schema.dart';

// Streaming queries
export 'src/streaming/query_dependency_analyzer.dart';
export 'src/streaming/streaming_query.dart';
export 'src/streaming/query_stream_manager.dart';

// Synchronization
export 'src/sync/server_sync_manager.dart';
export 'src/scheduling/task_scheduler.dart';
<!-- END FILE: declarative_sqlite/lib/declarative_sqlite.dart -->

<!-- BEGIN FILE: declarative_sqlite/lib/src/annotations/generate_db_record.dart -->
/// Annotation to mark a class for DbRecord code generation.
///
/// Classes annotated with @GenerateDbRecord will have typed getters and setters
/// generated automatically based on the table schema.
///
/// Example:
/// ```dart
/// @GenerateDbRecord('users')
/// @RegisterFactory()  // Optional: for automatic factory registration
/// class User extends DbRecord {
///   User(Map<String, Object?> data, DeclarativeDatabase database)
///       : super(data, 'users', database);
///
///   // Optional redirect to generated extension
///   static User fromMap(Map<String, Object?> data, DeclarativeDatabase database) {
///     return UserGenerated.fromMap(data, database);
///   }
/// }
/// ```
class GenerateDbRecord {
  /// The name of the database table this record represents.
  final String tableName;

  /// Creates a GenerateDbRecord annotation.
  ///
  /// [tableName] must match a table defined in your database schema.
  const GenerateDbRecord(this.tableName);
}
<!-- END FILE: declarative_sqlite/lib/src/annotations/generate_db_record.dart -->

<!-- BEGIN FILE: declarative_sqlite/lib/src/builders/aliased.dart -->
class Aliased<T> {
  final T expression;
  final String? alias;

  const Aliased(this.expression, this.alias);

  @override
  String toString() {
    return alias != null ? '$expression AS $alias' : expression.toString();
  }
}

<!-- END FILE: declarative_sqlite/lib/src/builders/aliased.dart -->

<!-- BEGIN FILE: declarative_sqlite/lib/src/builders/analysis_context.dart -->
import '../utils/string_utils.dart';

/// Interface for schema information to resolve column-to-table mappings
abstract class SchemaProvider {
  /// Returns true if the specified table contains the specified column
  bool tableHasColumn(String tableName, String columnName);
  
  /// Gets all tables that contain the specified column
  List<String> getTablesWithColumn(String columnName);
}

/// Represents the analysis context for dependency resolution
///
/// Acts as a stack of available table/view names and aliases that columns
/// can be qualified with. When collisions occur, the closest (most recently added)
/// one wins according to SQL scoping rules.
class AnalysisContext {
  final List<_ContextLevel> _levels = [];
  final SchemaProvider? _schema;

  /// Creates a new analysis context
  AnalysisContext([this._schema]);

  /// Adds a new context level (e.g., for subqueries)
  void pushLevel() {
    _levels.add(_ContextLevel());
  }

  /// Removes the current context level
  void popLevel() {
    if (_levels.isNotEmpty) {
      _levels.removeLast();
    }
  }

  /// Adds a table or view to the current context level
  void addTable(String name, {String? alias}) {
    if (_levels.isEmpty) {
      pushLevel();
    }
    _addTable(alias, name);
    _addTable(name, name);
  }

  void _addTable(String? key, String value) {
    if (isNullOrWhitespace(key) || isNullOrWhitespace(value)) {
      return;
    }
    _levels.last.tables[key!] = value;
  }

  /// Resolves a table/alias name to its full table name
  /// Returns null if not found in any context level
  String? resolveTable(String nameOrAlias) {
    // Search from most recent level to oldest (SQL scoping rules)
    for (int i = _levels.length - 1; i >= 0; i--) {
      final table = _levels[i].tables[nameOrAlias];
      if (table != null) {
        return table;
      }
    }
    return null;
  }

  /// Gets all available table names and aliases in the current context
  Map<String, String> getAllTables() {
    final result = <String, String>{};

    // Start from oldest level to newest so newer ones override older ones
    for (final level in _levels) {
      result.addAll(level.tables);
    }

    return result;
  }

  /// Gets the primary table from the outermost context (FROM clause)
  String? get primaryTable {
    if (_levels.isEmpty) return null;

    final outermost = _levels.first;
    if (outermost.tables.isEmpty) return null;

    // Return the first table added (which should be the FROM table)
    return outermost.tables.values.first;
  }

  /// Resolves an unqualified column to the most appropriate table
  /// This is used when a column doesn't have a table prefix and we need to
  /// determine which table it belongs to based on context.
  /// 
  /// Uses schema information when available to find tables that actually
  /// contain the column, otherwise falls back to context-based heuristics.
  String? resolveUnqualifiedColumn(String columnName) {
    if (_schema != null) {
      // Check tables from current level first (closest scope), then work backwards
      for (int i = _levels.length - 1; i >= 0; i--) {
        final level = _levels[i];
        
        // Within each level, check tables in reverse order of addition
        // (most recently added tables have precedence)
        final tableNames = level.tables.values.toList().reversed;
        
        for (final tableName in tableNames) {
          if (_schema.tableHasColumn(tableName, columnName)) {
            return tableName;
          }
        }
      }
      
      // No table in context contains this column
      return null;
    }
    
    // Fallback to heuristics when no schema is available
    // In the current context level, prefer the primary table (FROM clause)
    if (_levels.isNotEmpty) {
      final currentLevel = _levels.last;
      
      // If there's only one table in the current level, use it
      if (currentLevel.tables.length == 1) {
        return currentLevel.tables.values.first;
      }
      
      // If there are multiple tables, prefer the first one added (FROM table)
      if (currentLevel.tables.isNotEmpty) {
        return currentLevel.tables.values.first;
      }
    }
    
    // Fall back to the primary table from outer context
    return primaryTable;
  }

  /// Creates a copy of this context for use in subqueries
  AnalysisContext copy() {
    final newContext = AnalysisContext(_schema);
    for (final level in _levels) {
      newContext.pushLevel();
      newContext._levels.last.tables.addAll(level.tables);
    }
    return newContext;
  }

  @override
  String toString() {
    final buffer = StringBuffer('AnalysisContext{\n');
    for (int i = 0; i < _levels.length; i++) {
      buffer.writeln('  Level $i: ${_levels[i].tables}');
    }
    buffer.writeln('}');
    return buffer.toString();
  }
}

/// Represents a single context level with available tables/aliases
class _ContextLevel {
  /// Maps alias/table names to their full table names
  final Map<String, String> tables = <String, String>{};
}

<!-- END FILE: declarative_sqlite/lib/src/builders/analysis_context.dart -->

<!-- BEGIN FILE: declarative_sqlite/lib/src/builders/column_builder.dart -->
import 'package:declarative_sqlite/src/schema/db_column.dart';
import 'package:meta/meta.dart';

/// Base class for all column builders.
abstract class ColumnBuilder {
  final String name;
  final String logicalType;
  final String dbType;

  @protected
  bool isNotNull = false;
  @protected
  bool isParent = false;
  @protected
  bool isLww = false;
  @protected
  Object? defaultValue;
  @protected
  DefaultValueCallback? defaultValueCallback;

  ColumnBuilder(this.name, this.logicalType, this.dbType);

  ColumnBuilder notNull([Object? defaultValue]) {
    isNotNull = true;
    this.defaultValue = defaultValue;
    return this;
  }

  ColumnBuilder parent() {
    isParent = true;
    return this;
  }

  ColumnBuilder lww() {
    isLww = true;
    return this;
  }

  ColumnBuilder defaultsTo(Object? value) {
    defaultValue = value;
    defaultValueCallback = null; // Clear callback when setting static value
    return this;
  }

  /// Sets a callback function to generate default values on-the-fly
  /// The callback is called each time a record is inserted without a value for this column
  ColumnBuilder defaultCallback(DefaultValueCallback callback) {
    defaultValueCallback = callback;
    defaultValue = null; // Clear static value when setting callback
    return this;
  }

  DbColumn build() {
    return DbColumn(
      name: name,
      logicalType: logicalType,
      type: dbType,
      isNotNull: isNotNull,
      defaultValue: defaultValue,
      defaultValueCallback: defaultValueCallback,
      isParent: isParent,
      isLww: isLww,
    );
  }
}

<!-- END FILE: declarative_sqlite/lib/src/builders/column_builder.dart -->

<!-- BEGIN FILE: declarative_sqlite/lib/src/builders/date_column_builder.dart -->
import 'column_builder.dart';

class DateColumnBuilder extends ColumnBuilder {
  DateColumnBuilder(String name) : super(name, 'date', 'TEXT');
}

<!-- END FILE: declarative_sqlite/lib/src/builders/date_column_builder.dart -->

<!-- BEGIN FILE: declarative_sqlite/lib/src/builders/fileset_column_builder.dart -->
import 'column_builder.dart';
import '../schema/db_column.dart';

class FilesetColumnBuilder extends ColumnBuilder {
  FilesetColumnBuilder(String name) : super(name, 'fileset', 'TEXT');

  @override
  DbColumn build() {
    return DbColumn(
      name: name,
      logicalType: logicalType,
      type: dbType,
      isNotNull: isNotNull,
      defaultValue: defaultValue,
      defaultValueCallback: defaultValueCallback,
      isParent: isParent,
      isLww: isLww,
    );
  }
}

<!-- END FILE: declarative_sqlite/lib/src/builders/fileset_column_builder.dart -->

<!-- BEGIN FILE: declarative_sqlite/lib/src/builders/guid_column_builder.dart -->
import 'package:declarative_sqlite/src/builders/column_builder.dart';

class GuidColumnBuilder extends ColumnBuilder {
  GuidColumnBuilder(String name) : super(name, 'guid', 'TEXT');
}

<!-- END FILE: declarative_sqlite/lib/src/builders/guid_column_builder.dart -->

<!-- BEGIN FILE: declarative_sqlite/lib/src/builders/integer_column_builder.dart -->
import 'package:declarative_sqlite/src/builders/column_builder.dart';
import 'package:declarative_sqlite/src/schema/db_column.dart';

class IntegerColumnBuilder extends ColumnBuilder {
  num? _minValue;
  num? _maxValue;

  IntegerColumnBuilder(String name) : super(name, 'integer', 'INTEGER');

  IntegerColumnBuilder min(num value) {
    _minValue = value;
    return this;
  }

  IntegerColumnBuilder max(num value) {
    _maxValue = value;
    return this;
  }

  @override
  DbColumn build() {
    return DbColumn(
      name: name,
      logicalType: logicalType,
      type: dbType,
      isNotNull: isNotNull,
      defaultValue: defaultValue,
      defaultValueCallback: defaultValueCallback,
      isParent: isParent,
      isLww: isLww,
      minValue: _minValue,
      maxValue: _maxValue,
    );
  }
}

<!-- END FILE: declarative_sqlite/lib/src/builders/integer_column_builder.dart -->

<!-- BEGIN FILE: declarative_sqlite/lib/src/builders/join_clause.dart -->
import 'aliased.dart';
import 'analysis_context.dart';
import 'query_dependencies.dart';
import 'where_clause.dart';

class JoinClause {
  final String type; // 'INNER', 'LEFT', 'RIGHT', 'FULL OUTER', etc.
  final Aliased<String> table;
  final WhereClause? onCondition;

  JoinClause(this.type, this.table, this.onCondition);

  /// Factory constructors for common join types
  factory JoinClause.inner(String table, WhereClause onCondition,
      [String? alias]) {
    return JoinClause('INNER', Aliased(table, alias), onCondition);
  }

  factory JoinClause.left(String table, WhereClause onCondition,
      [String? alias]) {
    return JoinClause('LEFT', Aliased(table, alias), onCondition);
  }

  factory JoinClause.right(String table, WhereClause onCondition,
      [String? alias]) {
    return JoinClause('RIGHT', Aliased(table, alias), onCondition);
  }

  factory JoinClause.fullOuter(String table, WhereClause onCondition,
      [String? alias]) {
    return JoinClause('FULL OUTER', Aliased(table, alias), onCondition);
  }
  factory JoinClause.cross(String table, [String? alias]) {
    return JoinClause('CROSS', Aliased(table, alias), null);
  }

  BuiltJoinClause build() {
    final (sql, parameters) = _buildSql();
    return BuiltJoinClause(sql, parameters);
  }

  (String, List<Object?>) _buildSql() {
    if (type == 'CROSS') {
      return ('$type JOIN ${table.toString()}', []);
    }
    assert(
        onCondition != null, "onCondition can only be [null] for CROSS JOINs");
    final builtCondition = onCondition!.build();
    return (
      '$type JOIN ${table.toString()} ON ${builtCondition.sql}',
      builtCondition.parameters
    );
  }

  /// Analyzes this JOIN clause to extract table and column dependencies
  QueryDependencies analyzeDependencies(AnalysisContext context) {
    var dependencies = QueryDependencies.empty();

    // Add the joined table to context for proper resolution
    context.addTable(table.expression, alias: table.alias);

    // Add the joined table to dependencies
    dependencies = dependencies.merge(QueryDependencies(
      tables: {table.toString()}, // Use toString() to include alias if present
      columns: <QueryDependencyColumn>{},
      usesWildcard: false,
    ));

    // Analyze the ON condition dependencies
    if (onCondition != null) {
      dependencies =
          dependencies.merge(onCondition!.analyzeDependencies(context));
    }

    return dependencies;
  }
}

/// Represents a built JOIN clause with SQL and parameters
class BuiltJoinClause {
  final String sql;
  final List<Object?> parameters;

  BuiltJoinClause(this.sql, this.parameters);
}

<!-- END FILE: declarative_sqlite/lib/src/builders/join_clause.dart -->

<!-- BEGIN FILE: declarative_sqlite/lib/src/builders/key_builder.dart -->
import 'package:declarative_sqlite/src/schema/db_key.dart';

class KeyBuilder {
  final List<String> columns;
  KeyType _type = KeyType.indexed;
  String? _foreignTable;
  List<String>? _foreignColumns;

  KeyBuilder(this.columns);

  void primary() {
    _type = KeyType.primary;
  }

  void index() {
    _type = KeyType.indexed;
  }

  void unique() {
    _type = KeyType.unique;
  }

  void foreignKey(String table, List<String> columns) {
    _type = KeyType.foreign;
    _foreignTable = table;
    _foreignColumns = columns;
  }

  DbKey build() {
    return DbKey(
      columns: columns,
      type: _type,
      foreignTable: _foreignTable,
      foreignColumns: _foreignColumns,
    );
  }
}

<!-- END FILE: declarative_sqlite/lib/src/builders/key_builder.dart -->

<!-- BEGIN FILE: declarative_sqlite/lib/src/builders/query_builder.dart -->
import 'aliased.dart';
import 'analysis_context.dart';
import 'query_column.dart';
import 'join_clause.dart';
import 'query_dependencies.dart';
import 'where_clause.dart';

class QueryBuilder {
  Aliased<String>? _from;
  final List<Aliased<QueryColumn>> _columns = [];
  WhereClause? _where;
  final List<QueryColumn> _orderBy = [];
  final List<QueryColumn> _groupBy = [];
  final List<JoinClause> _joins = [];
  String? _having;
  String? _updateTable; // Table to target for CRUD operations

  QueryBuilder select(String column, [String? alias]) {
    _columns.add(Aliased(QueryColumn.parse(column), alias));
    return this;
  }

  QueryBuilder from(String table, [String? alias]) {
    _from = Aliased(table, alias);
    return this;
  }

  QueryBuilder where(WhereClause? clause) {
    _where = clause;
    return this;
  }

  QueryBuilder orderBy(List<String> columns) {
    _orderBy.addAll(columns.map((col) => QueryColumn.parse(col)));
    return this;
  }

  QueryBuilder groupBy(List<String> columns) {
    _groupBy.addAll(columns.map((col) => QueryColumn.parse(col)));
    return this;
  }

  QueryBuilder having(String condition) {
    _having = condition;
    return this;
  }

  /// Specifies that results from this query should be CRUD-enabled
  /// targeting the specified table for update operations.
  ///
  /// This allows queries from views or joins to return updatable records
  /// as long as they include system_id and system_version from the target table.
  QueryBuilder forUpdate(String tableName) {
    _updateTable = tableName;
    return this;
  }

  QueryBuilder innerJoin(
    String table,
    WhereClause onCondition, [
    String? alias,
  ]) {
    _joins.add(JoinClause.inner(table, onCondition, alias));
    return this;
  }

  QueryBuilder leftJoin(
    String table,
    WhereClause onCondition, [
    String? alias,
  ]) {
    _joins.add(JoinClause.left(table, onCondition, alias));
    return this;
  }

  QueryBuilder rightJoin(
    String table,
    WhereClause onCondition, [
    String? alias,
  ]) {
    _joins.add(JoinClause.right(table, onCondition, alias));
    return this;
  }

  QueryBuilder fullOuterJoin(
    String table,
    WhereClause onCondition, [
    String? alias,
  ]) {
    _joins.add(JoinClause.fullOuter(table, onCondition, alias));
    return this;
  }

  QueryBuilder crossJoin(
    String table,[
    String? alias,
  ]) {
    _joins.add(JoinClause.cross(table, alias));
    return this;
  }

  /// Select a subquery with an alias
  QueryBuilder selectSubQuery(void Function(QueryBuilder) build, String alias) {
    final subQueryBuilder = QueryBuilder();
    build(subQueryBuilder);
    final built = subQueryBuilder.build();
    final subQuery = built.$1;
    _columns.add(Aliased(QueryColumn.parse('($subQuery)'), alias));
    return this;
  }



  (String, List<Object?>) build() {
    if (_from == null) {
      throw StateError('A "from" clause is required to build a query.');
    }

    final columns = _columns.isEmpty
        ? '*'
        : _columns.map((col) => col.toString()).join(', ');

    var sql = 'SELECT $columns FROM ${_from!.toString()}';
    var parameters = <Object?>[];

    // Add JOINs using structured JoinClause.build()
    for (final joinClause in _joins) {
      final builtJoin = joinClause.build();
      sql += ' ${builtJoin.sql}';
      parameters.addAll(builtJoin.parameters);
    }

    if (_where != null) {
      final builtWhere = _where!.build();
      sql += ' WHERE ${builtWhere.sql}';
      parameters.addAll(builtWhere.parameters);
    }

    if (_groupBy.isNotEmpty) {
      sql += ' GROUP BY ${_groupBy.map((col) => col.toSql()).join(', ')}';
    }

    if (_having != null) {
      sql += ' HAVING $_having';
    }

    if (_orderBy.isNotEmpty) {
      sql += ' ORDER BY ${_orderBy.map((col) => col.toSql()).join(', ')}';
    }

    if (_limit != null) {
      sql += ' LIMIT $_limit';
    }

    if (_offset != null) {
      sql += ' OFFSET $_offset';
    }

    return (sql, parameters);
  }

  /// Gets the main table name being queried (without alias).
  String? get tableName {
    if (_from == null) return null;
    return _from!.expression;
  }

  /// Gets the table name specified for CRUD operations via forUpdate()
  String? get updateTableName => _updateTable;

  int? _limit;
  int? _offset;

  QueryBuilder limit(int count) {
    _limit = count;
    return this;
  }

  QueryBuilder offset(int count) {
    _offset = count;
    return this;
  }

  /// Analyzes this query to determine table and column dependencies
  QueryDependencies analyzeDependencies([AnalysisContext? parentContext]) {
    final context = parentContext ?? AnalysisContext();
    var dependencies = QueryDependencies.empty();

    // Build the analysis context with FROM clause
    String? baseTableName;

    // Add FROM clause to context
    if (_from != null) {
      baseTableName = _from!.expression;
      context.addTable(baseTableName, alias: _from!.alias);

      // Add to dependencies with alias if present
      final tableRef = _from!.alias != null
          ? '${_from!.expression} AS ${_from!.alias}'
          : _from!.expression;

      dependencies = dependencies.merge(QueryDependencies(
        tables: {tableRef},
        columns: <QueryDependencyColumn>{},
        usesWildcard: false,
      ));
    }

    // Add JOIN clauses and analyze their dependencies
    for (final joinClause in _joins) {
      dependencies = dependencies.merge(joinClause.analyzeDependencies(context));
    }

    // Analyze columns from SELECT clause using Column.analyzeDependencies
    for (final col in _columns) {
      dependencies = dependencies.merge(col.expression.analyzeDependencies(context, baseTableName));
    }

    // Add dependencies from WHERE clause
    if (_where != null) {
      dependencies = dependencies.merge(_where!.analyzeDependencies(context));
    }

    // Analyze columns from ORDER BY clause
    for (final columnExpr in _orderBy) {
      dependencies = dependencies.merge(columnExpr.analyzeDependencies(context, baseTableName));
    }

    // Analyze columns from GROUP BY clause
    for (final columnExpr in _groupBy) {
      dependencies = dependencies.merge(columnExpr.analyzeDependencies(context, baseTableName));
    }

    // Note: HAVING clause analysis would require WhereClause type
    // Currently _having is a String, so we can't analyze it structurally

    return dependencies;
  }
}

<!-- END FILE: declarative_sqlite/lib/src/builders/query_builder.dart -->

<!-- BEGIN FILE: declarative_sqlite/lib/src/builders/query_column.dart -->
import 'analysis_context.dart';
import 'query_dependencies.dart';

/// Represents a column reference in a SQL query
/// 
/// Can be a simple column, qualified column, aggregate function, or complex expression.
/// Handles parsing at construction time and provides structured dependency analysis.
abstract class QueryColumn {
  /// The original expression as provided by the user
  final String expression;
  
  const QueryColumn(this.expression);
  
  /// Factory constructor that parses column expressions and returns appropriate Column subtype
  factory QueryColumn.parse(String expression) {
    // Trim whitespace
    final trimmed = expression.trim();
    
    // Check for wildcard
    if (trimmed == '*' || trimmed.endsWith('.*')) {
      return WildcardColumn(trimmed);
    }
    
    // Check for aggregate functions (simple heuristic)
    final upperExpression = trimmed.toUpperCase();
    if (RegExp(r'^(COUNT|SUM|AVG|MIN|MAX|GROUP_CONCAT)\s*\(').hasMatch(upperExpression)) {
      return AggregateColumn(trimmed);
    }
    
    // Check for ORDER BY expressions with ASC/DESC (extract the column part)
    final orderByMatch = RegExp(r'^(.+?)\s+(ASC|DESC)$', caseSensitive: false).firstMatch(trimmed);
    if (orderByMatch != null) {
      final columnPart = orderByMatch.group(1)!.trim();
      return QueryColumn.parse(columnPart); // Recursively parse the column part
    }
    
    // Check for complex expressions (contains operators, functions, literals)
    if (RegExp(r'[+\-*/()]|CASE\s|WHEN\s|THEN\s|ELSE\s|END\s').hasMatch(upperExpression)) {
      return ExpressionColumn(trimmed);
    }
    
    // Check for qualified column (table.column or alias.column)
    if (trimmed.contains('.') && !trimmed.startsWith('.') && !trimmed.endsWith('.')) {
      final parts = trimmed.split('.');
      if (parts.length == 2 && parts[0].isNotEmpty && parts[1].isNotEmpty) {
        return QualifiedColumn(trimmed, parts[0], parts[1]);
      }
    }
    
    // Simple column name
    return SimpleColumn(trimmed);
  }
  
  /// Analyzes this column's dependencies
  QueryDependencies analyzeDependencies(AnalysisContext context, [String? fallbackTable]);
  
  /// Renders the column as SQL
  String toSql();
  
  @override
  String toString() => toSql();
}

/// A simple column name without table qualification
class SimpleColumn extends QueryColumn {
  final String columnName;
  
  const SimpleColumn(super.expression) : 
    columnName = expression;
  
  @override
  QueryDependencies analyzeDependencies(AnalysisContext context, [String? fallbackTable]) {
    // Try to resolve the column to an appropriate table
    final resolvedTable = fallbackTable ?? context.resolveUnqualifiedColumn(columnName);
    
    if (resolvedTable != null) {
      return QueryDependencies(
        tables: <String>{},
        columns: {QueryDependencyColumn(resolvedTable, columnName)},
        usesWildcard: false,
      );
    }
    
    // If we can't resolve the table, return empty dependencies
    // This shouldn't happen in well-formed queries
    return QueryDependencies.empty();
  }
  
  @override
  String toSql() => columnName;
}

/// A qualified column with table/alias prefix (e.g., "u.name", "posts.title")
class QualifiedColumn extends QueryColumn {
  final String tableOrAlias;
  final String columnName;
  
  const QualifiedColumn(super.expression, this.tableOrAlias, this.columnName);
  
  @override
  QueryDependencies analyzeDependencies(AnalysisContext context, [String? fallbackTable]) {
    final resolvedTable = context.resolveTable(tableOrAlias) ?? tableOrAlias;
    return QueryDependencies(
      tables: <String>{},
      columns: {QueryDependencyColumn(resolvedTable, columnName)},
      usesWildcard: false,
    );
  }
  
  @override
  String toSql() => '$tableOrAlias.$columnName';
}

/// A wildcard column (* or table.*)
class WildcardColumn extends QueryColumn {
  final String? tableOrAlias;
  
  WildcardColumn(super.expression) : 
    tableOrAlias = expression.contains('.') ? expression.split('.')[0] : null;
  
  @override
  QueryDependencies analyzeDependencies(AnalysisContext context, [String? fallbackTable]) {
    return QueryDependencies(
      tables: <String>{},
      columns: <QueryDependencyColumn>{},
      usesWildcard: true,
    );
  }
  
  @override
  String toSql() => expression;
}

/// An aggregate function column (e.g., "COUNT(*)", "SUM(amount)")
class AggregateColumn extends QueryColumn {
  const AggregateColumn(super.expression);
  
  @override
  QueryDependencies analyzeDependencies(AnalysisContext context, [String? fallbackTable]) {
    var dependencies = QueryDependencies.empty();
    
    // Extract column references from within the aggregate function
    // This is a simple approach - we could make it more sophisticated
    final columnRefs = RegExp(r'([a-zA-Z_][a-zA-Z0-9_]*\.)?([a-zA-Z_][a-zA-Z0-9_]*)')
        .allMatches(expression);
    
    for (final match in columnRefs) {
      final tableOrAlias = match.group(1)?.replaceAll('.', '');
      final columnName = match.group(2)!;
      
      // Skip SQL keywords and function names
      final upperColumn = columnName.toUpperCase();
      if (['COUNT', 'SUM', 'AVG', 'MIN', 'MAX', 'GROUP_CONCAT', 'DISTINCT'].contains(upperColumn)) {
        continue;
      }
      
      if (tableOrAlias != null) {
        final resolvedTable = context.resolveTable(tableOrAlias) ?? tableOrAlias;
        dependencies = dependencies.merge(QueryDependencies(
          tables: <String>{},
          columns: {QueryDependencyColumn(resolvedTable, columnName)},
          usesWildcard: false,
        ));
      } else if (fallbackTable != null) {
        dependencies = dependencies.merge(QueryDependencies(
          tables: <String>{},
          columns: {QueryDependencyColumn(fallbackTable, columnName)},
          usesWildcard: false,
        ));
      }
    }
    
    return dependencies;
  }
  
  @override
  String toSql() => expression;
}

/// A complex expression column (e.g., calculations, CASE statements)
class ExpressionColumn extends QueryColumn {
  const ExpressionColumn(super.expression);
  
  @override
  QueryDependencies analyzeDependencies(AnalysisContext context, [String? fallbackTable]) {
    var dependencies = QueryDependencies.empty();
    
    // Extract column references from the expression
    // This is a simple regex approach - could be made more sophisticated with proper SQL parsing
    final columnRefs = RegExp(r'([a-zA-Z_][a-zA-Z0-9_]*\.)?([a-zA-Z_][a-zA-Z0-9_]*)')
        .allMatches(expression);
    
    for (final match in columnRefs) {
      final tableOrAlias = match.group(1)?.replaceAll('.', '');
      final columnName = match.group(2)!;
      
      // Skip SQL keywords and function names
      final upperColumn = columnName.toUpperCase();
      if (['CASE', 'WHEN', 'THEN', 'ELSE', 'END', 'AND', 'OR', 'NOT', 'NULL', 'TRUE', 'FALSE'].contains(upperColumn)) {
        continue;
      }
      
      if (tableOrAlias != null) {
        final resolvedTable = context.resolveTable(tableOrAlias) ?? tableOrAlias;
        dependencies = dependencies.merge(QueryDependencies(
          tables: <String>{},
          columns: {QueryDependencyColumn(resolvedTable, columnName)},
          usesWildcard: false,
        ));
      } else if (fallbackTable != null) {
        dependencies = dependencies.merge(QueryDependencies(
          tables: <String>{},
          columns: {QueryDependencyColumn(fallbackTable, columnName)},
          usesWildcard: false,
        ));
      }
    }
    
    return dependencies;
  }
  
  @override
  String toSql() => expression;
}
<!-- END FILE: declarative_sqlite/lib/src/builders/query_column.dart -->

<!-- BEGIN FILE: declarative_sqlite/lib/src/builders/query_dependencies.dart -->
/// Represents dependencies of a query component
class QueryDependencies {
  final Set<String> tables;
  final Set<QueryDependencyColumn> columns;
  final bool usesWildcard;

  const QueryDependencies({
    required this.tables,
    required this.columns,
    required this.usesWildcard,
  });

  QueryDependencies.empty() : tables = {}, columns = {}, usesWildcard = false;

  /// Merges this dependencies with another
  QueryDependencies merge(QueryDependencies other) {
    return QueryDependencies(
      tables: {...tables, ...other.tables},
      columns: {...columns, ...other.columns},
      usesWildcard: usesWildcard || other.usesWildcard,
    );
  }
}

class QueryDependencyColumn {
  final String table;
  final String column;

  QueryDependencyColumn(this.table, this.column);

  /// Returns true if this column reference is qualified (has a table name)
  bool get isQualified => table.isNotEmpty;

  /// Returns the fully qualified column name (table.column)
  String get qualifiedName => isQualified ? '$table.$column' : column;

  @override
  bool operator ==(Object other) {
    if (identical(this, other)) return true;
    return other is QueryDependencyColumn &&
           other.table == table &&
           other.column == column;
  }

  @override
  int get hashCode => Object.hash(table, column);

  @override
  String toString() => 'QueryDependencyColumn(table: $table, column: $column)';
}
<!-- END FILE: declarative_sqlite/lib/src/builders/query_dependencies.dart -->

<!-- BEGIN FILE: declarative_sqlite/lib/src/builders/real_column_builder.dart -->
import 'package:declarative_sqlite/src/builders/column_builder.dart';
import 'package:declarative_sqlite/src/schema/db_column.dart';

class RealColumnBuilder extends ColumnBuilder {
  num? _minValue;
  num? _maxValue;

  RealColumnBuilder(String name) : super(name, 'real', 'REAL');

  RealColumnBuilder min(num value) {
    _minValue = value;
    return this;
  }

  RealColumnBuilder max(num value) {
    _maxValue = value;
    return this;
  }

  @override
  DbColumn build() {
    return DbColumn(
      name: name,
      logicalType: logicalType,
      type: dbType,
      isNotNull: isNotNull,
      defaultValue: defaultValue,
      defaultValueCallback: defaultValueCallback,
      isParent: isParent,
      isLww: isLww,
      minValue: _minValue,
      maxValue: _maxValue,
    );
  }
}

<!-- END FILE: declarative_sqlite/lib/src/builders/real_column_builder.dart -->

<!-- BEGIN FILE: declarative_sqlite/lib/src/builders/schema_builder.dart -->
import 'package:declarative_sqlite/src/schema/db_table.dart';
import 'package:declarative_sqlite/src/schema/schema.dart';
import 'package:declarative_sqlite/src/builders/table_builder.dart';
import 'package:declarative_sqlite/src/builders/view_builder.dart';
import 'package:declarative_sqlite/src/sync/hlc.dart';

/// A fluent builder for defining a database schema.
///
/// The `SchemaBuilder` is the entry point for defining the structure of your
/// database, including its tables and views.
///
/// Example:
/// ```dart
/// final schemaBuilder = SchemaBuilder();
///
/// schemaBuilder.table('users', (table) {
///   table.guid('id').notNull(Uuid().v4());
///   table.text('name').notNull('Default Name');
///   table.integer('age').notNull(0);
///   table.key(['id']).primary();
/// });
///
/// schemaBuilder.view('user_names', (view) {
///   view.select('name').from('users');
/// });
///
/// final schema = schemaBuilder.build();
/// ```
class SchemaBuilder {
  final _tableBuilders = <TableBuilder>[];
  final _viewBuilders = <ViewBuilder>[];

  /// Defines a table in the schema.
  ///
  /// The [name] is the name of the table.
  /// The [build] callback provides a [TableBuilder] to define the table's
  /// columns and keys.
  ///
  /// The [name] is not allowed to start with `__` (two underscores) as that is
  /// reserved for system tables.
  SchemaBuilder table(String name, void Function(TableBuilder) build) {
    final builder = TableBuilder(name);
    build(builder);
    _tableBuilders.add(builder);
    return this;
  }

  /// Defines a view in the schema.
  ///
  /// The [name] is the name of the view.
  /// The [build] callback provides a [ViewBuilder] to define the view's
  /// SELECT statement.
  SchemaBuilder view(String name, void Function(ViewBuilder) build) {
    final builder = ViewBuilder(name);
    build(builder);
    _viewBuilders.add(builder);
    return this;
  }

  /// Builds the [Schema] object.
  ///
  /// This should be called after all tables and views have been defined.
  Schema build() {
    final userTables = _tableBuilders
        .where((t) => !t.name.startsWith('__'))
        .map((b) => b.build())
        .toList();
    final systemTables = [
      _buildSystemTableSettings(),
      _buildSystemTableFiles(),
      _buildSystemTableDirtyRows(),
    ];

    return Schema(
      tables: [...userTables, ...systemTables],
      views: _viewBuilders.map((b) => b.build()).toList(),
    );
  }

  DbTable _buildSystemTableSettings() {
    final builder = TableBuilder('__settings');
    builder.text('key').notNull('_');
    builder.text('value');
    builder.key(['key']).primary();
    return builder.build();
  }

  DbTable _buildSystemTableFiles() {
    final builder = TableBuilder('__files');
    builder.guid('id').notNull('00000000-0000-0000-0000-000000000000');
    builder.guid('owner_id').notNull('00000000-0000-0000-0000-000000000000');
    builder.text('filename').notNull('default');
    builder.integer('remote_version').notNull(0);
    builder.text('mimetype').notNull('application/octet-stream');
    builder.integer('size').notNull(0);
    builder.key(['id']).primary();
    builder.key(['owner_id', 'filename']).index();
    return builder.build();
  }

  DbTable _buildSystemTableDirtyRows() {
    final builder = TableBuilder('__dirty_rows');
    builder.text('table_name').notNull('default');
    builder.guid('row_id').notNull('00000000-0000-0000-0000-000000000000');
    builder.text('hlc').notNull(Hlc.min.toString());
    builder.key(['table_name', 'row_id']).primary();
    return builder.build();
  }
}

<!-- END FILE: declarative_sqlite/lib/src/builders/schema_builder.dart -->

<!-- BEGIN FILE: declarative_sqlite/lib/src/builders/table_builder.dart -->
import 'package:declarative_sqlite/src/schema/db_column.dart';
import 'package:declarative_sqlite/src/builders/column_builder.dart';
import 'package:declarative_sqlite/src/builders/date_column_builder.dart';
import 'package:declarative_sqlite/src/builders/fileset_column_builder.dart';
import 'package:declarative_sqlite/src/builders/guid_column_builder.dart';
import 'package:declarative_sqlite/src/builders/integer_column_builder.dart';
import 'package:declarative_sqlite/src/builders/key_builder.dart';
import 'package:declarative_sqlite/src/builders/real_column_builder.dart';
import 'package:declarative_sqlite/src/builders/text_column_builder.dart';
import 'package:declarative_sqlite/src/schema/db_table.dart';

class TableBuilder {
  final String name;
  final List<ColumnBuilder> _columnBuilders = [];
  final List<KeyBuilder> _keyBuilders = [];

  TableBuilder(this.name);

  T _addColumn<T extends ColumnBuilder>(T builder) {
    _columnBuilders.add(builder);
    return builder;
  }

  GuidColumnBuilder guid(String name) => _addColumn(GuidColumnBuilder(name));
  TextColumnBuilder text(String name) => _addColumn(TextColumnBuilder(name));
  IntegerColumnBuilder integer(String name) =>
      _addColumn(IntegerColumnBuilder(name));
  RealColumnBuilder real(String name) => _addColumn(RealColumnBuilder(name));
  DateColumnBuilder date(String name) => _addColumn(DateColumnBuilder(name));
  FilesetColumnBuilder fileset(String name) =>
      _addColumn(FilesetColumnBuilder(name));

  KeyBuilder key(List<String> columns) {
    final builder = KeyBuilder(columns);
    _keyBuilders.add(builder);
    return builder;
  }

  DbTable build() {
    final columns = _columnBuilders.map((b) => b.build()).toList();
    final hlcColumns = <DbColumn>[];
    for (final column in columns) {
      if (column.isLww) {
        hlcColumns.add(
          DbColumn(
            name: '${column.name}__hlc',
            logicalType: 'hlc',
            type: 'TEXT',
            isNotNull: false, // Nullable to support partial inserts
            isParent: false,
            isLww: false,
          ),
        );
      }
    }

    final isSystemTable = name.startsWith('__');

    final systemColumns = isSystemTable
        ? <DbColumn>[]
        : [
            DbColumn(
              name: 'system_id',
              logicalType: 'guid',
              type: 'TEXT', // GUID
              isNotNull: true,
              defaultValue: '00000000-0000-0000-0000-000000000000',
              isParent: false,
              isLww: false,
            ),
            DbColumn(
              name: 'system_created_at',
              logicalType: 'hlc',
              type: 'TEXT', // HLC
              isNotNull: true,
              defaultValue: '000000000000000:000000000:000000000000000000000000000000000000', // HLC format: milliseconds(15):counter(9):nodeId(36)
              isParent: false,
              isLww: false,
            ),
            DbColumn(
              name: 'system_version',
              logicalType: 'hlc',
              type: 'TEXT', // HLC
              isNotNull: true,
              defaultValue: '000000000000000:000000000:000000000000000000000000000000000000', // HLC format: milliseconds(15):counter(9):nodeId(36)
              isParent: false,
              isLww: false,
            ),
          ];

    return DbTable(
      name: name,
      columns: [...systemColumns, ...columns, ...hlcColumns],
      keys: _keyBuilders.map((b) => b.build()).toList(),
    );
  }
}

<!-- END FILE: declarative_sqlite/lib/src/builders/table_builder.dart -->

<!-- BEGIN FILE: declarative_sqlite/lib/src/builders/text_column_builder.dart -->
import 'package:declarative_sqlite/src/builders/column_builder.dart';
import 'package:declarative_sqlite/src/schema/db_column.dart';

class TextColumnBuilder extends ColumnBuilder {
  int? _maxLength;

  TextColumnBuilder(String name) : super(name, 'text', 'TEXT');

  TextColumnBuilder maxLength(int value) {
    _maxLength = value;
    return this;
  }

  @override
  DbColumn build() {
    return DbColumn(
      name: name,
      logicalType: logicalType,
      type: dbType,
      isNotNull: isNotNull,
      defaultValue: defaultValue,
      defaultValueCallback: defaultValueCallback,
      isParent: isParent,
      isLww: isLww,
      maxLength: _maxLength,
    );
  }
}

<!-- END FILE: declarative_sqlite/lib/src/builders/text_column_builder.dart -->

<!-- BEGIN FILE: declarative_sqlite/lib/src/builders/view_builder.dart -->
import 'query_builder.dart';
import 'where_clause.dart';
import '../schema/db_view.dart';

class ViewBuilder {
  final String name;
  final List<String> _selectColumns = [];
  final List<String> _fromClauses = [];
  final List<String> _joinClauses = [];
  final List<WhereClause> _whereClauses = [];
  final List<String> _groupByColumns = [];
  final List<String> _havingClauses = [];
  final List<String> _orderByColumns = [];
  bool _hasFrom = false;

  ViewBuilder(this.name);

  /// Select a single column with optional alias
  /// Each column must be specified in a separate select() call
  ViewBuilder select(String columnExpression, [String? alias]) {
    assert(columnExpression.isNotEmpty, 
        'Column expression cannot be empty');
    assert(!columnExpression.contains(','), 
        'Multiple columns in single select() call are not allowed. '
        'Use separate select() calls for each column: '
        'view.select("col1").select("col2") instead of view.select("col1, col2")');
    assert(!columnExpression.toLowerCase().contains(' as ') || alias == null,
        'Do not use both inline AS alias and alias parameter. '
        'Use either select("column AS alias") or select("column", "alias")');
    
    if (alias != null) {
      _selectColumns.add('$columnExpression AS $alias');
    } else {
      _selectColumns.add(columnExpression);
    }
    return this;
  }

  ViewBuilder selectSubQuery(
      void Function(QueryBuilder) callback, String alias) {
    assert(alias.isNotEmpty, 'Sub-query alias cannot be empty');
    assert(!alias.contains(' '), 'Alias cannot contain spaces');
    
    final subQueryBuilder = QueryBuilder();
    callback(subQueryBuilder);
    final built = subQueryBuilder.build();
    final subQuery = built.$1;
    
    _selectColumns.add('($subQuery) AS $alias');
    return this;
  }

  ViewBuilder from(String table, [String? alias]) {
    assert(table.isNotEmpty, 'Table name cannot be empty');
    assert(!_hasFrom, 'FROM clause already specified. Use joins for additional tables.');
    assert(_fromClauses.isEmpty, 'FROM clause already specified');
    
    if (alias != null) {
      assert(alias.isNotEmpty, 'Table alias cannot be empty');
      assert(!alias.contains(' '), 'Table alias cannot contain spaces');
      _fromClauses.add('$table AS $alias');
    } else {
      _fromClauses.add(table);
    }
    _hasFrom = true;
    return this;
  }

  ViewBuilder fromSubQuery(
    void Function(QueryBuilder) build, [
    String? alias,
  ]) {
    assert(!_hasFrom, 'FROM clause already specified');
    assert(_fromClauses.isEmpty, 'FROM clause already specified');
    
    final subQueryBuilder = QueryBuilder();
    build(subQueryBuilder);
    final built = subQueryBuilder.build();
    final subQuery = built.$1;

    if (alias != null) {
      assert(alias.isNotEmpty, 'Sub-query alias cannot be empty');
      assert(!alias.contains(' '), 'Sub-query alias cannot contain spaces');
      _fromClauses.add('($subQuery) AS $alias');
    } else {
      _fromClauses.add('($subQuery)');
    }
    _hasFrom = true;
    return this;
  }

  @Deprecated('Use typed join methods instead: innerJoin(), leftJoin(), etc.')
  ViewBuilder join(String joinClause) {
    assert(joinClause.isNotEmpty, 'Join clause cannot be empty');
    assert(_hasFrom, 'FROM clause must be specified before joins');
    
    _joinClauses.add(joinClause);
    return this;
  }

  /// Inner join with proper condition builder support
  ViewBuilder innerJoin(String table, WhereClause onCondition, [String? alias]) {
    assert(table.isNotEmpty, 'Table name cannot be empty');
    assert(_hasFrom, 'FROM clause must be specified before joins');
    
    final tableWithAlias = alias != null ? '$table AS $alias' : table;
    final built = onCondition.build();
    _joinClauses.add('INNER JOIN $tableWithAlias ON ${built.sql}');
    return this;
  }

  /// Left join with proper condition builder support  
  ViewBuilder leftJoin(String table, WhereClause onCondition, [String? alias]) {
    assert(table.isNotEmpty, 'Table name cannot be empty');
    assert(_hasFrom, 'FROM clause must be specified before joins');
    
    final tableWithAlias = alias != null ? '$table AS $alias' : table;
    final built = onCondition.build();
    _joinClauses.add('LEFT JOIN $tableWithAlias ON ${built.sql}');
    return this;
  }

  /// Right join with proper condition builder support
  ViewBuilder rightJoin(String table, WhereClause onCondition, [String? alias]) {
    assert(table.isNotEmpty, 'Table name cannot be empty');
    assert(_hasFrom, 'FROM clause must be specified before joins');
    
    final tableWithAlias = alias != null ? '$table AS $alias' : table;
    final built = onCondition.build();
    _joinClauses.add('RIGHT JOIN $tableWithAlias ON ${built.sql}');
    return this;
  }

  /// Full outer join with proper condition builder support
  ViewBuilder fullOuterJoin(String table, WhereClause onCondition, [String? alias]) {
    assert(table.isNotEmpty, 'Table name cannot be empty');
    assert(_hasFrom, 'FROM clause must be specified before joins');
    
    final tableWithAlias = alias != null ? '$table AS $alias' : table;
    final built = onCondition.build();
    _joinClauses.add('FULL OUTER JOIN $tableWithAlias ON ${built.sql}');
    return this;
  }

  /// Cross join (Cartesian product)
  ViewBuilder crossJoin(String table, [String? alias]) {
    assert(table.isNotEmpty, 'Table name cannot be empty');
    assert(_hasFrom, 'FROM clause must be specified before joins');
    
    final tableWithAlias = alias != null ? '$table AS $alias' : table;
    _joinClauses.add('CROSS JOIN $tableWithAlias');
    return this;
  }

  ViewBuilder where(WhereClause condition) {
    assert(_hasFrom, 'FROM clause must be specified before WHERE clause');
    
    _whereClauses.add(condition);
    return this;
  }

  ViewBuilder groupBy(List<String> columns) {
    assert(columns.isNotEmpty, 'GROUP BY columns cannot be empty');
    assert(columns.every((col) => col.isNotEmpty), 'GROUP BY column names cannot be empty');
    assert(_hasFrom, 'FROM clause must be specified before GROUP BY clause');
    
    _groupByColumns.addAll(columns);
    return this;
  }

  @Deprecated('Use WhereClause builder for HAVING conditions')
  ViewBuilder having(String condition) {
    assert(condition.isNotEmpty, 'HAVING condition cannot be empty');
    assert(_groupByColumns.isNotEmpty, 'GROUP BY clause must be specified before HAVING clause');
    
    _havingClauses.add(condition);
    return this;
  }

  ViewBuilder orderBy(List<String> columns) {
    assert(columns.isNotEmpty, 'ORDER BY columns cannot be empty');
    assert(columns.every((col) => col.isNotEmpty), 'ORDER BY column names cannot be empty');
    assert(_hasFrom, 'FROM clause must be specified before ORDER BY clause');
    
    _orderByColumns.addAll(columns);
    return this;
  }

  DbView build() {
    assert(_selectColumns.isNotEmpty, 'At least one SELECT column must be specified');
    assert(_hasFrom, 'FROM clause must be specified');
    
    // Parse SELECT columns into ViewColumn objects
    final columns = _selectColumns.map((colExpr) {
      // Handle "expression AS alias" format
      if (colExpr.toUpperCase().contains(' AS ')) {
        final parts = colExpr.split(RegExp(r'\s+AS\s+', caseSensitive: false));
        if (parts.length == 2) {
          return ViewColumn(
            expression: parts[0].trim(),
            alias: parts[1].trim(),
          );
        }
      }
      
      // Simple column expression
      return ViewColumn(expression: colExpr.trim());
    }).toList();
    
    // Parse FROM tables into ViewTable objects
    final fromTables = _fromClauses.map((fromExpr) {
      // Handle "table AS alias" format
      if (fromExpr.toUpperCase().contains(' AS ')) {
        final parts = fromExpr.split(RegExp(r'\s+AS\s+', caseSensitive: false));
        if (parts.length == 2) {
          return ViewTable(
            name: parts[0].trim(),
            alias: parts[1].trim(),
          );
        }
      }
      
      // Simple table name
      return ViewTable(name: fromExpr.trim());
    }).toList();
    
    // Parse JOIN clauses into ViewJoin objects
    final joins = _joinClauses.map((joinExpr) {
      // Parse join expressions like "INNER JOIN table AS alias ON condition"
      final joinRegex = RegExp(r'^(\w+(?:\s+\w+)?)\s+JOIN\s+([^\s]+)(?:\s+AS\s+([^\s]+))?(?:\s+ON\s+(.+))?', caseSensitive: false);
      final match = joinRegex.firstMatch(joinExpr);
      
      if (match != null) {
        return ViewJoin(
          type: match.group(1)!.toUpperCase(),
          table: match.group(2)!,
          alias: match.group(3),
          onCondition: match.group(4),
        );
      }
      
      // Fallback for complex join expressions
      return ViewJoin(
        type: 'INNER',
        table: 'unknown',
        onCondition: joinExpr,
      );
    }).toList();
    
    // Convert WHERE clauses to strings
    final whereStrings = _whereClauses.map((whereClause) {
      final built = whereClause.build();
      return built.sql;
    }).toList();
    
    return DbView(
      name: name,
      columns: columns,
      fromTables: fromTables,
      joins: joins,
      whereClauses: whereStrings,
      groupByColumns: List.from(_groupByColumns),
      havingClauses: List.from(_havingClauses),
      orderByColumns: List.from(_orderByColumns),
    );
  }
}

<!-- END FILE: declarative_sqlite/lib/src/builders/view_builder.dart -->

<!-- BEGIN FILE: declarative_sqlite/lib/src/builders/where_clause.dart -->
// lib/src/builders/where_clause.dart
import 'analysis_context.dart';
import 'query_column.dart';
import 'query_builder.dart';
import 'query_dependencies.dart';
import '../utils/value_serializer.dart';

abstract class WhereClause {
  BuiltWhereClause build();
  
  /// Analyzes this WHERE clause to extract table and column dependencies
  QueryDependencies analyzeDependencies(AnalysisContext context);
}

class BuiltWhereClause {
  final String sql;
  final List<Object?> parameters;

  BuiltWhereClause(this.sql, this.parameters);
}

class Condition {
  final QueryColumn _column;

  Condition(String columnExpression) : _column = QueryColumn.parse(columnExpression);
  
  QueryColumn get column => _column;

  Comparison eq(Object value) => _compare('=', value);
  Comparison neq(Object value) => _compare('!=', value);
  Comparison gt(Object value) => _compare('>', value);
  Comparison gte(Object value) => _compare('>=', value);
  Comparison lt(Object value) => _compare('<', value);
  Comparison lte(Object value) => _compare('<=', value);
  Comparison like(String value) => _compare('LIKE', value);
  InListComparison inList(List<Object> list) => InListComparison(column, list);
  InSubQueryComparsion inSubQuery(QueryBuilder subQuery) => InSubQueryComparsion(column, subQuery);
  Comparison get nil => _compare('IS NULL', null);
  Comparison get notNil => _compare('IS NOT NULL', null);

  Comparison _compare(String operator, Object? value) {
    return Comparison(_column, operator, value);
  }
}

class InSubQueryComparsion extends WhereClause {
  final QueryColumn column;
  final QueryBuilder subQuery;

  InSubQueryComparsion(this.column, this.subQuery);
  
  @override
  QueryDependencies analyzeDependencies(AnalysisContext context) {
    var dependencies = QueryDependencies.empty();
    
    // Analyze the column dependencies
    dependencies = dependencies.merge(column.analyzeDependencies(context));
    
    // Create a new context level for the subquery
    final subqueryContext = context.copy();
    subqueryContext.pushLevel();
    
    // Analyze the subquery dependencies
    dependencies = dependencies.merge(subQuery.analyzeDependencies(subqueryContext));
    
    return dependencies;
  }
  
  @override
  BuiltWhereClause build() {
    final (sql, parameters) = subQuery.build();
    
    return BuiltWhereClause(
      '${column.toSql()} IN ($sql)', 
      parameters
    );
  }
}

class InListComparison extends WhereClause {
  final QueryColumn column;
  final List<Object> list;

  InListComparison(this.column, this.list);
  
  @override
  BuiltWhereClause build() {
    final questionMarks = list.map((_) => '?').join(',');
    final serializedList = list.map(DatabaseValueSerializer.serialize).toList();
    return BuiltWhereClause('${column.toSql()} IN ($questionMarks)', serializedList);
  }

  @override
  QueryDependencies analyzeDependencies(AnalysisContext context) {
    var dependencies = QueryDependencies.empty();

    // Analyze the column dependencies
    dependencies = dependencies.merge(column.analyzeDependencies(context));

    return dependencies;
  }
}

class Comparison extends WhereClause {
  final QueryColumn column;
  final String operator;
  final Object? value;

  Comparison(this.column, this.operator, this.value);

  @override
  BuiltWhereClause build() {
    if (value == null && (operator == 'IS NULL' || operator == 'IS NOT NULL')) {
      return BuiltWhereClause('${column.toSql()} $operator', []);
    }
    
    // Check if value is a column reference (Condition object)
    if (value is Condition) {
      final condition = value as Condition;
      return BuiltWhereClause('${column.toSql()} $operator ${condition.column.toSql()}', []);
    }
    
    // Serialize values using the centralized database serialization logic
    final serializedValue = DatabaseValueSerializer.serialize(value);
    return BuiltWhereClause('${column.toSql()} $operator ?', [serializedValue]);
  }

  @override
  QueryDependencies analyzeDependencies(AnalysisContext context) {
    var dependencies = QueryDependencies.empty();
    
    // Analyze the left-hand column
    dependencies = dependencies.merge(column.analyzeDependencies(context));
    
    // Analyze the right-hand column if it's a column reference
    if (value is Condition) {
      final rightColumn = (value as Condition).column;
      dependencies = dependencies.merge(rightColumn.analyzeDependencies(context));
    }
    
    return dependencies;
  }
}

class LogicalOperator extends WhereClause {
  final String operator;
  final List<WhereClause> clauses;

  LogicalOperator(this.operator, this.clauses);

  @override
  BuiltWhereClause build() {
    if (clauses.isEmpty) {
      return BuiltWhereClause('', []);
    }
    final builtClauses = clauses.map((c) => c.build()).toList();
    final sql = '(${builtClauses.map((c) => c.sql).join(' $operator ')})';
    final parameters = builtClauses.expand((c) => c.parameters).toList();
    return BuiltWhereClause(sql, parameters);
  }

  @override
  QueryDependencies analyzeDependencies(AnalysisContext context) {
    var result = QueryDependencies.empty();
    
    // Merge dependencies from all child clauses
    for (final clause in clauses) {
      result = result.merge(clause.analyzeDependencies(context));
    }
    
    return result;
  }
}

Condition col(String column) => Condition(column);
LogicalOperator and(List<WhereClause> clauses) =>
    LogicalOperator('AND', clauses);
LogicalOperator or(List<WhereClause> clauses) => LogicalOperator('OR', clauses);

class Exists extends WhereClause {
  final QueryBuilder _subQuery;
  final bool _negated;

  Exists(this._subQuery, [this._negated = false]);

  @override
  BuiltWhereClause build() {
    final builtSubQuery = _subQuery.build();
    final subQuerySql = builtSubQuery.$1;
    final subQueryParameters = builtSubQuery.$2;
    final operator = _negated ? 'NOT EXISTS' : 'EXISTS';
    return BuiltWhereClause(
        '$operator ($subQuerySql)', subQueryParameters);
  }

  @override
  QueryDependencies analyzeDependencies(AnalysisContext context) {
    // Create a new context level for the subquery
    final subqueryContext = context.copy();
    subqueryContext.pushLevel();
    
    // Delegate to the subquery's dependency analysis
    return _subQuery.analyzeDependencies(subqueryContext);
  }
}

Exists exists(void Function(QueryBuilder) build) {
  final builder = QueryBuilder();
  build(builder);
  return Exists(builder);
}

Exists notExists(void Function(QueryBuilder) build) {
  final builder = QueryBuilder();
  build(builder);
  return Exists(builder, true);
}

class RawSqlWhereClause extends WhereClause {
  final String sql;
  final List<Object?>? parameters;

  RawSqlWhereClause(this.sql, [this.parameters]);

  @override
  BuiltWhereClause build() {
    return BuiltWhereClause(sql, parameters ?? []);
  }

  @override
  QueryDependencies analyzeDependencies(AnalysisContext context) {
    // For raw SQL, we can't analyze dependencies without parsing
    // This is a limitation that encourages use of structured queries
    return QueryDependencies.empty();
  }
}

<!-- END FILE: declarative_sqlite/lib/src/builders/where_clause.dart -->

<!-- BEGIN FILE: declarative_sqlite/lib/src/data_mapping.dart -->
import 'package:declarative_sqlite/src/declarative_database.dart';
import 'package:declarative_sqlite/src/files/fileset_field.dart';

/// Base class for mapping database rows to typed objects.
///
/// Generated code will create subclasses of this for each table/view.
abstract class DataMapper<T> {
  String get tableName;

  /// Creates an instance of [T] from a database row map.
  T fromMap(Map<String, dynamic> map);
}

/// Utility class for converting database values to appropriate types.
class DataMappingUtils {
  /// Creates a FilesetField from a database value.
  /// 
  /// [value] should be the fileset identifier (string) from the database.
  /// [database] is the DeclarativeDatabase instance.
  static FilesetField? filesetFieldFromValue(
    dynamic value,
    DeclarativeDatabase database,
  ) {
    if (value == null) return null;
    return FilesetField.fromDatabaseValue(value, database);
  }

  /// Converts a FilesetField back to a database value.
  /// 
  /// Returns the fileset identifier string or null.
  static String? filesetFieldToValue(FilesetField? field) {
    return field?.toDatabaseValue();
  }
}

<!-- END FILE: declarative_sqlite/lib/src/data_mapping.dart -->

<!-- BEGIN FILE: declarative_sqlite/lib/src/db_record.dart -->
import 'package:collection/collection.dart';
import 'package:declarative_sqlite/src/declarative_database.dart';
import 'package:declarative_sqlite/src/files/fileset_field.dart';
import 'package:declarative_sqlite/src/schema/db_column.dart';
import 'package:declarative_sqlite/src/schema/db_table.dart';
import 'package:declarative_sqlite/src/sync/hlc.dart';

/// Base class for typed database records.
///
/// Provides typed getters and setters with automatic conversion between
/// database values and Dart types, including special handling for:
/// - DateTime serialization/deserialization
/// - FilesetField conversion
/// - LWW (Last-Write-Wins) column updates
/// - Automatic dirty tracking for updates
/// - Read-only vs CRUD differentiation
abstract class DbRecord {
  final Map<String, Object?> _data;
  final String _tableName;
  final DeclarativeDatabase _database;
  final DbTable? _tableDefinition;
  final String? _updateTableName; // Table to target for CRUD operations

  /// Map to track which fields have been modified since creation
  final Set<String> _modifiedFields = <String>{};

  DbRecord(Map<String, Object?> data, this._tableName, this._database)
    : _data = Map<String, Object?>.from(data), 
    _tableDefinition = _database.schema.userTables.firstWhereOrNull(
        (table) => table.name == _tableName,
      ),
      _updateTableName = _tableName;

  /// Gets the table name for this record
  String get tableName => _tableName;

  /// Gets the table name that will be used for CRUD operations
  String? get updateTableName => _updateTableName;

  /// Checks if CRUD operations are allowed on this record's target table
  /// Returns true if the table is in the user tables list (not a view)
  bool get isCrudEnabled {
    final targetTable = _updateTableName ?? _tableName;
    return _database.schema.userTables.any((table) => table.name == targetTable);
  }

  /// Internal method to check CRUD permissions and throw if not allowed
  void _checkCrudPermission(String operation) {
    final targetTable = _updateTableName ?? _tableName;
    final isUserTable = _database.schema.userTables.any((table) => table.name == targetTable);
    
    if (!isUserTable) {
      throw StateError(
        'Cannot $operation record: table "$targetTable" is not a user table (may be a view or system table). Available user tables: ${_database.schema.userTables.map((t) => t.name).join(", ")}'
      );
    }
  }

  /// Gets the underlying data map (read-only copy)
  Map<String, Object?> get data => Map.unmodifiable(_data);

  /// Gets the set of fields that have been modified (read-only copy)
  Set<String> get modifiedFields => Set.unmodifiable(_modifiedFields);

  /// Gets the system_id for this record
  String? get systemId => getRawValue('system_id') as String?;

  /// Gets the system_created_at timestamp for this record
  DateTime? get systemCreatedAt {
    final value = getRawValue('system_created_at');
    return value != null ? _parseDateTime(value) : null;
  }

  /// Gets the system_version HLC for this record
  Hlc? get systemVersion {
    final value = getRawValue('system_version');
    return value != null ? Hlc.parse(value as String) : null;
  }

  /// Gets a raw value from the data map without type conversion
  Object? getRawValue(String columnName) {
    return _data[columnName];
  }

  /// Gets a typed value with automatic conversion based on column definition
  T? getValue<T>(String columnName) {
    final rawValue = _data[columnName];
    if (rawValue == null) return null;

    final column = _getColumn(columnName);
    if (column == null) {
      // Fallback for views or complex queries without schema info
      if (T == DateTime) {
        return _parseDateTime(rawValue) as T?;
      }
      if (T == FilesetField) {
        return _parseFilesetField(rawValue) as T?;
      }
      return rawValue as T?;
    }

    switch (column.logicalType) {
      case 'text':
      case 'guid':
        return rawValue as T;
      case 'integer':
        return rawValue as T;
      case 'real':
        return rawValue as T;
      case 'date':
        return _parseDateTime(rawValue) as T;
      case 'fileset':
        return _parseFilesetField(rawValue) as T;
      default:
        return rawValue as T;
    }
  }

  /// Sets a value with automatic conversion and LWW handling  
  /// Throws StateError if the target table doesn't support CRUD operations
  void setValue<T>(String columnName, T? value) {
    _checkCrudPermission('modify');

    // Validate that the column exists in the update table schema
    if (_tableDefinition != null) {
      final column = _getColumn(columnName);
      if (column == null) {
        throw ArgumentError(
          'Column $columnName does not exist in update table $_updateTableName',
        );
      }
    }

    final column = _getColumn(columnName);
    Object? databaseValue;

    switch (column?.logicalType ?? 'unknown') {
      case 'text':
      case 'guid':
      case 'integer':
      case 'real':
        databaseValue = value;
        break;
      case 'date':
        databaseValue = value != null
            ? _serializeDateTime(value as DateTime)
            : null;
        break;
      case 'fileset':
        databaseValue = value != null
            ? (value as FilesetField).toDatabaseValue()
            : null;
        break;
      default:
        databaseValue = value;
    }

    _data[columnName] = databaseValue;
    _modifiedFields.add(columnName);

    // Handle LWW column HLC updates
    if (column?.isLww == true) {
      final hlcColumnName = '${columnName}__hlc';
      final currentHlc = _database.hlcClock.now();
      _data[hlcColumnName] = currentHlc.toString();
      _modifiedFields.add(hlcColumnName);
    }
  }

  // Typed helper methods for generated code

  /// Gets a String value from the specified column.
  /// Returns null if the column value is null.
  String? getText(String columnName) => getValue<String>(columnName);

  /// Gets a non-null String value from the specified column.
  /// Throws if the column value is null.
  String getTextNotNull(String columnName) {
    final value = getText(columnName);
    if (value == null) {
      throw StateError(
        'Column $columnName is null but expected to be non-null',
      );
    }
    return value;
  }

  /// Gets an int value from the specified column.
  /// Returns null if the column value is null.
  int? getInteger(String columnName) => getValue<int>(columnName);

  /// Gets a non-null int value from the specified column.
  /// Throws if the column value is null.
  int getIntegerNotNull(String columnName) {
    final value = getInteger(columnName);
    if (value == null) {
      throw StateError(
        'Column $columnName is null but expected to be non-null',
      );
    }
    return value;
  }

  /// Gets a double value from the specified column.
  /// Returns null if the column value is null.
  double? getReal(String columnName) => getValue<double>(columnName);

  /// Gets a non-null double value from the specified column.
  /// Throws if the column value is null.
  double getRealNotNull(String columnName) {
    final value = getReal(columnName);
    if (value == null) {
      throw StateError(
        'Column $columnName is null but expected to be non-null',
      );
    }
    return value;
  }

  /// Gets a DateTime value from the specified column.
  /// Returns null if the column value is null.
  DateTime? getDateTime(String columnName) => getValue<DateTime>(columnName);

  /// Gets a non-null DateTime value from the specified column.
  /// Throws if the column value is null.
  DateTime getDateTimeNotNull(String columnName) {
    final value = getDateTime(columnName);
    if (value == null) {
      throw StateError(
        'Column $columnName is null but expected to be non-null',
      );
    }
    return value;
  }

  /// Gets a FilesetField value from the specified column.
  /// Returns null if the column value is null.
  FilesetField? getFilesetField(String columnName) =>
      getValue<FilesetField>(columnName);

  /// Gets a non-null FilesetField value from the specified column.
  /// Throws if the column value is null.
  FilesetField getFilesetFieldNotNull(String columnName) {
    final value = getFilesetField(columnName);
    if (value == null) {
      throw StateError(
        'Column $columnName is null but expected to be non-null',
      );
    }
    return value;
  }

  // Typed setter methods for generated code

  /// Sets a String value for the specified column.
  void setText(String columnName, String? value) => setValue(columnName, value);

  /// Sets an int value for the specified column.
  void setInteger(String columnName, int? value) => setValue(columnName, value);

  /// Sets a double value for the specified column.
  void setReal(String columnName, double? value) => setValue(columnName, value);

  /// Sets a DateTime value for the specified column.
  void setDateTime(String columnName, DateTime? value) =>
      setValue(columnName, value);

  /// Sets a FilesetField value for the specified column.
  void setFilesetField(String columnName, FilesetField? value) =>
      setValue(columnName, value);

  /// Saves any modified fields back to the database
  /// Throws StateError if the target table doesn't support CRUD operations
  Future<void> save() async {
    _checkCrudPermission('save');

    if (_modifiedFields.isEmpty) return;

    final systemId = this.systemId;
    if (systemId == null) {
      throw StateError('Cannot save record without system_id');
    }

    final systemVersion = this.systemVersion;
    if (systemVersion == null) {
      throw StateError('Cannot save record without system_version');
    }

    // Build update map with only modified fields (excluding system columns)
    final updateData = <String, Object?>{};
    for (final fieldName in _modifiedFields) {
      // Skip system columns - they're managed by the database layer
      if (!fieldName.startsWith('system_')) {
        updateData[fieldName] = _data[fieldName];
      }
    }

    if (updateData.isNotEmpty) {
      await _database.update(
        _updateTableName ?? _tableName,
        updateData,
        where: 'system_id = ?',
        whereArgs: [systemId],
      );
    }

    // Clear modified fields after successful save
    _modifiedFields.clear();
  }

  /// Creates a new record in the database with the current data
  /// Throws StateError if the target table doesn't support CRUD operations
  Future<void> insert() async {
    _checkCrudPermission('insert');

    // Remove system columns - they'll be added by the database layer
    final insertData = Map<String, Object?>.from(_data);
    insertData.removeWhere((key, value) => key.startsWith('system_'));

    await _database.insert(_updateTableName ?? _tableName, insertData);

    // Clear modified fields since this is a new record
    _modifiedFields.clear();
  }

  /// Deletes this record from the database
  /// Throws StateError if the target table doesn't support CRUD operations
  Future<void> delete() async {
    _checkCrudPermission('delete');

    final systemId = this.systemId;
    if (systemId == null) {
      throw StateError('Cannot delete record without system_id');
    }

    await _database.delete(
      _updateTableName ?? _tableName,
      where: 'system_id = ?',
      whereArgs: [systemId],
    );
  }

  /// Reloads this record from the database
  /// Only available for CRUD-enabled records as views cannot guarantee uniqueness
  Future<void> reload() async {
    _checkCrudPermission('reload');

    final systemId = this.systemId;
    if (systemId == null) {
      throw StateError('Cannot reload record without system_id');
    }

    final results = await _database.queryTable(
      _updateTableName ?? _tableName,
      where: 'system_id = ?',
      whereArgs: [systemId],
    );

    if (results.isEmpty) {
      throw StateError(
        'Record with system_id $systemId not found in table ${_updateTableName ?? _tableName}',
      );
    }

    // Update the data map with fresh data
    _data.clear();
    _data.addAll(results.first);

    // Clear modified fields since we have fresh data
    _modifiedFields.clear();
  }

  /// Gets the column definition for the specified column name
  DbColumn? _getColumn(String columnName) {
    return _tableDefinition?.columns.firstWhereOrNull(
      (col) => col.name == columnName,
    );
  }

  /// Parses a database value into a DateTime
  DateTime _parseDateTime(Object? value) {
    if (value == null || value == "") throw ArgumentError('Cannot parse null as DateTime');
    if (value is DateTime) return value;
    if (value is String) return DateTime.parse(value);
    if (value is int) return DateTime.fromMillisecondsSinceEpoch(value);
    throw ArgumentError('Cannot parse $value as DateTime');
  }

  /// Serializes a DateTime for database storage
  String _serializeDateTime(DateTime dateTime) {
    return dateTime.toIso8601String();
  }

  /// Parses a database value into a FilesetField
  FilesetField? _parseFilesetField(Object? value) {
    if (value == null) return null;
    return FilesetField.fromDatabaseValue(value, _database);
  }

  @override
  String toString() {
    return '$runtimeType($_tableName: $_data)';
  }

  @override
  bool operator ==(Object other) {
    if (identical(this, other)) return true;
    return other is DbRecord &&
        other._tableName == _tableName &&
        other._data.toString() == _data.toString();
  }

  @override
  int get hashCode => _tableName.hashCode ^ _data.toString().hashCode;

  Object? operator [](String key) {
    return data[key];
  }
}

<!-- END FILE: declarative_sqlite/lib/src/db_record.dart -->

<!-- BEGIN FILE: declarative_sqlite/lib/src/declarative_database.dart -->
import 'dart:async';
import 'dart:developer' as developer;

import 'package:declarative_sqlite/src/builders/query_builder.dart';
import 'package:declarative_sqlite/src/builders/where_clause.dart';
import 'package:declarative_sqlite/src/exceptions/db_exception_wrapper.dart';
import 'package:declarative_sqlite/src/db_record.dart';
import 'package:declarative_sqlite/src/record_factory.dart';
import 'package:declarative_sqlite/src/record_map_factory_registry.dart';
import 'package:declarative_sqlite/src/schema/db_column.dart';
import 'package:declarative_sqlite/src/schema/db_table.dart';
import 'package:declarative_sqlite/src/sync/sqlite_dirty_row_store.dart';
import 'package:sqflite_common/sqlite_api.dart' as sqflite;
import 'package:uuid/uuid.dart';

import 'files/file_repository.dart';
import 'files/fileset.dart';
import 'files/fileset_field.dart';
import 'migration/diff_schemas.dart';
import 'migration/generate_migration_scripts.dart';
import 'migration/introspect_schema.dart';
import 'schema/schema.dart';
import 'streaming/query_stream_manager.dart';
import 'streaming/streaming_query.dart';
import 'sync/hlc.dart';
import 'sync/dirty_row_store.dart';

/// A declarative SQLite database.
class DeclarativeDatabase {
  /// The underlying sqflite database.
  ///
  /// This is exposed for advanced use cases, but it's recommended to use the
  /// declarative API as much as possible.
  sqflite.DatabaseExecutor get db => _db;
  final sqflite.DatabaseExecutor _db;

  /// The schema for the database.
  final Schema schema;

  final DirtyRowStore? dirtyRowStore;

  /// The query stream manager for this database instance
  QueryStreamManager get streamManager => _streamManager;

  /// The repository for storing and retrieving file content.
  final IFileRepository fileRepository;

  /// The Hybrid Logical Clock for generating timestamps.
  final HlcClock hlcClock;

  final String? transactionId;

  /// API for interacting with filesets.
  late final FileSet files;

  /// Manager for streaming queries.
  late final QueryStreamManager _streamManager;

  /// Tracks table names that need notifications (used in transactions)
  final Set<String> _pendingNotifications = <String>{};

  final Map<String, DbRecord> _recordCache = {};

  DeclarativeDatabase._internal(
    this._db,
    this.schema,
    this.dirtyRowStore,
    this.hlcClock,
    this.fileRepository,
  ) : transactionId = null {
    files = FileSet(this);
    _streamManager = QueryStreamManager();
  }

  DeclarativeDatabase._inTransaction(
    this._db,
    this.schema,
    this.dirtyRowStore,
    this.hlcClock,
    this.fileRepository,
    this.transactionId, {
    QueryStreamManager? sharedStreamManager,
  }) : _streamManager = sharedStreamManager ?? QueryStreamManager() {
    files = FileSet(this);
  }

  // Cache and registry methods
  void registerRecord(DbRecord record) {
    final systemId = record.systemId;
    if (systemId != null) {
      _recordCache[systemId] = record;
    }
  }

  DbRecord? getRecordFromCache(String systemId) {
    return _recordCache[systemId];
  }

  /// Opens the database at the given [path].
  ///
  /// The [schema] is used to create and migrate the database.
  /// The [dirtyRowStore] is used to store and retrieve operations for CRDTs.
  /// The [databaseFactory] is used to open the database.
  /// 
  /// If [recreateDatabase] is true, the existing database file will be deleted
  /// before opening. This is useful for testing and demo data initialization.
  /// Defaults to false for production safety.
  /// 
  /// **SAFETY**: [recreateDatabase] only works in debug mode to prevent
  /// accidental data loss in production. In release mode, this parameter
  /// is ignored and an assertion error is thrown if set to true.
  static Future<DeclarativeDatabase> open(
    String path, {
    required sqflite.DatabaseFactory databaseFactory,
    required Schema schema,
    DirtyRowStore? dirtyRowStore,
    required IFileRepository fileRepository,
    bool isReadOnly = false,
    bool isSingleInstance = true,
    bool recreateDatabase = false,
  }) async {
    return await DbExceptionWrapper.wrapConnection(() async {
      // Safety check: recreateDatabase only works in debug mode
      assert(() {
        if (recreateDatabase && !isReadOnly) {
          // This assertion will only be active in debug mode
          return true;
        }
        return true;
      }(), 'recreateDatabase can only be used in debug mode for safety');
      
      // Delete existing database if recreation is requested
      if (recreateDatabase && !isReadOnly) {
        // Double check: only proceed if assertions are enabled (debug mode)
        var debugMode = false;
        assert(() {
          debugMode = true;
          return true;
        }());
        
        if (debugMode) {
          try {
            await databaseFactory.deleteDatabase(path);
          } catch (e) {
            // Ignore errors if database doesn't exist
          }
        } else {
          throw StateError(
            'recreateDatabase=true is not allowed in production/release mode. '
            'This is a safety measure to prevent accidental data loss.'
          );
        }
      }
      
      final db = await databaseFactory.openDatabase(
        path,
        options: sqflite.OpenDatabaseOptions(
          readOnly: isReadOnly,
          singleInstance: isSingleInstance,
        ),
      );

      // Migrate schema
      final liveSchemaHash = await _getSetting(db, 'schema_hash');
      final newSchemaHash = schema.toHash();
      if (newSchemaHash != liveSchemaHash) {
        developer.log('üîÑ Schema hash mismatch detected. Starting migration...', name: 'Migration');
        developer.log('  Current hash: $liveSchemaHash', name: 'Migration');
        developer.log('  Target hash:  $newSchemaHash', name: 'Migration');
        
        final liveSchema = await introspectSchema(db);
        developer.log('üìä Introspected current schema: ${liveSchema.tables.length} tables, ${liveSchema.views.length} views', name: 'Migration');
        
        final changes = diffSchemas(schema, liveSchema);
        developer.log('üîç Schema diff complete: ${changes.length} changes identified', name: 'Migration');
        
        final scripts = generateMigrationScripts(changes);
        developer.log('‚ö° Executing ${scripts.length} migration scripts...', name: 'Migration');
        
        for (int i = 0; i < scripts.length; i++) {
          final script = scripts[i];
          developer.log('üîß Executing script ${i + 1}/${scripts.length}: ${script.length > 100 ? '${script.substring(0, 100)}...' : script}', name: 'Migration');
          try {
            await db.execute(script);
            developer.log('  ‚úÖ Script ${i + 1} executed successfully', name: 'Migration');
          } catch (e) {
            developer.log('  ‚ùå Script ${i + 1} failed: $e', name: 'Migration');
            rethrow;
          }
        }
        
        await _setSetting(db, 'schema_hash', newSchemaHash);
        developer.log('‚úÖ Migration completed successfully! New schema hash: $newSchemaHash', name: 'Migration');
      } else {
        developer.log('‚ú® Schema is up to date (hash: $liveSchemaHash)', name: 'Migration');
      }

      // Initialize the dirty row store
      dirtyRowStore ??= SqliteDirtyRowStore();
      await dirtyRowStore?.init(db);

      // Get or create the persistent HLC node ID
      final nodeId =
          await _setSettingIfNotSet(db, 'hlc_node_id', () => Uuid().v4());

      final hlcClock = HlcClock(nodeId: nodeId);

      return DeclarativeDatabase._internal(
        db,
        schema,
        dirtyRowStore,
        hlcClock,
        fileRepository,
      );
    });
  }

  /// Closes the database.
  Future<void> close() async {
    await _streamManager.dispose();
    if (_db is sqflite.Database) {
      await _db.close();
    }
  }

  /// Executes a raw SQL statement.
  Future<void> execute(String sql, [List<Object?>? arguments]) async {
    await _db.execute(sql, arguments);
  }

  /// Executes a raw SQL query and returns a list of the results.
  Future<List<Map<String, Object?>>> rawQuery(
    String sql, [
    List<Object?>? arguments,
  ]) {
    return _db.rawQuery(sql, arguments);
  }

  /// Executes a raw SQL statement and returns the number of changes.
  Future<int> rawUpdate(
    String sql, [
    List<Object?>? arguments,
  ]) {
    return _db.rawUpdate(sql, arguments);
  }

  /// Executes a raw SQL INSERT query and returns the last inserted row ID.
  Future<int> rawInsert(
    String sql, [
    List<Object?>? arguments,
  ]) {
    return _db.rawInsert(sql, arguments);
  }

  /// Executes a raw SQL DELETE query and returns the number of changes.
  Future<int> rawDelete(
    String sql, [
    List<Object?>? arguments,
  ]) {
    return _db.rawDelete(sql, arguments);
  }

  // Helper and utility methods
  
  DbTable _getTableDefinition(String tableName) {
    return schema.tables.firstWhere(
      (t) => t.name == tableName,
      orElse: () =>
          throw ArgumentError('Table not found in schema: $tableName'),
    );
  }

  /// Converts a value for database storage using the same logic as DbRecord.setValue
  Object? _serializeValueForColumn(Object? value, DbColumn column) {
    if (value == null) return null;
    
    switch (column.logicalType) {
      case 'text':
      case 'guid':
      case 'integer':
      case 'real':
        return value;
      case 'date':
        if (value is DateTime) {
          return value.toIso8601String();
        } else if (value is String) {
          return value; // Assume already serialized
        } else {
          return value.toString();
        }
      case 'fileset':
        if (value is FilesetField) {
          return value.toDatabaseValue();
        }
        return value;
      default:
        return value;
    }
  }

  /// Serializes all values in a map according to their column definitions
  Map<String, Object?> _serializeValuesForTable(String tableName, Map<String, Object?> values) {
    final tableDef = _getTableDefinition(tableName);
    final serializedValues = <String, Object?>{};
    
    for (final entry in values.entries) {
      final columnName = entry.key;
      final value = entry.value;
      
      // Find the column definition
      final column = tableDef.columns.where((col) => col.name == columnName).firstOrNull;
      
      if (column != null) {
        // Serialize using column definition
        serializedValues[columnName] = _serializeValueForColumn(value, column);
      } else {
        // Column not found in schema - pass through as-is (might be system column)
        serializedValues[columnName] = value;
      }
    }
    
    return serializedValues;
  }

  /// Applies default values for columns that are missing from the provided values map
  /// or have null values when the column doesn't allow nulls
  Map<String, Object?> _applyDefaultValues(String tableName, Map<String, Object?> values) {
    final tableDef = _getTableDefinition(tableName);
    final valuesWithDefaults = <String, Object?>{...values};
    
    // Generate default values for missing columns or null values in non-null columns
    for (final col in tableDef.columns) {
      // Skip system columns - they're handled separately
      if (col.name.startsWith('system_')) continue;
      
      final hasValue = valuesWithDefaults.containsKey(col.name);
      final currentValue = valuesWithDefaults[col.name];
      final isNullValue = currentValue == null;
      
      // Apply default if:
      // 1. Column value is not provided, OR
      // 2. Column exists but is null and column doesn't allow nulls
      final shouldApplyDefault = !hasValue || (hasValue && isNullValue && col.isNotNull);
      
      if (shouldApplyDefault) {
        final defaultValue = col.getDefaultValue();
        if (defaultValue != null) {
          // Apply the same serialization logic as DbRecord.setValue
          final serializedValue = _serializeValueForColumn(defaultValue, col);
          valuesWithDefaults[col.name] = serializedValue;
        }
      }
    }
    
    return valuesWithDefaults;
  }

  /// Converts FilesetField values back to database strings before storing.
  Map<String, Object?> _convertFilesetFieldsToValues(
    String tableName,
    Map<String, Object?> values,
  ) {
    final tableDef = _getTableDefinition(tableName);
    final filesetColumns = tableDef.columns
        .where((col) => col.logicalType == 'fileset')
        .map((col) => col.name)
        .toSet();

    if (filesetColumns.isEmpty) return values;

    final convertedValues = <String, Object?>{...values};

    for (final columnName in filesetColumns) {
      if (convertedValues.containsKey(columnName)) {
        final value = convertedValues[columnName];
        if (value is FilesetField) {
          convertedValues[columnName] = value.toDatabaseValue();
        }
      }
    }

    return convertedValues;
  }

  /// Transforms raw query results by converting fileset columns to FilesetField objects.
  List<Map<String, Object?>> _transformFilesetColumns(
    String tableName,
    List<Map<String, Object?>> rawResults,
  ) {
    if (rawResults.isEmpty) return rawResults;

    // Get table definition to identify fileset columns
    final tableDef = _getTableDefinition(tableName);
    final filesetColumns = tableDef.columns
        .where((col) => col.logicalType == 'fileset')
        .map((col) => col.name)
        .toSet();

    if (filesetColumns.isEmpty) return rawResults;

    // Transform each row
    return rawResults.map((row) {
      final transformedRow = <String, Object?>{...row};

      for (final columnName in filesetColumns) {
        if (transformedRow.containsKey(columnName)) {
          final value = transformedRow[columnName];
          transformedRow[columnName] = _createFilesetField(value);
        }
      }

      return transformedRow;
    }).toList();
  }

  /// Creates a FilesetField from a database value.
  Object? _createFilesetField(Object? value) {
    if (value == null) return null;
    return FilesetField.fromDatabaseValue(value, this);
  }

  /// Validates that a query result meets the requirements for forUpdate
  void _validateForUpdateQuery(
      List<Map<String, Object?>> results, String updateTableName) {
    // Check that the update table exists in the schema
    schema.userTables.firstWhere(
      (table) => table.name == updateTableName,
      orElse: () =>
          throw ArgumentError('Update table $updateTableName not found in schema'),
    );

    if (results.isEmpty) return; // No results to validate

    final firstResult = results.first;

    // Verify that system_id is present
    if (!firstResult.containsKey('system_id') ||
        firstResult['system_id'] == null) {
      throw StateError(
          'Query with forUpdate(\'$updateTableName\') must include system_id column from the target table');
    }

    // Verify that system_version is present
    if (!firstResult.containsKey('system_version') ||
        firstResult['system_version'] == null) {
      throw StateError(
          'Query with forUpdate(\'$updateTableName\') must include system_version column from the target table');
    }
  }

  /// Determines if a QueryBuilder represents a simple table query (CRUD-enabled)
  /// vs a complex query or view query (read-only by default).
  ///
  /// A simple table query is one that:
  /// - Queries directly from a table (not a view)
  /// - Has no complex joins, subqueries, or aggregations
  /// - Can be safely updated via system_id
  bool _isSimpleTableQuery(QueryBuilder builder) {
    final tableName = builder.tableName;
    if (tableName == null) return false;

    // Check if the table name refers to an actual table (not a view)
    final isActualTable =
        schema.userTables.any((table) => table.name == tableName);
    if (!isActualTable) return false;

    // For now, we'll consider any direct table reference as "simple"
    // This could be enhanced to check for complex joins, aggregations, etc.
    // based on the QueryBuilder structure
    return true;
  }

  // Query methods (read operations)

  /// Executes a query built with a [QueryBuilder] and returns raw Map objects.
  ///
  /// This is a lower-level method. Most code should use query() to get
  /// typed DbRecord objects instead of raw maps.
  ///
  /// Example:
  /// ```dart
  /// final results = await db.queryMaps((q) => q.from('users'));
  /// final userName = results.first['name'] as String; // Manual casting needed
  /// ```
  Future<List<Map<String, Object?>>> queryMaps(
      void Function(QueryBuilder) onBuild) {
    final builder = QueryBuilder();
    onBuild(builder);
    return queryMapsWith(builder);
  }

  /// Executes a query built with a [QueryBuilder] and returns raw Map results.
  Future<List<Map<String, Object?>>> queryMapsWith(QueryBuilder builder) async {
    final (sql, params) = builder.build();
    final rawResults = await rawQuery(sql, params);

    // Apply fileset transformation if we have table context
    final tableName = builder.tableName;
    if (tableName != null) {
      return _transformFilesetColumns(tableName, rawResults);
    }

    return rawResults;
  }

  /// Creates a streaming query that emits new results whenever the underlying data changes.
  ///
  /// The [onBuild] callback is used to configure the query using a [QueryBuilder].
  /// The [mapper] function converts raw database rows to typed objects.
  ///
  /// Returns a [Stream] that emits a list of results whenever the query result changes.
  /// The stream will emit an initial result when subscribed to, and then emit new results
  /// whenever insert, update, delete, or bulkLoad operations affect the query dependencies.
  ///
  /// Example:
  /// ```dart
  /// final usersStream = db.stream<User>(
  ///   (q) => q.from('users').where(col('age').gt(18)),
  ///   (row) => User.fromMap(row),
  /// );
  ///
  /// usersStream.listen((users) {
  ///   print('Users updated: ${users.length}');
  /// });
  /// ```
  Stream<List<T>> stream<T>(
    void Function(QueryBuilder) onBuild,
    T Function(Map<String, Object?>) mapper,
  ) {
    final builder = QueryBuilder();
    onBuild(builder);
    return streamMapsWith(builder, mapper);
  }

  /// Creates a streaming query using an existing [QueryBuilder].
  ///
  /// See [stream] for more details.
  Stream<List<T>> streamMapsWith<T>(
    QueryBuilder builder,
    T Function(Map<String, Object?>) mapper,
  ) {
    final queryId = Uuid().v4();
    final streamingQuery = StreamingQuery.create(
      id: queryId,
      builder: builder,
      database: this,
      mapper: mapper,
    );

    // StreamingQuery will automatically register/unregister itself with the
    // QueryStreamManager when listeners subscribe/unsubscribe via _onListen/_onCancel
    return streamingQuery.stream;
  }

  /// Executes a query and returns typed DbRecord objects.
  ///
  /// This is the main query method that intelligently determines CRUD vs read-only
  /// behavior by inspecting the QueryBuilder:
  /// - Table queries (simple from('table')) ‚Üí CRUD-enabled
  /// - View queries ‚Üí Read-only
  /// - Complex queries with forUpdate('table') ‚Üí CRUD-enabled for specified table
  ///
  /// Examples:
  /// ```dart
  /// // Table query - CRUD enabled
  /// final users = await db.query((q) => q.from('users'));
  /// users.first.setValue('name', 'Updated');
  /// await users.first.save(); // ‚úÖ Works
  ///
  /// // View query - read-only
  /// final details = await db.query((q) => q.from('user_details_view'));
  /// details.first.setValue('name', 'Test'); // ‚ùå StateError
  ///
  /// // Complex query with forUpdate - CRUD enabled for target table
  /// final results = await db.query(
  ///   (q) => q.from('user_details_view').forUpdate('users')
  /// );
  /// results.first.setValue('name', 'Updated');
  /// await results.first.save(); // ‚úÖ Updates users table
  /// ```
  Future<List<DbRecord>> query(void Function(QueryBuilder) onBuild) async {
    final builder = QueryBuilder();
    onBuild(builder);
    return queryWith(builder);
  }

  /// Executes a query built with a [QueryBuilder] and returns typed DbRecord objects.
  Future<List<DbRecord>> queryWith(QueryBuilder builder) async {
    final results = await queryMapsWith(builder);
    final tableName = builder.tableName;
    final updateTableName = builder.updateTableName;

    if (tableName == null) {
      throw ArgumentError(
          'QueryBuilder must specify a table to return DbRecord objects');
    }

    // If forUpdate was specified, validate the requirements
    if (updateTableName != null) {
      _validateForUpdateQuery(results, updateTableName);

      // Return records configured for CRUD with the specified update table
      return RecordFactory.fromMapList(results, tableName, this);
    }

    // Determine if this is a table or view query by inspecting the QueryBuilder
    final isSimpleTableQuery = _isSimpleTableQuery(builder);

    if (isSimpleTableQuery) {
      // Simple table query - CRUD enabled by default
      return RecordFactory.fromMapList(results, tableName, this);
    } else {
      // View or complex query - read-only by default
      return RecordFactory.fromMapList(results, tableName, this);
    }
  }

  /// Creates a streaming query that returns typed DbRecord objects.
  ///
  /// Like the query() method, this intelligently determines CRUD vs read-only
  /// behavior by inspecting the QueryBuilder shape.
  ///
  /// Example:
  /// ```dart
  /// final usersStream = db.streamRecords(
  ///   (q) => q.from('users').where(col('age').gt(18)),
  /// );
  ///
  /// usersStream.listen((users) {
  ///   for (final user in users) {
  ///     print('User: ${user.getValue<String>('name')}');
  ///     user.setValue('last_seen', DateTime.now());
  ///     await user.save(); // ‚úÖ Works for table queries
  ///   }
  /// });
  /// ```
  Stream<List<DbRecord>> streamRecords(
    void Function(QueryBuilder) onBuild,
  ) {
    final builder = QueryBuilder();
    onBuild(builder);
    return streamRecordsWith(builder);
  }

  /// Creates a streaming query using an existing [QueryBuilder] that returns DbRecord objects.
  Stream<List<DbRecord>> streamRecordsWith(QueryBuilder builder) {
    final tableName = builder.tableName;
    final updateTableName = builder.updateTableName;

    if (tableName == null) {
      throw ArgumentError(
          'QueryBuilder must specify a table to return DbRecord objects');
    }

    return streamMapsWith(
      builder,
      (row) {
        // Validate forUpdate requirements on each emitted result
        if (updateTableName != null) {
          _validateForUpdateQuery([row], updateTableName);
          return RecordFactory.fromMap(row, tableName, this);
        }

        // Determine if this is a simple table query by inspecting the QueryBuilder
        final isSimpleTableQuery = _isSimpleTableQuery(builder);

        if (isSimpleTableQuery) {
          return RecordFactory.fromMap(row, tableName, this);
        } else {
          return RecordFactory.fromMap(row, tableName, this);
        }
      },
    );
  }

  // Typed query methods using RecordMapFactoryRegistry

  /// Executes a query and returns typed record objects using registered factories.
  ///
  /// The record type T must be registered with `RecordMapFactoryRegistry.register<T>()`.
  /// This method uses the same intelligent CRUD vs read-only detection as query().
  ///
  /// Example:
  /// ```dart
  /// // First register the factory
  /// RecordMapFactoryRegistry.register<User>(User.fromMap);
  ///
  /// // Then query with automatic typing
  /// final users = await db.queryTyped<User>((q) => q.from('users'));
  /// users.first.name = 'Updated'; // Direct property access
  /// await users.first.save(); // ‚úÖ Works for table queries
  /// ```
  Future<List<T>> queryTyped<T extends DbRecord>(
    void Function(QueryBuilder) onBuild,
  ) async {
    final builder = QueryBuilder();
    onBuild(builder);
    return queryTypedWith<T>(builder);
  }

  /// Executes a query using an existing QueryBuilder and returns typed record objects.
  Future<List<T>> queryTypedWith<T extends DbRecord>(
      QueryBuilder builder) async {
    final results = await queryMapsWith(builder);
    final factory = RecordMapFactoryRegistry.getFactory<T>();

    return results.map((row) => factory(row, this)).toList();
  }

  /// Creates a streaming query that returns typed record objects using registered factories.
  ///
  /// Uses the same intelligent CRUD vs read-only detection as stream().
  Stream<List<T>> streamTyped<T extends DbRecord>(
    void Function(QueryBuilder) onBuild,
  ) {
    final builder = QueryBuilder();
    onBuild(builder);
    return streamTypedWith<T>(builder);
  }

  /// Creates a streaming query using an existing QueryBuilder that returns typed record objects.
  Stream<List<T>> streamTypedWith<T extends DbRecord>(QueryBuilder builder) {
    final factory = RecordMapFactoryRegistry.getFactory<T>();

    return streamMapsWith(
      builder,
      (row) => factory(row, this),
    );
  }

  /// Creates a transaction and runs the given [action] in it.
  ///
  /// The [action] is provided with a new [DeclarativeDatabase] instance that
  /// is bound to the transaction.
  Future<T> transaction<T>(
    Future<T> Function(DeclarativeDatabase txn) action, {
    bool? exclusive,
  }) async {
    return await DbExceptionWrapper.wrapTransaction(() async {
      if (_db is! sqflite.Database) {
        throw StateError('Cannot start a transaction within a transaction.');
      }
      final txnId = Uuid().v4();
      return _db.transaction(
        (txn) async {
          final db = DeclarativeDatabase._inTransaction(
            txn,
            schema,
            dirtyRowStore,
            hlcClock,
            fileRepository,
            txnId,
            sharedStreamManager: _streamManager,
          );
          
          try {
            final result = await action(db);
            
            // Transaction succeeded - notify for all pending changes
            await Future.wait(
              db._pendingNotifications.map(
                (tableName) => _streamManager.notifyTableChanged(tableName)
              )
            );
            
            return result;
          } catch (e) {
            // Transaction failed - clear pending notifications without sending
            db._pendingNotifications.clear();
            rethrow;
          }
        },
        exclusive: exclusive,
      );
    });
  }

  /// Inserts a row into the given [tableName].
  ///
  /// Returns the System ID of the last inserted row.
  Future<String> insert(String tableName, Map<String, Object?> values) async {
    return await DbExceptionWrapper.wrapCreate(() async {
      final now = hlcClock.now();
      
      // Serialize input values using column definitions
      final serializedValues = _serializeValuesForTable(tableName, values);
      
      final systemId = await _insert(tableName, serializedValues, now);
      await dirtyRowStore?.add(tableName, systemId, now);

      // Notify streaming queries of the change (or defer if in transaction)
      if (transactionId != null) {
        _pendingNotifications.add(tableName);
      } else {
        await _streamManager.notifyTableChanged(tableName);
      }

      return systemId;
    }, tableName: tableName);
  }

  Future<String> _insert(
      String tableName, Map<String, Object?> values, Hlc hlc) async {
    final tableDef = _getTableDefinition(tableName);

    // Convert FilesetField values to database strings
    final convertedValues = _convertFilesetFieldsToValues(tableName, values);

    // Apply default values for missing columns
    final valuesToInsert = _applyDefaultValues(tableName, convertedValues);
    
    // Add system columns
    valuesToInsert['system_version'] = hlc.toString();
    if (valuesToInsert['system_id'] == null) {
      valuesToInsert['system_id'] = Uuid().v4();
    }
    if (valuesToInsert['system_created_at'] == null) {
      valuesToInsert['system_created_at'] = hlc.toString();
    }

    for (final col in tableDef.columns) {
      if (col.isLww) {
        valuesToInsert['${col.name}__hlc'] = hlc.toString();
      }
    }

    await _db.insert(tableName, valuesToInsert);

    return valuesToInsert['system_id']! as String;
  }

  /// Updates rows in the given [tableName].
  ///
  /// The [values] are the new values for the rows.
  /// The [where] and [whereArgs] are used to filter the rows to update.
  ///
  /// Returns the number of rows updated.
  Future<int> update(
    String tableName,
    Map<String, Object?> values, {
    String? where,
    List<Object?>? whereArgs,
  }) async {
    return await DbExceptionWrapper.wrapUpdate(() async {
      final rowsToUpdate = await query(
        (q) {
          q.from(tableName).select('system_id');
          if (where != null) {
            q.where(RawSqlWhereClause(where, whereArgs));
          }
        },
      );

      // Serialize input values using column definitions
      final serializedValues = _serializeValuesForTable(tableName, values);

      final now = hlcClock.now();
      final result = await _update(
        tableName,
        serializedValues,
        now,
        where: where,
        whereArgs: whereArgs,
      );

      if (result > 0) {
        for (final row in rowsToUpdate) {
          await dirtyRowStore?.add(
              tableName, row.getValue<String>('system_id')!, now);
        }
        // Notify streaming queries of the change (or defer if in transaction)
        if (transactionId != null) {
          _pendingNotifications.add(tableName);
        } else {
          await _streamManager.notifyTableChanged(tableName);
        }
      }

      return result;
    }, tableName: tableName);
  }

  Future<int> _update(
    String tableName,
    Map<String, Object?> values,
    Hlc hlc, {
    String? where,
    List<Object?>? whereArgs,
  }) async {
    final tableDef = _getTableDefinition(tableName);

    // Convert FilesetField values to database strings
    final convertedValues = _convertFilesetFieldsToValues(tableName, values);

    final lwwColumns =
        tableDef.columns.where((c) => c.isLww).map((c) => c.name);

    final valuesToUpdate = {...convertedValues};
    valuesToUpdate['system_version'] = hlc.toString();

    if (lwwColumns.isNotEmpty) {
      // We need to check the HLCs of the existing rows to see if we can
      // update them.
      final existingRows = await queryMaps(
        (q) {
          q.from(tableName)
              .select(lwwColumns.map((c) => '${c}__hlc').toList().join(', '));
          if (where != null) {
            q.where(RawSqlWhereClause(where, whereArgs));
          }
        },
      );

      if (existingRows.isNotEmpty) {
        final existingHlcs = existingRows.first;
        for (final colName in values.keys) {
          if (lwwColumns.contains(colName)) {
            final hlcColName = '${colName}__hlc';
            final existingHlc = existingHlcs[hlcColName] != null
                ? Hlc.parse(existingHlcs[hlcColName] as String)
                : null;
            if (existingHlc == null || hlc.compareTo(existingHlc) > 0) {
              valuesToUpdate[hlcColName] = hlc.toString();
            } else {
              // The value in the database is newer, so we remove this
              // column from the update.
              valuesToUpdate.remove(colName);
            }
          }
        }
      }
    }

    if (valuesToUpdate.length == 1 &&
        valuesToUpdate.containsKey('system_version')) {
      // Nothing to update except the system version, so we can skip this.
      return 0;
    }

    return _db.update(
      tableName,
      valuesToUpdate,
      where: where,
      whereArgs: whereArgs,
    );
  }

  /// Deletes rows from the given [tableName].
  ///
  /// The [where] and [whereArgs] are used to filter the rows to delete.
  ///
  /// Returns the number of rows deleted.
  Future<int> delete(
    String tableName, {
    String? where,
    List<Object?>? whereArgs,
  }) async {
    return await DbExceptionWrapper.wrapDelete(() async {
      // Make sure the table exists or throw an exception
      final _ = _getTableDefinition(tableName);

      final rowsToDelete = await query(
        (q) {
          q.from(tableName).select('system_id');
          if (where != null) {
            q.where(RawSqlWhereClause(where, whereArgs));
          }
        },
      );

      final result = await _db.delete(
        tableName,
        where: where,
        whereArgs: whereArgs,
      );

      if (result > 0) {
        final now = hlcClock.now();
        for (final row in rowsToDelete) {
          await dirtyRowStore?.add(
              tableName, row.getValue<String>('system_id')!, now);
        }
        // Notify streaming queries of the change (or defer if in transaction)
        if (transactionId != null) {
          _pendingNotifications.add(tableName);
        } else {
          await _streamManager.notifyTableChanged(tableName);
        }
      }

      return result;
    }, tableName: tableName);
  }

  /// Queries the given [table] and returns a list of the results.
  Future<List<Map<String, Object?>>> queryTable(
    String table, {
    bool? distinct,
    List<String>? columns,
    String? where,
    List<Object?>? whereArgs,
    String? groupBy,
    String? having,
    String? orderBy,
    int? limit,
    int? offset,
  }) async {
    return await DbExceptionWrapper.wrapRead(() async {
      final rawResults = await _db.query(
        table,
        distinct: distinct,
        columns: columns,
        where: where,
        whereArgs: whereArgs,
        groupBy: groupBy,
        having: having,
        orderBy: orderBy,
        limit: limit,
        offset: offset,
      );

      return _transformFilesetColumns(table, rawResults);
    }, tableName: table);
  }

  /// Queries a query and returns a single result, or null if none is found.
  Future<Map<String, Object?>?> queryFirst(
    String table, {
    bool? distinct,
    List<String>? columns,
    String? where,
    List<Object?>? whereArgs,
    String? groupBy,
    String? having,
    String? orderBy,
    int? offset,
  }) async {
    final results = await queryTable(
      table,
      distinct: distinct,
      columns: columns,
      where: where,
      whereArgs: whereArgs,
      groupBy: groupBy,
      having: having,
      orderBy: orderBy,
      limit: 1,
      offset: offset,
    );
    return results.isNotEmpty ? results.first : null;
  }

  /// Queries an entire table and returns typed record objects using registered factories.
  ///
  /// The record type T must be registered with `RecordMapFactoryRegistry.register<T>()`.
  ///
  /// Example:
  /// ```dart
  /// // First register the factory
  /// RecordMapFactoryRegistry.register<User>(User.fromMap);
  ///
  /// // Then query the whole table
  /// final allUsers = await db.queryTableTyped<User>('users');
  /// ```
  Future<List<T>> queryTableTyped<T extends DbRecord>(
    String tableName, {
    bool? distinct,
    List<String>? columns,
    String? where,
    List<Object?>? whereArgs,
    String? groupBy,
    String? having,
    String? orderBy,
    int? limit,
    int? offset,
  }) async {
    final results = await queryTable(
      tableName,
      distinct: distinct,
      columns: columns,
      where: where,
      whereArgs: whereArgs,
      groupBy: groupBy,
      having: having,
      orderBy: orderBy,
      limit: limit,
      offset: offset,
    );
    final factory = RecordMapFactoryRegistry.getFactory<T>();
    return results.map((row) => factory(row, this)).toList();
  }

  /// Bulk loads data into a table, performing an "upsert" operation.
  ///
  /// This method is designed for loading data from a sync source. It respects
  /// LWW (Last-Write-Wins) semantics for columns marked as such.
  ///
  /// For each row in [rows]:
  /// - If a local row with the same `system_id` exists, it's an UPDATE.
  ///   - LWW columns are only updated if the incoming HLC is newer.
  ///   - Regular columns are always updated.
  /// - If no local row exists, it's an INSERT.
  ///
  /// Rows processed by this method are NOT marked as dirty.
  Future<void> bulkLoad(
      String tableName, List<Map<String, Object?>> rows) async {
    final tableDef = _getTableDefinition(tableName);
    final pkColumns = tableDef.keys
        .where((k) => k.isPrimary)
        .expand((k) => k.columns)
        .toSet();
    final lwwColumns =
        tableDef.columns.where((c) => c.isLww).map((c) => c.name).toSet();

    await transaction((db) async {
      for (final row in rows) {
        final systemId = row['system_id'] as String?;
        if (systemId == null) continue;

        final existing = await db.query(
          (q) => q
              .from(tableName)
              .where(RawSqlWhereClause('system_id = ?', [systemId])).limit(1),
        );

        if (existing.isNotEmpty) {
          // UPDATE logic
          final existingRow = existing.first;
          final valuesToUpdate = <String, Object?>{};
          final now = hlcClock.now();

          for (final entry in row.entries) {
            final colName = entry.key;
            if (pkColumns.contains(colName) || colName.endsWith('__hlc')) {
              continue;
            }

            if (lwwColumns.contains(colName)) {
              final hlcColName = '${colName}__hlc';
              final remoteHlcString = row[hlcColName] as String?;

              if (remoteHlcString != null) {
                // If HLC is provided, do a proper LWW comparison.
                final localHlcString =
                    existingRow.getValue<String?>(hlcColName);
                final localHlc =
                    localHlcString != null ? Hlc.parse(localHlcString) : null;
                final remoteHlc = Hlc.parse(remoteHlcString);

                if (localHlc == null || remoteHlc.compareTo(localHlc) > 0) {
                  valuesToUpdate[colName] = entry.value;
                  valuesToUpdate[hlcColName] = remoteHlc.toString();
                }
              } else {
                // If no HLC is provided, the server value wins (non-LWW update).
                valuesToUpdate[colName] = entry.value;
              }
            } else {
              // Regular column, always update.
              valuesToUpdate[colName] = entry.value;
            }
          }

          if (valuesToUpdate.isNotEmpty) {
            await db._update(
              tableName,
              valuesToUpdate,
              now,
              where: 'system_id = ?',
              whereArgs: [systemId],
            );
          }
        } else {
          // INSERT logic
          await db._insert(tableName, row, hlcClock.now());
        }
      }
    });

    // Notify streaming queries of the change (or defer if in transaction)
    if (transactionId != null) {
      _pendingNotifications.add(tableName);
    } else {
      await _streamManager.notifyTableChanged(tableName);
    }
  }

}

// Static helper methods for settings
Future<String> _setSettingIfNotSet(
  sqflite.DatabaseExecutor db,
  String key,
  String Function() defaultFactory,
) async {
  var result = await _getSetting(db, key);
  result ??= await _setSetting(db, key, defaultFactory());
  return result;
}

Future<String> _setSetting(
  sqflite.DatabaseExecutor db,
  String key,
  String value,
) async {
  await db.insert(
    '__settings',
    {
      'key': key,
      'value': value,
    },
    conflictAlgorithm: sqflite.ConflictAlgorithm.replace,
  );
  return value;
}

Future<String?> _getSetting(
  sqflite.DatabaseExecutor db,
  String key,
) async {
  try {
    final result = await db.query('__settings',
        where: 'key = ?', whereArgs: [key], limit: 1, columns: ['value']);
    if (result.isNotEmpty) {
      return result.first['value'] as String?;
    }
  } on Exception {
    // Ignore any errors, most likely due to missing table,
    // in which case, there's nothing to do but to return null
  }
  return null;
}

<!-- END FILE: declarative_sqlite/lib/src/declarative_database.dart -->

<!-- BEGIN FILE: declarative_sqlite/lib/src/exceptions/db_exception_mapper.dart -->
import 'package:sqflite_common/sqlite_api.dart' as sqflite;
import 'db_exceptions.dart';

/// Utility class for mapping platform-specific database exceptions
/// to developer-friendly DbException types
class DbExceptionMapper {
  /// Maps a platform exception to a DbException based on operation type and error details
  static DbException mapException(
    Exception originalException,
    DbOperationType operationType, {
    String? tableName,
    String? columnName,
    Map<String, Object?>? context,
  }) {
    final errorMessage = originalException.toString();
    final lowerErrorMessage = errorMessage.toLowerCase();

    // Extract table name from error message if not provided
    final inferredTableName = tableName ?? _extractTableNameFromError(errorMessage);

    // Determine error category based on the exception type and message
    final errorCategory = _categorizeError(originalException, lowerErrorMessage);

    // Create appropriate exception based on operation type
    switch (operationType) {
      case DbOperationType.create:
        return _createInsertException(
          errorCategory,
          originalException,
          inferredTableName,
          columnName,
          context,
        );

      case DbOperationType.read:
        return _createReadException(
          errorCategory,
          originalException,
          inferredTableName,
          columnName,
          context,
        );

      case DbOperationType.update:
        return _createUpdateException(
          errorCategory,
          originalException,
          inferredTableName,
          columnName,
          context,
        );

      case DbOperationType.delete:
        return _createDeleteException(
          errorCategory,
          originalException,
          inferredTableName,
          context,
        );

      case DbOperationType.transaction:
        return _createTransactionException(
          errorCategory,
          originalException,
          context,
        );

      case DbOperationType.connection:
        return _createConnectionException(
          errorCategory,
          originalException,
          context,
        );

      case DbOperationType.migration:
        return _createMigrationException(
          errorCategory,
          originalException,
          context,
        );
    }
  }

  /// Categorizes an error based on the exception type and message content
  static DbErrorCategory _categorizeError(Exception originalException, String lowerErrorMessage) {
    // Check for SQLite-specific error codes and messages
    if (originalException is sqflite.DatabaseException) {
      final sqliteException = originalException;
      
      // Check by error codes first (more reliable)
      if (sqliteException.toString().contains('SQLITE_CONSTRAINT')) {
        return DbErrorCategory.constraintViolation;
      }
      
      if (sqliteException.toString().contains('SQLITE_BUSY') ||
          sqliteException.toString().contains('SQLITE_LOCKED')) {
        return DbErrorCategory.databaseLocked;
      }
      
      if (sqliteException.toString().contains('SQLITE_CORRUPT')) {
        return DbErrorCategory.corruption;
      }
      
      if (sqliteException.toString().contains('SQLITE_NOTFOUND') ||
          sqliteException.toString().contains('no such table') ||
          sqliteException.toString().contains('no such column')) {
        return DbErrorCategory.notFound;
      }
    }

    // Fallback to message-based detection
    if (lowerErrorMessage.contains('constraint') ||
        lowerErrorMessage.contains('unique') ||
        lowerErrorMessage.contains('foreign key') ||
        lowerErrorMessage.contains('primary key') ||
        lowerErrorMessage.contains('check constraint')) {
      return DbErrorCategory.constraintViolation;
    }

    if (lowerErrorMessage.contains('not found') ||
        lowerErrorMessage.contains('no such table') ||
        lowerErrorMessage.contains('no such column') ||
        lowerErrorMessage.contains('does not exist')) {
      return DbErrorCategory.notFound;
    }

    if (lowerErrorMessage.contains('locked') ||
        lowerErrorMessage.contains('busy') ||
        lowerErrorMessage.contains('timeout')) {
      return DbErrorCategory.databaseLocked;
    }

    if (lowerErrorMessage.contains('corrupt') ||
        lowerErrorMessage.contains('malformed')) {
      return DbErrorCategory.corruption;
    }

    if (lowerErrorMessage.contains('permission') ||
        lowerErrorMessage.contains('access denied') ||
        lowerErrorMessage.contains('unauthorized')) {
      return DbErrorCategory.accessDenied;
    }

    if (lowerErrorMessage.contains('invalid') ||
        lowerErrorMessage.contains('syntax error') ||
        lowerErrorMessage.contains('datatype mismatch')) {
      return DbErrorCategory.invalidData;
    }

    if (lowerErrorMessage.contains('conflict') ||
        lowerErrorMessage.contains('concurrent') ||
        lowerErrorMessage.contains('version')) {
      return DbErrorCategory.concurrencyConflict;
    }

    if (lowerErrorMessage.contains('schema') ||
        lowerErrorMessage.contains('migration')) {
      return DbErrorCategory.schemaMismatch;
    }

    if (lowerErrorMessage.contains('connection') ||
        lowerErrorMessage.contains('network') ||
        lowerErrorMessage.contains('disconnected')) {
      return DbErrorCategory.connectionError;
    }

    return DbErrorCategory.unknown;
  }

  /// Extracts table name from error message if possible
  static String? _extractTableNameFromError(String errorMessage) {
    // Try to extract table name from common error patterns
    final patterns = [
      RegExp(r'table (?:"|`)?(\w+)(?:"|`)?', caseSensitive: false),
      RegExp(r'in table (?:"|`)?(\w+)(?:"|`)?', caseSensitive: false),
      RegExp(r'on table (?:"|`)?(\w+)(?:"|`)?', caseSensitive: false),
    ];

    for (final pattern in patterns) {
      final match = pattern.firstMatch(errorMessage);
      if (match != null) {
        return match.group(1);
      }
    }

    return null;
  }

  static DbCreateException _createInsertException(
    DbErrorCategory errorCategory,
    Exception originalException,
    String? tableName,
    String? columnName,
    Map<String, Object?>? context,
  ) {
    switch (errorCategory) {
      case DbErrorCategory.constraintViolation:
        return DbCreateException.constraintViolation(
          message: _getConstraintViolationMessage(originalException, tableName, columnName),
          tableName: tableName,
          columnName: columnName,
          originalException: originalException,
          context: context,
        );

      case DbErrorCategory.invalidData:
        return DbCreateException.invalidData(
          message: _getInvalidDataMessage(originalException, tableName, columnName),
          tableName: tableName,
          columnName: columnName,
          originalException: originalException,
          context: context,
        );

      default:
        return DbCreateException(
          errorCategory: errorCategory,
          message: 'Failed to create record${tableName != null ? ' in table $tableName' : ''}',
          tableName: tableName,
          columnName: columnName,
          originalException: originalException,
          context: context,
        );
    }
  }

  static DbReadException _createReadException(
    DbErrorCategory errorCategory,
    Exception originalException,
    String? tableName,
    String? columnName,
    Map<String, Object?>? context,
  ) {
    switch (errorCategory) {
      case DbErrorCategory.notFound:
        return DbReadException.notFound(
          message: 'Record or resource not found${tableName != null ? ' in table $tableName' : ''}',
          tableName: tableName,
          originalException: originalException,
          context: context,
        );

      case DbErrorCategory.accessDenied:
        return DbReadException.accessDenied(
          message: 'Access denied when reading${tableName != null ? ' from table $tableName' : ''}',
          tableName: tableName,
          originalException: originalException,
          context: context,
        );

      default:
        return DbReadException(
          errorCategory: errorCategory,
          message: 'Failed to read record${tableName != null ? ' from table $tableName' : ''}',
          tableName: tableName,
          columnName: columnName,
          originalException: originalException,
          context: context,
        );
    }
  }

  static DbUpdateException _createUpdateException(
    DbErrorCategory errorCategory,
    Exception originalException,
    String? tableName,
    String? columnName,
    Map<String, Object?>? context,
  ) {
    switch (errorCategory) {
      case DbErrorCategory.constraintViolation:
        return DbUpdateException.constraintViolation(
          message: _getConstraintViolationMessage(originalException, tableName, columnName),
          tableName: tableName,
          columnName: columnName,
          originalException: originalException,
          context: context,
        );

      case DbErrorCategory.concurrencyConflict:
        return DbUpdateException.concurrencyConflict(
          message: 'Concurrency conflict when updating${tableName != null ? ' table $tableName' : ''}',
          tableName: tableName,
          originalException: originalException,
          context: context,
        );

      case DbErrorCategory.notFound:
        return DbUpdateException.notFound(
          message: 'Record to update not found${tableName != null ? ' in table $tableName' : ''}',
          tableName: tableName,
          originalException: originalException,
          context: context,
        );

      default:
        return DbUpdateException(
          errorCategory: errorCategory,
          message: 'Failed to update record${tableName != null ? ' in table $tableName' : ''}',
          tableName: tableName,
          columnName: columnName,
          originalException: originalException,
          context: context,
        );
    }
  }

  static DbDeleteException _createDeleteException(
    DbErrorCategory errorCategory,
    Exception originalException,
    String? tableName,
    Map<String, Object?>? context,
  ) {
    switch (errorCategory) {
      case DbErrorCategory.constraintViolation:
        return DbDeleteException.constraintViolation(
          message: 'Cannot delete record due to foreign key constraint${tableName != null ? ' in table $tableName' : ''}',
          tableName: tableName,
          originalException: originalException,
          context: context,
        );

      case DbErrorCategory.notFound:
        return DbDeleteException.notFound(
          message: 'Record to delete not found${tableName != null ? ' in table $tableName' : ''}',
          tableName: tableName,
          originalException: originalException,
          context: context,
        );

      default:
        return DbDeleteException(
          errorCategory: errorCategory,
          message: 'Failed to delete record${tableName != null ? ' from table $tableName' : ''}',
          tableName: tableName,
          originalException: originalException,
          context: context,
        );
    }
  }

  static DbTransactionException _createTransactionException(
    DbErrorCategory errorCategory,
    Exception originalException,
    Map<String, Object?>? context,
  ) {
    switch (errorCategory) {
      case DbErrorCategory.databaseLocked:
        return DbTransactionException.databaseLocked(
          message: 'Database is locked and transaction cannot proceed',
          originalException: originalException,
          context: context,
        );

      default:
        return DbTransactionException.rollback(
          message: 'Transaction failed and was rolled back',
          originalException: originalException,
          context: context,
        );
    }
  }

  static DbConnectionException _createConnectionException(
    DbErrorCategory errorCategory,
    Exception originalException,
    Map<String, Object?>? context,
  ) {
    switch (errorCategory) {
      case DbErrorCategory.corruption:
        return DbConnectionException.corruption(
          message: 'Database file is corrupted and cannot be opened',
          originalException: originalException,
          context: context,
        );

      default:
        return DbConnectionException.connectionFailed(
          message: 'Failed to establish database connection',
          originalException: originalException,
          context: context,
        );
    }
  }

  static DbMigrationException _createMigrationException(
    DbErrorCategory errorCategory,
    Exception originalException,
    Map<String, Object?>? context,
  ) {
    return DbMigrationException.schemaMismatch(
      message: 'Database schema migration failed',
      originalException: originalException,
      context: context,
    );
  }

  static String _getConstraintViolationMessage(
    Exception originalException,
    String? tableName,
    String? columnName,
  ) {
    final errorMessage = originalException.toString().toLowerCase();
    
    if (errorMessage.contains('unique')) {
      return 'Unique constraint violation${columnName != null ? ' on column $columnName' : ''}${tableName != null ? ' in table $tableName' : ''}';
    }
    
    if (errorMessage.contains('foreign key')) {
      return 'Foreign key constraint violation${tableName != null ? ' in table $tableName' : ''}';
    }
    
    if (errorMessage.contains('primary key')) {
      return 'Primary key constraint violation${tableName != null ? ' in table $tableName' : ''}';
    }
    
    if (errorMessage.contains('check')) {
      return 'Check constraint violation${columnName != null ? ' on column $columnName' : ''}${tableName != null ? ' in table $tableName' : ''}';
    }
    
    return 'Constraint violation${tableName != null ? ' in table $tableName' : ''}';
  }

  static String _getInvalidDataMessage(
    Exception originalException,
    String? tableName,
    String? columnName,
  ) {
    final errorMessage = originalException.toString().toLowerCase();
    
    if (errorMessage.contains('datatype mismatch')) {
      return 'Data type mismatch${columnName != null ? ' for column $columnName' : ''}${tableName != null ? ' in table $tableName' : ''}';
    }
    
    if (errorMessage.contains('syntax error')) {
      return 'Invalid SQL syntax in query';
    }
    
    return 'Invalid data provided${tableName != null ? ' for table $tableName' : ''}';
  }
}
<!-- END FILE: declarative_sqlite/lib/src/exceptions/db_exception_mapper.dart -->

<!-- BEGIN FILE: declarative_sqlite/lib/src/exceptions/db_exception_wrapper.dart -->
import 'dart:async';
import 'dart:developer' as developer;
import 'db_exceptions.dart';
import 'db_exception_mapper.dart';

/// Utility class for wrapping database operations with exception handling
/// 
/// Automatically catches platform-specific exceptions and converts them
/// to developer-friendly DbException types.
class DbExceptionWrapper {
  /// Wraps a database create operation with exception handling
  static Future<T> wrapCreate<T>(
    Future<T> Function() operation, {
    String? tableName,
    String? columnName,
    Map<String, Object?>? context,
  }) async {
    try {
      return await operation();
    } on DbException {
      // Re-throw already wrapped exceptions
      rethrow;
    } on Exception catch (e) {
      final dbException = DbExceptionMapper.mapException(
        e,
        DbOperationType.create,
        tableName: tableName,
        columnName: columnName,
        context: context,
      );
      
      // Log constraint violations for developer debugging with severity-based levels
      if (dbException.errorCategory == DbErrorCategory.constraintViolation) {
        final constraintType = _getConstraintType(dbException.message);
        final logLevel = _getConstraintLogLevel(constraintType);
        final emoji = _getConstraintEmoji(constraintType);
        
        developer.log(
          '$emoji Constraint violation in CREATE: ${dbException.message}${tableName != null ? ' [table: $tableName]' : ''}${columnName != null ? ' [column: $columnName]' : ''} [type: $constraintType]',
          name: 'DbConstraint${constraintType.name}',
          level: logLevel,
          error: e,
        );
      }
      
      throw dbException;
    }
  }

  /// Wraps a database read operation with exception handling
  static Future<T> wrapRead<T>(
    Future<T> Function() operation, {
    String? tableName,
    String? columnName,
    Map<String, Object?>? context,
  }) async {
    try {
      return await operation();
    } on DbException {
      // Re-throw already wrapped exceptions
      rethrow;
    } on Exception catch (e) {
      final dbException = DbExceptionMapper.mapException(
        e,
        DbOperationType.read,
        tableName: tableName,
        columnName: columnName,
        context: context,
      );
      
      // Log constraint violations for developer debugging with severity-based levels
      if (dbException.errorCategory == DbErrorCategory.constraintViolation) {
        final constraintType = _getConstraintType(dbException.message);
        final logLevel = _getConstraintLogLevel(constraintType);
        final emoji = _getConstraintEmoji(constraintType);
        
        developer.log(
          '$emoji Constraint violation in READ: ${dbException.message}${tableName != null ? ' [table: $tableName]' : ''}${columnName != null ? ' [column: $columnName]' : ''} [type: $constraintType]',
          name: 'DbConstraint${constraintType.name}',
          level: logLevel,
          error: e,
        );
      }
      
      throw dbException;
    }
  }

  /// Wraps a database update operation with exception handling
  static Future<T> wrapUpdate<T>(
    Future<T> Function() operation, {
    String? tableName,
    String? columnName,
    Map<String, Object?>? context,
  }) async {
    try {
      return await operation();
    } on DbException {
      // Re-throw already wrapped exceptions
      rethrow;
    } on Exception catch (e) {
      final dbException = DbExceptionMapper.mapException(
        e,
        DbOperationType.update,
        tableName: tableName,
        columnName: columnName,
        context: context,
      );
      
      // Log constraint violations for developer debugging with severity-based levels
      if (dbException.errorCategory == DbErrorCategory.constraintViolation) {
        final constraintType = _getConstraintType(dbException.message);
        final logLevel = _getConstraintLogLevel(constraintType);
        final emoji = _getConstraintEmoji(constraintType);
        
        developer.log(
          '$emoji Constraint violation in UPDATE: ${dbException.message}${tableName != null ? ' [table: $tableName]' : ''}${columnName != null ? ' [column: $columnName]' : ''} [type: $constraintType]',
          name: 'DbConstraint${constraintType.name}',
          level: logLevel,
          error: e,
        );
      }
      
      throw dbException;
    }
  }

  /// Wraps a database delete operation with exception handling
  static Future<T> wrapDelete<T>(
    Future<T> Function() operation, {
    String? tableName,
    Map<String, Object?>? context,
  }) async {
    try {
      return await operation();
    } on DbException {
      // Re-throw already wrapped exceptions
      rethrow;
    } on Exception catch (e) {
      final dbException = DbExceptionMapper.mapException(
        e,
        DbOperationType.delete,
        tableName: tableName,
        context: context,
      );
      
      // Log constraint violations for developer debugging with severity-based levels
      if (dbException.errorCategory == DbErrorCategory.constraintViolation) {
        final constraintType = _getConstraintType(dbException.message);
        final logLevel = _getConstraintLogLevel(constraintType);
        final emoji = _getConstraintEmoji(constraintType);
        
        developer.log(
          '$emoji Constraint violation in DELETE: ${dbException.message}${tableName != null ? ' [table: $tableName]' : ''} [type: $constraintType]',
          name: 'DbConstraint${constraintType.name}',
          level: logLevel,
          error: e,
        );
      }
      
      throw dbException;
    }
  }

  /// Wraps a database transaction operation with exception handling
  static Future<T> wrapTransaction<T>(
    Future<T> Function() operation, {
    Map<String, Object?>? context,
  }) async {
    try {
      return await operation();
    } on DbException {
      // Re-throw already wrapped exceptions
      rethrow;
    } on Exception catch (e) {
      final dbException = DbExceptionMapper.mapException(
        e,
        DbOperationType.transaction,
        context: context,
      );
      
      // Log constraint violations for developer debugging with severity-based levels
      if (dbException.errorCategory == DbErrorCategory.constraintViolation) {
        final constraintType = _getConstraintType(dbException.message);
        final logLevel = _getConstraintLogLevel(constraintType);
        final emoji = _getConstraintEmoji(constraintType);
        
        developer.log(
          '$emoji Constraint violation in TRANSACTION: ${dbException.message} [type: $constraintType]',
          name: 'DbConstraint${constraintType.name}',
          level: logLevel,
          error: e,
        );
      }
      
      throw dbException;
    }
  }

  /// Wraps a database connection operation with exception handling
  static Future<T> wrapConnection<T>(
    Future<T> Function() operation, {
    Map<String, Object?>? context,
  }) async {
    try {
      return await operation();
    } on DbException {
      // Re-throw already wrapped exceptions
      rethrow;
    } on Exception catch (e) {
      final dbException = DbExceptionMapper.mapException(
        e,
        DbOperationType.connection,
        context: context,
      );
      
      // Log constraint violations for developer debugging with severity-based levels
      if (dbException.errorCategory == DbErrorCategory.constraintViolation) {
        final constraintType = _getConstraintType(dbException.message);
        final logLevel = _getConstraintLogLevel(constraintType);
        final emoji = _getConstraintEmoji(constraintType);
        
        developer.log(
          '$emoji Constraint violation in CONNECTION: ${dbException.message} [type: $constraintType]',
          name: 'DbConstraint${constraintType.name}',
          level: logLevel,
          error: e,
        );
      }
      
      throw dbException;
    }
  }

  /// Wraps a database migration operation with exception handling
  static Future<T> wrapMigration<T>(
    Future<T> Function() operation, {
    Map<String, Object?>? context,
  }) async {
    try {
      return await operation();
    } on DbException {
      // Re-throw already wrapped exceptions
      rethrow;
    } on Exception catch (e) {
      throw DbExceptionMapper.mapException(
        e,
        DbOperationType.migration,
        context: context,
      );
    }
  }

  /// Generic wrapper that can handle any operation type
  static Future<T> wrap<T>(
    Future<T> Function() operation,
    DbOperationType operationType, {
    String? tableName,
    String? columnName,
    Map<String, Object?>? context,
  }) async {
    try {
      return await operation();
    } on DbException {
      // Re-throw already wrapped exceptions
      rethrow;
    } on Exception catch (e) {
      throw DbExceptionMapper.mapException(
        e,
        operationType,
        tableName: tableName,
        columnName: columnName,
        context: context,
      );
    }
  }

  /// Synchronous wrapper for operations that don't return Future
  static T wrapSync<T>(
    T Function() operation,
    DbOperationType operationType, {
    String? tableName,
    String? columnName,
    Map<String, Object?>? context,
  }) {
    try {
      return operation();
    } on DbException {
      // Re-throw already wrapped exceptions
      rethrow;
    } on Exception catch (e) {
      throw DbExceptionMapper.mapException(
        e,
        operationType,
        tableName: tableName,
        columnName: columnName,
        context: context,
      );
    }
  }
  
  /// Determines the constraint type from the error message
  static ConstraintType _getConstraintType(String message) {
    final lowerMessage = message.toLowerCase();
    
    if (lowerMessage.contains('unique')) {
      return ConstraintType.unique;
    } else if (lowerMessage.contains('foreign key') || lowerMessage.contains('fkey')) {
      return ConstraintType.foreignKey;
    } else if (lowerMessage.contains('not null')) {
      return ConstraintType.notNull;
    } else if (lowerMessage.contains('check')) {
      return ConstraintType.check;
    } else if (lowerMessage.contains('primary key') || lowerMessage.contains('pkey')) {
      return ConstraintType.primaryKey;
    } else {
      return ConstraintType.other;
    }
  }
  
  /// Gets the appropriate log level based on constraint type
  static int _getConstraintLogLevel(ConstraintType type) {
    switch (type) {
      case ConstraintType.foreignKey:
      case ConstraintType.primaryKey:
        return 1000; // SEVERE - Data integrity violations
      case ConstraintType.unique:
      case ConstraintType.notNull:
        return 900; // WARNING - Business logic violations
      case ConstraintType.check:
      case ConstraintType.other:
        return 800; // INFO - General constraint violations
    }
  }
  
  /// Gets an appropriate emoji based on constraint type for visual identification
  static String _getConstraintEmoji(ConstraintType type) {
    switch (type) {
      case ConstraintType.foreignKey:
        return 'üîó'; // Chain link for foreign key relationships
      case ConstraintType.primaryKey:
        return 'üîë'; // Key for primary key
      case ConstraintType.unique:
        return '‚≠ê'; // Star for uniqueness
      case ConstraintType.notNull:
        return '‚ùó'; // Exclamation for required fields
      case ConstraintType.check:
        return '‚úì'; // Check mark for check constraints
      case ConstraintType.other:
        return '‚ö†Ô∏è'; // Warning for other constraints
    }
  }
}

/// Enum for different constraint violation types
enum ConstraintType {
  unique,
  foreignKey,
  notNull,
  check,
  primaryKey,
  other,
}

/// Extension to get readable names for constraint types
extension ConstraintTypeName on ConstraintType {
  String get name {
    switch (this) {
      case ConstraintType.unique:
        return 'Unique';
      case ConstraintType.foreignKey:
        return 'ForeignKey';
      case ConstraintType.notNull:
        return 'NotNull';
      case ConstraintType.check:
        return 'Check';
      case ConstraintType.primaryKey:
        return 'PrimaryKey';
      case ConstraintType.other:
        return 'Other';
    }
  }
}
<!-- END FILE: declarative_sqlite/lib/src/exceptions/db_exception_wrapper.dart -->

<!-- BEGIN FILE: declarative_sqlite/lib/src/exceptions/db_exceptions.dart -->
/// Enumeration of database operation types that can fail
enum DbOperationType {
  create,
  read,
  update,
  delete,
  transaction,
  migration,
  connection,
}

/// Enumeration of database error categories
enum DbErrorCategory {
  /// Constraint violation (unique, foreign key, check, etc.)
  constraintViolation,
  
  /// Resource not found (table, column, record, etc.)
  notFound,
  
  /// Invalid data or operation
  invalidData,
  
  /// Permission or access denied
  accessDenied,
  
  /// Database is locked or busy
  databaseLocked,
  
  /// Connection issues
  connectionError,
  
  /// Database corruption
  corruption,
  
  /// Schema mismatch or migration issues
  schemaMismatch,
  
  /// Concurrency conflict (optimistic locking, etc.)
  concurrencyConflict,
  
  /// Unknown or unexpected error
  unknown,
}

/// Base class for all database exceptions
/// 
/// Provides a developer-friendly interface similar to REST API status codes
/// for handling database operations failures.
abstract class DbException implements Exception {
  /// The operation that failed
  final DbOperationType operationType;
  
  /// The category of error
  final DbErrorCategory errorCategory;
  
  /// Human-readable error message
  final String message;
  
  /// Optional table name related to the error
  final String? tableName;
  
  /// Optional column name related to the error
  final String? columnName;
  
  /// The original platform-specific exception that caused this error
  final Exception? originalException;
  
  /// Additional context information
  final Map<String, Object?>? context;

  const DbException({
    required this.operationType,
    required this.errorCategory,
    required this.message,
    this.tableName,
    this.columnName,
    this.originalException,
    this.context,
  });

  @override
  String toString() {
    final buffer = StringBuffer();
    buffer.write('$runtimeType: $message');
    
    if (tableName != null) {
      buffer.write(' (table: $tableName');
      if (columnName != null) {
        buffer.write(', column: $columnName');
      }
      buffer.write(')');
    }
    
    if (originalException != null) {
      buffer.write(' [Original: ${originalException.runtimeType}]');
    }
    
    return buffer.toString();
  }
}

/// Exception thrown when a record cannot be created
class DbCreateException extends DbException {
  const DbCreateException({
    required super.errorCategory,
    required super.message,
    super.tableName,
    super.columnName,
    super.originalException,
    super.context,
  }) : super(
          operationType: DbOperationType.create,
        );

  /// Creates an exception for constraint violations during insert
  factory DbCreateException.constraintViolation({
    required String message,
    String? tableName,
    String? columnName,
    Exception? originalException,
    Map<String, Object?>? context,
  }) =>
      DbCreateException(
        errorCategory: DbErrorCategory.constraintViolation,
        message: message,
        tableName: tableName,
        columnName: columnName,
        originalException: originalException,
        context: context,
      );

  /// Creates an exception for invalid data during insert
  factory DbCreateException.invalidData({
    required String message,
    String? tableName,
    String? columnName,
    Exception? originalException,
    Map<String, Object?>? context,
  }) =>
      DbCreateException(
        errorCategory: DbErrorCategory.invalidData,
        message: message,
        tableName: tableName,
        columnName: columnName,
        originalException: originalException,
        context: context,
      );
}

/// Exception thrown when a record cannot be read/found
class DbReadException extends DbException {
  const DbReadException({
    required super.errorCategory,
    required super.message,
    super.tableName,
    super.columnName,
    super.originalException,
    super.context,
  }) : super(
          operationType: DbOperationType.read,
        );

  /// Creates an exception for when a record is not found
  factory DbReadException.notFound({
    required String message,
    String? tableName,
    Exception? originalException,
    Map<String, Object?>? context,
  }) =>
      DbReadException(
        errorCategory: DbErrorCategory.notFound,
        message: message,
        tableName: tableName,
        originalException: originalException,
        context: context,
      );

  /// Creates an exception for access denied during read
  factory DbReadException.accessDenied({
    required String message,
    String? tableName,
    Exception? originalException,
    Map<String, Object?>? context,
  }) =>
      DbReadException(
        errorCategory: DbErrorCategory.accessDenied,
        message: message,
        tableName: tableName,
        originalException: originalException,
        context: context,
      );
}

/// Exception thrown when a record cannot be updated
class DbUpdateException extends DbException {
  const DbUpdateException({
    required super.errorCategory,
    required super.message,
    super.tableName,
    super.columnName,
    super.originalException,
    super.context,
  }) : super(
          operationType: DbOperationType.update,
        );

  /// Creates an exception for constraint violations during update
  factory DbUpdateException.constraintViolation({
    required String message,
    String? tableName,
    String? columnName,
    Exception? originalException,
    Map<String, Object?>? context,
  }) =>
      DbUpdateException(
        errorCategory: DbErrorCategory.constraintViolation,
        message: message,
        tableName: tableName,
        columnName: columnName,
        originalException: originalException,
        context: context,
      );

  /// Creates an exception for concurrency conflicts during update
  factory DbUpdateException.concurrencyConflict({
    required String message,
    String? tableName,
    Exception? originalException,
    Map<String, Object?>? context,
  }) =>
      DbUpdateException(
        errorCategory: DbErrorCategory.concurrencyConflict,
        message: message,
        tableName: tableName,
        originalException: originalException,
        context: context,
      );

  /// Creates an exception for when the record to update is not found
  factory DbUpdateException.notFound({
    required String message,
    String? tableName,
    Exception? originalException,
    Map<String, Object?>? context,
  }) =>
      DbUpdateException(
        errorCategory: DbErrorCategory.notFound,
        message: message,
        tableName: tableName,
        originalException: originalException,
        context: context,
      );
}

/// Exception thrown when a record cannot be deleted
class DbDeleteException extends DbException {
  const DbDeleteException({
    required super.errorCategory,
    required super.message,
    super.tableName,
    super.originalException,
    super.context,
  }) : super(
          operationType: DbOperationType.delete,
        );

  /// Creates an exception for constraint violations during delete
  factory DbDeleteException.constraintViolation({
    required String message,
    String? tableName,
    Exception? originalException,
    Map<String, Object?>? context,
  }) =>
      DbDeleteException(
        errorCategory: DbErrorCategory.constraintViolation,
        message: message,
        tableName: tableName,
        originalException: originalException,
        context: context,
      );

  /// Creates an exception for when the record to delete is not found
  factory DbDeleteException.notFound({
    required String message,
    String? tableName,
    Exception? originalException,
    Map<String, Object?>? context,
  }) =>
      DbDeleteException(
        errorCategory: DbErrorCategory.notFound,
        message: message,
        tableName: tableName,
        originalException: originalException,
        context: context,
      );
}

/// Exception thrown when a transaction fails
class DbTransactionException extends DbException {
  const DbTransactionException({
    required super.errorCategory,
    required super.message,
    super.originalException,
    super.context,
  }) : super(
          operationType: DbOperationType.transaction,
        );

  /// Creates an exception for when a transaction is rolled back
  factory DbTransactionException.rollback({
    required String message,
    Exception? originalException,
    Map<String, Object?>? context,
  }) =>
      DbTransactionException(
        errorCategory: DbErrorCategory.concurrencyConflict,
        message: message,
        originalException: originalException,
        context: context,
      );

  /// Creates an exception for when a database is locked during transaction
  factory DbTransactionException.databaseLocked({
    required String message,
    Exception? originalException,
    Map<String, Object?>? context,
  }) =>
      DbTransactionException(
        errorCategory: DbErrorCategory.databaseLocked,
        message: message,
        originalException: originalException,
        context: context,
      );
}

/// Exception thrown when database connection fails
class DbConnectionException extends DbException {
  const DbConnectionException({
    required super.errorCategory,
    required super.message,
    super.originalException,
    super.context,
  }) : super(
          operationType: DbOperationType.connection,
        );

  /// Creates an exception for connection failures
  factory DbConnectionException.connectionFailed({
    required String message,
    Exception? originalException,
    Map<String, Object?>? context,
  }) =>
      DbConnectionException(
        errorCategory: DbErrorCategory.connectionError,
        message: message,
        originalException: originalException,
        context: context,
      );

  /// Creates an exception for database corruption
  factory DbConnectionException.corruption({
    required String message,
    Exception? originalException,
    Map<String, Object?>? context,
  }) =>
      DbConnectionException(
        errorCategory: DbErrorCategory.corruption,
        message: message,
        originalException: originalException,
        context: context,
      );
}

/// Exception thrown when database migration fails
class DbMigrationException extends DbException {
  const DbMigrationException({
    required super.errorCategory,
    required super.message,
    super.originalException,
    super.context,
  }) : super(
          operationType: DbOperationType.migration,
        );

  /// Creates an exception for schema mismatch
  factory DbMigrationException.schemaMismatch({
    required String message,
    Exception? originalException,
    Map<String, Object?>? context,
  }) =>
      DbMigrationException(
        errorCategory: DbErrorCategory.schemaMismatch,
        message: message,
        originalException: originalException,
        context: context,
      );
}
<!-- END FILE: declarative_sqlite/lib/src/exceptions/db_exceptions.dart -->

<!-- BEGIN FILE: declarative_sqlite/lib/src/files/file_repository.dart -->
import 'dart:async';

/// Defines the contract for a file repository used to store and retrieve
/// the content of files.
abstract class IFileRepository {
  /// Adds a file's content to a logical container.
  ///
  /// [filesetId] is the ID of the container (e.g., a folder).
  /// [fileId] is the unique ID of the file (e.g., a filename).
  /// [content] is a stream of the file's byte content.
  ///
  /// Returns the path where the file was stored.
  Future<String> addFile(
    String filesetId,
    String fileId,
    Stream<List<int>> content,
  );

  /// Removes a file's content.
  ///
  /// [filesetId] is the ID of the container.
  /// [fileId] is the ID of the file to remove.
  Future<void> removeFile(String filesetId, String fileId);

  /// Retrieves the content of a specific file.
  ///
  /// [filesetId] is the ID of the container.
  /// [fileId] is the ID of the file to retrieve.
  ///
  /// Returns a stream of the file's byte content.
  Future<Stream<List<int>>> getFileContent(String filesetId, String fileId);

  /// Performs garbage collection on filesets.
  ///
  /// Removes all fileset directories on disk that are not in the provided
  /// [validFilesetIds] list. This helps clean up orphaned filesets that
  /// may have been left behind when database records were deleted.
  ///
  /// [validFilesetIds] is the list of all valid fileset IDs that should
  /// be preserved. Any fileset directory not in this list will be removed.
  ///
  /// Returns the number of orphaned filesets that were removed.
  Future<int> garbageCollectFilesets(List<String> validFilesetIds);

  /// Performs garbage collection on files within a specific fileset.
  ///
  /// Removes all files on disk in the specified fileset that are not in the
  /// provided [validFileIds] list. This helps clean up orphaned files that
  /// may have been left behind when file records were deleted.
  ///
  /// [filesetId] is the ID of the fileset to clean up.
  /// [validFileIds] is the list of all valid file IDs that should be
  /// preserved within this fileset. Any file not in this list will be removed.
  ///
  /// Returns the number of orphaned files that were removed.
  Future<int> garbageCollectFiles(String filesetId, List<String> validFileIds);
}

<!-- END FILE: declarative_sqlite/lib/src/files/file_repository.dart -->

<!-- BEGIN FILE: declarative_sqlite/lib/src/files/fileset.dart -->
import 'dart:async';
import 'dart:typed_data';

import 'package:declarative_sqlite/src/declarative_database.dart';
import 'package:uuid/uuid.dart';

/// Orchestrates file storage and metadata for fileset columns.
class FileSet {
  final DeclarativeDatabase _db;

  FileSet(this._db);

  /// Adds a file to a fileset.
  ///
  /// This creates a record in the `__files` table and stores the file
  /// using the configured [IFileRepository].
  ///
  /// Returns the ID of the newly created file record.
  Future<String> addFile(
    String fileset,
    String fileName,
    Uint8List content,
  ) async {
    final fileId = Uuid().v4();
    final now = _db.hlcClock.now();

    // Store the file content using the repository
    await _db.fileRepository.addFile(fileset, fileId, Stream.value(content));

    // Store the metadata in the database
    await _db.insert('__files', {
      'id': fileId,
      'fileset': fileset,
      'name': fileName,
      'size': content.length,
      'created_at': now.toString(),
      'modified_at': now.toString(),
    });

    return fileId;
  }

  /// Retrieves the content of a file.
  Future<Uint8List?> getFileContent(String fileId) async {
    final fileRecord = await _db.queryTable(
      '__files',
      where: 'id = ?',
      whereArgs: [fileId],
    );

    if (fileRecord.isEmpty) {
      return null;
    }

    final fileset = fileRecord.first['fileset'] as String;
    final contentStream =
        await _db.fileRepository.getFileContent(fileset, fileId);

    final completer = Completer<Uint8List>();
    final builder = BytesBuilder();
    contentStream.listen(
      builder.add,
      onDone: () => completer.complete(builder.toBytes()),
      onError: completer.completeError,
    );
    return completer.future;
  }

  /// Deletes a file from a fileset.
  ///
  /// This removes the file from the [IFileRepository] and deletes its
  /// metadata record from the `__files` table.
  Future<void> deleteFile(String fileId) async {
    final fileRecord = await _db.queryTable(
      '__files',
      where: 'id = ?',
      whereArgs: [fileId],
    );

    if (fileRecord.isNotEmpty) {
      final fileset = fileRecord.first['fileset'] as String;
      await _db.fileRepository.removeFile(fileset, fileId);
      await _db.delete('__files', where: 'id = ?', whereArgs: [fileId]);
    }
  }

  /// Gets all files in a specific fileset.
  ///
  /// Returns a list of file metadata records from the `__files` table
  /// for the given fileset.
  Future<List<Map<String, dynamic>>> getFilesInFileset(String fileset) async {
    return await _db.queryTable(
      '__files',
      where: 'fileset = ?',
      whereArgs: [fileset],
      orderBy: 'created_at DESC',
    );
  }

  /// Gets the count of files in a specific fileset.
  ///
  /// Returns the number of files in the given fileset.
  Future<int> getFileCountInFileset(String fileset) async {
    final result = await _db.queryTable(
      '__files',
      columns: ['COUNT(*) as count'],
      where: 'fileset = ?',
      whereArgs: [fileset],
    );
    return result.first['count'] as int;
  }

  /// Performs garbage collection on fileset directories.
  ///
  /// This method identifies and removes orphaned fileset directories from the
  /// file repository. Orphaned filesets are those that exist on disk but have
  /// no corresponding records in the database.
  ///
  /// Optionally, you can provide [additionalValidFilesets] to preserve specific
  /// filesets that might not be in the database but should be kept.
  ///
  /// Returns the number of orphaned filesets that were removed.
  Future<int> garbageCollectFilesets({
    List<String> additionalValidFilesets = const [],
  }) async {
    // Get all filesets referenced in the database
    final filesetRecords = await _db.queryTable(
      '__files',
      columns: ['DISTINCT fileset'],
    );

    final validFilesets = <String>{
      ...filesetRecords.map((record) => record['fileset'] as String),
      ...additionalValidFilesets,
    };

    return await _db.fileRepository.garbageCollectFilesets(validFilesets.toList());
  }

  /// Performs garbage collection on files within a specific fileset.
  ///
  /// This method identifies and removes orphaned files from the specified
  /// fileset directory. Orphaned files are those that exist on disk but have
  /// no corresponding records in the database.
  ///
  /// [fileset] is the fileset ID to clean up.
  /// Optionally, you can provide [additionalValidFiles] to preserve specific
  /// files that might not be in the database but should be kept.
  ///
  /// Returns the number of orphaned files that were removed.
  Future<int> garbageCollectFilesInFileset(
    String fileset, {
    List<String> additionalValidFiles = const [],
  }) async {
    // Get all file IDs in this fileset from the database
    final fileRecords = await _db.queryTable(
      '__files',
      columns: ['id'],
      where: 'fileset = ?',
      whereArgs: [fileset],
    );

    final validFiles = <String>{
      ...fileRecords.map((record) => record['id'] as String),
      ...additionalValidFiles,
    };

    return await _db.fileRepository.garbageCollectFiles(fileset, validFiles.toList());
  }

  /// Performs a comprehensive garbage collection on both filesets and files.
  ///
  /// This is a convenience method that first cleans up orphaned filesets,
  /// then cleans up orphaned files within the remaining valid filesets.
  ///
  /// Returns a map with 'filesets' and 'files' keys indicating the number
  /// of orphaned items removed in each category.
  Future<Map<String, int>> garbageCollectAll() async {
    int removedFilesets = 0;
    int removedFiles = 0;

    // First, clean up orphaned filesets
    removedFilesets = await garbageCollectFilesets();

    // Then, clean up orphaned files in each remaining valid fileset
    final validFilesetRecords = await _db.queryTable(
      '__files',
      columns: ['DISTINCT fileset'],
    );

    for (final record in validFilesetRecords) {
      final fileset = record['fileset'] as String;
      removedFiles += await garbageCollectFilesInFileset(fileset);
    }

    return {
      'filesets': removedFilesets,
      'files': removedFiles,
    };
  }
}

<!-- END FILE: declarative_sqlite/lib/src/files/fileset.dart -->

<!-- BEGIN FILE: declarative_sqlite/lib/src/files/fileset_field.dart -->
import 'dart:async';
import 'dart:typed_data';

import 'package:declarative_sqlite/src/declarative_database.dart';
import 'package:declarative_sqlite/src/files/fileset.dart';

/// Represents a fileset column value with convenient access to file operations.
/// 
/// This class wraps a fileset identifier and provides easy access to file
/// operations for that specific fileset through the database's FileSet instance.
class FilesetField {
  final String? _filesetId;
  final DeclarativeDatabase _database;
  late final FileSet _fileSet;

  /// Creates a new FilesetField with the given fileset identifier and database.
  FilesetField._(this._filesetId, this._database) {
    _fileSet = _database.files;
  }

  /// Creates a FilesetField from a database value.
  /// 
  /// [value] should be the fileset identifier (string) from the database.
  /// [database] is the DeclarativeDatabase instance.
  factory FilesetField.fromDatabaseValue(
    dynamic value,
    DeclarativeDatabase database,
  ) {
    final filesetId = value as String?;
    return FilesetField._(filesetId, database);
  }

  /// Gets the fileset identifier.
  String? get filesetId => _filesetId;

  /// Returns true if this fileset field has a value (is not null or empty).
  bool get hasValue => _filesetId != null && _filesetId.isNotEmpty;

  /// Adds a file to this fileset.
  ///
  /// Returns the ID of the newly created file record.
  /// Throws [StateError] if this fileset field has no value.
  Future<String> addFile(
    String fileName,
    Uint8List content,
  ) async {
    if (!hasValue) {
      throw StateError('Cannot add file to null or empty fileset');
    }
    return await _fileSet.addFile(_filesetId!, fileName, content);
  }

  /// Retrieves the content of a file by its ID.
  /// 
  /// Returns null if the file is not found.
  Future<Uint8List?> getFileContent(String fileId) async {
    return await _fileSet.getFileContent(fileId);
  }

  /// Gets metadata for a specific file by its ID.
  /// 
  /// Returns the file metadata record from the __files table,
  /// or null if the file is not found.
  Future<Map<String, dynamic>?> getFileMetadata(String fileId) async {
    final fileRecords = await _database.queryTable(
      '__files',
      where: 'id = ?',
      whereArgs: [fileId],
    );
    
    if (fileRecords.isEmpty) {
      return null;
    }
    
    return fileRecords.first;
  }

  /// Deletes a file from this fileset.
  /// 
  /// [fileId] is the ID of the file to delete.
  Future<void> deleteFile(String fileId) async {
    await _fileSet.deleteFile(fileId);
  }

  /// Gets all files in this fileset.
  /// 
  /// Returns a list of file metadata maps from the __files table.
  /// Returns an empty list if this fileset field has no value.
  Future<List<Map<String, dynamic>>> getFiles() async {
    if (!hasValue) {
      return [];
    }
    return await _fileSet.getFilesInFileset(_filesetId!);
  }

  /// Gets the count of files in this fileset.
  /// 
  /// Returns 0 if this fileset field has no value.
  Future<int> getFileCount() async {
    if (!hasValue) {
      return 0;
    }
    return await _fileSet.getFileCountInFileset(_filesetId!);
  }

  /// Returns the database value for this fileset field.
  /// 
  /// This is used when converting back to a map for database storage.
  String? toDatabaseValue() => _filesetId;

  @override
  String toString() {
    return 'FilesetField(filesetId: $_filesetId, hasValue: $hasValue)';
  }

  @override
  bool operator ==(Object other) {
    if (identical(this, other)) return true;
    return other is FilesetField && other._filesetId == _filesetId;
  }

  @override
  int get hashCode => _filesetId.hashCode;
}
<!-- END FILE: declarative_sqlite/lib/src/files/fileset_field.dart -->

<!-- BEGIN FILE: declarative_sqlite/lib/src/files/filesystem_file_repository.dart -->
import 'dart:async';
import 'dart:io';
import 'package:path/path.dart' as p;
import 'package:declarative_sqlite/src/files/file_repository.dart';

/// A default implementation of [IFileRepository] that stores files on the
/// local filesystem.
class FilesystemFileRepository implements IFileRepository {
  final String _storagePath;

  /// Creates a new [FilesystemFileRepository].
  ///
  /// [_storagePath] is the root directory where files will be stored.
  FilesystemFileRepository(this._storagePath);

  String _getFolderPath(String filesetId) => p.join(_storagePath, filesetId);
  String _getFilePath(String filesetId, String fileId) =>
      p.join(_getFolderPath(filesetId), fileId);

  @override
  Future<String> addFile(
    String filesetId,
    String fileId,
    Stream<List<int>> content,
  ) async {
    final folderPath = _getFolderPath(filesetId);
    await Directory(folderPath).create(recursive: true);

    final filePath = _getFilePath(filesetId, fileId);
    final file = File(filePath);

    final sink = file.openWrite();
    await content.pipe(sink);
    await sink.close();

    return filePath;
  }

  @override
  Future<void> removeFile(String filesetId, String fileId) async {
    final filePath = _getFilePath(filesetId, fileId);
    final file = File(filePath);
    if (await file.exists()) {
      await file.delete();
    }
  }

  @override
  Future<Stream<List<int>>> getFileContent(
      String filesetId, String fileId) async {
    final filePath = _getFilePath(filesetId, fileId);
    final file = File(filePath);
    if (!await file.exists()) {
      throw Exception('File not found at path: $filePath');
    }
    return file.openRead();
  }

  @override
  Future<int> garbageCollectFilesets(List<String> validFilesetIds) async {
    final storageDir = Directory(_storagePath);
    if (!await storageDir.exists()) {
      return 0; // Nothing to clean up
    }

    final validFilesetSet = validFilesetIds.toSet();
    int removedCount = 0;

    await for (final entity in storageDir.list()) {
      if (entity is Directory) {
        final filesetId = p.basename(entity.path);
        
        // Skip if this fileset ID is valid
        if (validFilesetSet.contains(filesetId)) {
          continue;
        }

        // This is an orphaned fileset directory, remove it
        try {
          await entity.delete(recursive: true);
          removedCount++;
        } catch (e) {
          // Log error but continue with cleanup
          print('Warning: Failed to delete orphaned fileset directory ${entity.path}: $e');
        }
      }
    }

    return removedCount;
  }

  @override
  Future<int> garbageCollectFiles(String filesetId, List<String> validFileIds) async {
    final filesetDir = Directory(_getFolderPath(filesetId));
    if (!await filesetDir.exists()) {
      return 0; // Fileset directory doesn't exist
    }

    final validFileSet = validFileIds.toSet();
    int removedCount = 0;

    await for (final entity in filesetDir.list()) {
      if (entity is File) {
        final fileId = p.basename(entity.path);
        
        // Skip if this file ID is valid
        if (validFileSet.contains(fileId)) {
          continue;
        }

        // This is an orphaned file, remove it
        try {
          await entity.delete();
          removedCount++;
        } catch (e) {
          // Log error but continue with cleanup
          print('Warning: Failed to delete orphaned file ${entity.path}: $e');
        }
      }
    }

    return removedCount;
  }
}

<!-- END FILE: declarative_sqlite/lib/src/files/filesystem_file_repository.dart -->

<!-- BEGIN FILE: declarative_sqlite/lib/src/migration/diff_schemas.dart -->
import 'package:collection/collection.dart';
import 'package:declarative_sqlite/src/migration/schema_diff.dart';
import 'package:declarative_sqlite/src/schema/live_schema.dart';
import 'package:declarative_sqlite/src/schema/db_table.dart';
import 'package:declarative_sqlite/src/schema/schema.dart';

List<SchemaChange> diffSchemas(
    Schema declarativeSchema, LiveSchema liveSchema) {
  final changes = <SchemaChange>[];

  final declarativeTables = declarativeSchema.tables;
  final liveTables = liveSchema.tables;

  // Compare tables
  for (final declarativeTable in declarativeTables) {
    final liveTable =
        liveTables.firstWhereOrNull((t) => t.name == declarativeTable.name);
    if (liveTable == null) {
      changes.add(CreateTable(declarativeTable));
    } else {
      final columnChanges = _diffColumns(declarativeTable, liveTable);
      final keyChanges = _diffKeys(declarativeTable, liveTable);
      if (columnChanges.isNotEmpty || keyChanges.isNotEmpty) {
        changes.add(
            AlterTable(liveTable, declarativeTable, columnChanges, keyChanges));
      }
    }
  }

  for (final liveTable in liveTables) {
    if (!declarativeTables.any((t) => t.name == liveTable.name)) {
      changes.add(DropTable(liveTable));
    }
  }

  // Compare views
  final declarativeViews = declarativeSchema.views;
  final liveViews = liveSchema.views;

  for (final declarativeView in declarativeViews) {
    final liveView =
        liveViews.firstWhereOrNull((v) => v.name == declarativeView.name);
    if (liveView == null) {
      changes.add(CreateView(declarativeView));
    } else if (liveView.sql != declarativeView.definition) {
      changes.add(AlterView(liveView, declarativeView));
    }
  }

  for (final liveView in liveViews) {
    if (!declarativeViews.any((v) => v.name == liveView.name)) {
      changes.add(DropView(liveView));
    }
  }

  return changes;
}

List<ColumnChange> _diffColumns(DbTable declarativeTable, LiveTable liveTable) {
  final changes = <ColumnChange>[];
  final declarativeColumns = declarativeTable.columns;
  final liveColumns = liveTable.columns;

  for (final declarativeColumn in declarativeColumns) {
    final liveColumn =
        liveColumns.firstWhereOrNull((c) => c.name == declarativeColumn.name);
    if (liveColumn == null) {
      changes.add(AddColumn(declarativeColumn));
    } else {
      // A simple diff for demonstration. A real implementation would be more robust.
      if (liveColumn.type.toUpperCase() !=
              declarativeColumn.type.toUpperCase() ||
          liveColumn.isNotNull != declarativeColumn.isNotNull) {
        changes.add(AlterColumn(liveColumn, declarativeColumn));
      }
    }
  }

  for (final liveColumn in liveColumns) {
    if (!declarativeColumns.any((c) => c.name == liveColumn.name)) {
      changes.add(DropColumn(liveColumn));
    }
  }

  return changes;
}

List<KeyChange> _diffKeys(DbTable declarativeTable, LiveTable liveTable) {
  final changes = <KeyChange>[];
  final declarativeKeys = declarativeTable.keys;
  final liveKeys = liveTable.keys;

  for (final declarativeKey in declarativeKeys) {
    final liveKey = liveKeys.firstWhereOrNull(
        (k) => const ListEquality().equals(k.columns, declarativeKey.columns));
    if (liveKey == null) {
      changes.add(AddKey(declarativeKey));
    }
  }

  for (final liveKey in liveKeys) {
    if (!declarativeKeys
        .any((k) => const ListEquality().equals(k.columns, liveKey.columns))) {
      changes.add(DropKey(liveKey));
    }
  }

  return changes;
}


<!-- END FILE: declarative_sqlite/lib/src/migration/diff_schemas.dart -->

<!-- BEGIN FILE: declarative_sqlite/lib/src/migration/generate_migration_scripts.dart -->
import 'dart:convert';
import 'dart:developer' as developer;

import 'package:collection/collection.dart';
import 'package:crypto/crypto.dart';
import 'package:declarative_sqlite/src/migration/schema_diff.dart';
import 'package:declarative_sqlite/src/schema/db_key.dart';

List<String> generateMigrationScripts(List<SchemaChange> changes) {
  developer.log('üîÑ Starting migration script generation with ${changes.length} schema changes', name: 'Migration');
  
  final scripts = <String>[];
  for (int i = 0; i < changes.length; i++) {
    final change = changes[i];
    developer.log('üìù Processing change ${i + 1}/${changes.length}: ${change.runtimeType}', name: 'Migration');
    
    if (change is CreateTable) {
      developer.log('‚ûï Creating table: ${change.table.name} with ${change.table.columns.length} columns', name: 'Migration');
      final tableScripts = _generateCreateTableScripts(change);
      scripts.addAll(tableScripts);
      developer.log('  ‚îî‚îÄ Generated ${tableScripts.length} scripts for table creation', name: 'Migration');
    } else if (change is DropTable) {
      developer.log('üóëÔ∏è Dropping table: ${change.table.name}', name: 'Migration');
      scripts.add('DROP TABLE ${change.table.name};');
    } else if (change is AlterTable) {
      developer.log('üîß Altering table: ${change.liveTable.name} ‚Üí ${change.targetTable.name}', name: 'Migration');
      developer.log('  ‚îî‚îÄ Column changes: ${change.columnChanges.length}, Key changes: ${change.keyChanges.length}', name: 'Migration');
      final alterScripts = _generateAlterTableScripts(change);
      scripts.addAll(alterScripts);
      developer.log('  ‚îî‚îÄ Generated ${alterScripts.length} scripts for table alteration', name: 'Migration');
    } else if (change is CreateView) {
      developer.log('üëÅÔ∏è Creating view: ${change.view.name}', name: 'Migration');
      scripts.add('CREATE VIEW ${change.view.name} AS ${change.view.definition};');
    } else if (change is DropView) {
      developer.log('üóëÔ∏è Dropping view: ${change.view.name}', name: 'Migration');
      scripts.add('DROP VIEW ${change.view.name};');
    } else if (change is AlterView) {
      developer.log('üîß Altering view: ${change.liveView.name} ‚Üí ${change.targetView.name}', name: 'Migration');
      scripts.add('DROP VIEW ${change.liveView.name};');
      scripts.add('CREATE VIEW ${change.targetView.name} AS ${change.targetView.definition};');
      developer.log('  ‚îî‚îÄ Generated 2 scripts (drop + create) for view alteration', name: 'Migration');
    } else {
      developer.log('‚ö†Ô∏è Unknown schema change type: ${change.runtimeType}', name: 'Migration');
    }
  }
  
  developer.log('‚úÖ Migration script generation complete. Total scripts: ${scripts.length}', name: 'Migration');
  if (scripts.isNotEmpty) {
    developer.log('üìã Generated SQL scripts:', name: 'Migration');
    for (int i = 0; i < scripts.length; i++) {
      developer.log('  ${i + 1}. ${scripts[i]}', name: 'Migration');
    }
  }
  
  return scripts;
}

String _generateCreateTableScript(CreateTable change) {
  final table = change.table;
  final columns = table.columns.map((c)=>c.toSql()).join(', ');
  final primaryKeys = table.keys
      .where((k) => k.type == KeyType.primary)
      .map((k) => 'PRIMARY KEY (${k.columns.join(', ')})')
      .join(', ');

  final parts = [
    columns,
    if (primaryKeys.isNotEmpty) primaryKeys,
  ];
  return 'CREATE TABLE ${table.name} (${parts.where((p) => p.isNotEmpty).join(', ')});';
}

List<String> _generateCreateTableScripts(CreateTable change) {
  final scripts = <String>[];
  final table = change.table;
  
  // Log table details
  developer.log('    üìä Table details: ${table.columns.length} columns, ${table.keys.length} keys', name: 'Migration');
  for (final column in table.columns) {
    developer.log('      ‚Ä¢ ${column.name} (${column.logicalType}${column.isNotNull ? ', NOT NULL' : ''}${column.defaultValue != null ? ', default: ${column.defaultValue}' : ''})', name: 'Migration');
  }
  
  scripts.add(_generateCreateTableScript(change));

  final indexKeys = table.keys.where((k) => k.type == KeyType.indexed);
  if (indexKeys.isNotEmpty) {
    developer.log('    üìä Creating ${indexKeys.length} indexes for table ${table.name}', name: 'Migration');
  }
  
  for (final key in indexKeys) {
    var indexName = 'idx_${table.name}_${key.columns.join('_')}';
    if (indexName.length > 62) {
      final hash =
          sha1.convert(utf8.encode(indexName)).toString().substring(0, 10);
      indexName = 'idx_${table.name}_$hash';
      developer.log('      ‚Ä¢ Index name truncated: $indexName (${key.columns.join(', ')})', name: 'Migration');
    } else {
      developer.log('      ‚Ä¢ Index: $indexName (${key.columns.join(', ')})', name: 'Migration');
    }
    scripts.add(
        'CREATE INDEX $indexName ON ${table.name} (${key.columns.join(', ')});');
  }
  
  return scripts;
}

List<String> _generateAlterTableScripts(AlterTable change) {
  final scripts = <String>[];
  final addColumnChanges = change.columnChanges.whereType<AddColumn>().toList();
  final dropColumnChanges =
      change.columnChanges.whereType<DropColumn>().toList();
  final alterColumnChanges =
      change.columnChanges.whereType<AlterColumn>().toList();
  final keyChanges = change.keyChanges;

  // Log detailed change breakdown
  developer.log('    üìä Alter table breakdown:', name: 'Migration');
  developer.log('      ‚Ä¢ Add columns: ${addColumnChanges.length}', name: 'Migration');
  if (addColumnChanges.isNotEmpty) {
    for (final add in addColumnChanges) {
      developer.log('        + ${add.column.name} (${add.column.logicalType})', name: 'Migration');
    }
  }
  developer.log('      ‚Ä¢ Drop columns: ${dropColumnChanges.length}', name: 'Migration');
  if (dropColumnChanges.isNotEmpty) {
    for (final drop in dropColumnChanges) {
      developer.log('        - ${drop.column.name}', name: 'Migration');
    }
  }
  developer.log('      ‚Ä¢ Alter columns: ${alterColumnChanges.length}', name: 'Migration');
  if (alterColumnChanges.isNotEmpty) {
    for (final alter in alterColumnChanges) {
      developer.log('        ~ ${alter.liveColumn.name}: ${alter.liveColumn.type} ‚Üí ${alter.targetColumn.logicalType}', name: 'Migration');
    }
  }
  developer.log('      ‚Ä¢ Key changes: ${keyChanges.length}', name: 'Migration');

  if (dropColumnChanges.isNotEmpty ||
      alterColumnChanges.isNotEmpty ||
      keyChanges.isNotEmpty) {
    developer.log('    ‚ö†Ô∏è Complex changes detected - will recreate table ${change.liveTable.name}', name: 'Migration');
    // Recreate table if columns are dropped or altered, or if keys/references change
    final newTable = change.targetTable;
    final oldTable = change.liveTable;
    final tempTableName = 'old_${oldTable.name}';
    final keptColumns = newTable.columns.map((c) => c.name).toList();

    developer.log('    üîÑ Table recreation steps:', name: 'Migration');
    developer.log('      1Ô∏è‚É£ Rename ${oldTable.name} ‚Üí $tempTableName', name: 'Migration');
    
    // 1. Rename old table
    scripts.add('ALTER TABLE ${oldTable.name} RENAME TO $tempTableName;');

    developer.log('      2Ô∏è‚É£ Create new ${newTable.name} with ${newTable.columns.length} columns', name: 'Migration');
    
    // 2. Create new table with original name
    scripts.addAll(_generateCreateTableScripts(CreateTable(newTable)));

    developer.log('      3Ô∏è‚É£ Prepare data migration for ${keptColumns.length} columns', name: 'Migration');
    
    final selectColumns = newTable.columns.map((newCol) {
      final oldCol =
          oldTable.columns.firstWhereOrNull((c) => c.name == newCol.name);
      if (oldCol == null) {
        if (newCol.isNotNull) {
          final defaultValue = newCol.defaultValue;
          if (defaultValue != null) {
            final value =
                defaultValue is String ? "'$defaultValue'" : defaultValue;
            return '$value AS ${newCol.name}';
          }
        }
      } else {
        // The column exists in the old table, so we can select it.
        // We need to handle the case where a column is now NOT NULL,
        // but was previously nullable.
        if (newCol.isNotNull && !oldCol.isNotNull) {
          final defaultValue = newCol.defaultValue;
          final value =
              defaultValue is String ? "'$defaultValue'" : defaultValue;
          return 'IFNULL(${newCol.name}, $value) AS ${newCol.name}';
        }
      }
      return newCol.name;
    }).join(', ');

    developer.log('      4Ô∏è‚É£ Copy data: SELECT $selectColumns FROM $tempTableName', name: 'Migration');
    
    // 3. Copy data from old table to new table
    scripts.add(
        'INSERT INTO ${newTable.name} (${keptColumns.join(', ')}) SELECT $selectColumns FROM $tempTableName;');

    developer.log('      5Ô∏è‚É£ Drop temporary table: $tempTableName', name: 'Migration');
    
    // 4. Drop old table
    scripts.add('DROP TABLE $tempTableName;');
  } else {
    developer.log('    ‚ú® Simple column additions - using ALTER TABLE ADD COLUMN', name: 'Migration');
    
    // Only handle adding columns if no columns are dropped, altered, or keys/references change
    for (final columnChange in addColumnChanges) {
      final columnDef = columnChange.column.toSql();
      developer.log('      + Adding column: ${columnChange.column.name} (${columnChange.column.logicalType})', name: 'Migration');
      scripts
          .add('ALTER TABLE ${change.liveTable.name} ADD COLUMN $columnDef;');
    }
  }

  // NOTE: This implementation assumes that if any column is dropped or altered,
  // the table is recreated. If columns are only added, it uses ALTER TABLE ADD
  // COLUMN.
  return scripts;
}

<!-- END FILE: declarative_sqlite/lib/src/migration/generate_migration_scripts.dart -->

<!-- BEGIN FILE: declarative_sqlite/lib/src/migration/introspect_schema.dart -->
import 'package:sqflite_common/sqflite.dart' as sqflite;
import 'package:declarative_sqlite/src/schema/live_schema.dart';

Future<LiveSchema> introspectSchema(sqflite.Database db) async {
  final tables = await _introspectTables(db);
  final views = await _introspectViews(db);
  return LiveSchema(tables: tables, views: views);
}

Future<List<LiveTable>> _introspectTables(sqflite.Database db) async {
  final tables = <LiveTable>[];
  final tableRows = await db.rawQuery(
      "SELECT name FROM sqlite_master WHERE type='table' AND name NOT LIKE 'sqlite\\_%' ESCAPE '\\' AND name NOT LIKE 'android\\_metadata' ESCAPE '\\'");
  for (final tableRow in tableRows) {
    final tableName = tableRow['name'] as String;
    final columns = await _introspectColumns(db, tableName);
    final keys = await _introspectKeys(db, tableName);
    tables.add(LiveTable(
      name: tableName,
      columns: columns,
      keys: keys,
    ));
  }
  return tables;
}

Future<List<LiveView>> _introspectViews(sqflite.Database db) async {
  final views = <LiveView>[];
  final viewRows = await db
      .rawQuery("SELECT name, sql FROM sqlite_master WHERE type='view'");
  for (final viewRow in viewRows) {
    views.add(LiveView(
      name: viewRow['name'] as String,
      sql: viewRow['sql'] as String,
    ));
  }
  return views;
}

Future<List<LiveColumn>> _introspectColumns(
    sqflite.Database db, String tableName) async {
  final columns = <LiveColumn>[];
  final columnRows = await db.rawQuery('PRAGMA table_info($tableName)');
  for (final columnRow in columnRows) {
    columns.add(LiveColumn(
      name: columnRow['name'] as String,
      type: columnRow['type'] as String,
      isNotNull: (columnRow['notnull'] as int) == 1,
      isPrimaryKey: (columnRow['pk'] as int) >= 1,
      defaultValue: columnRow['dflt_value'] as String?,
    ));
  }
  return columns;
}

Future<List<LiveKey>> _introspectKeys(
    sqflite.Database db, String tableName) async {
  final keys = <LiveKey>[];
  final indexList = await db.rawQuery('PRAGMA index_list($tableName)');
  for (final indexRow in indexList) {
    final indexName = indexRow['name'] as String;
    final isUnique = (indexRow['unique'] as int) == 1;
    final indexInfo = await db.rawQuery('PRAGMA index_info($indexName)');
    final columns = indexInfo.map((row) => row['name'] as String).toList();
    keys.add(LiveKey(name: indexName, columns: columns, isUnique: isUnique));
  }
  return keys;
}

<!-- END FILE: declarative_sqlite/lib/src/migration/introspect_schema.dart -->

<!-- BEGIN FILE: declarative_sqlite/lib/src/migration/schema_diff.dart -->
import 'package:declarative_sqlite/src/schema/db_column.dart';
import 'package:declarative_sqlite/src/schema/db_key.dart';
import 'package:declarative_sqlite/src/schema/live_schema.dart';
import 'package:declarative_sqlite/src/schema/db_table.dart';
import 'package:declarative_sqlite/src/schema/db_view.dart';

abstract class SchemaChange {}

// Table changes
class CreateTable extends SchemaChange {
  final DbTable table;
  CreateTable(this.table);
}

class DropTable extends SchemaChange {
  final LiveTable table;
  DropTable(this.table);
}

class AlterTable extends SchemaChange {
  final LiveTable liveTable;
  final DbTable targetTable;
  final List<ColumnChange> columnChanges;
  final List<KeyChange> keyChanges;
  AlterTable(
      this.liveTable, this.targetTable, this.columnChanges, this.keyChanges);
}

// Column changes
abstract class ColumnChange {}

class AddColumn extends ColumnChange {
  final DbColumn column;
  AddColumn(this.column);
}

class DropColumn extends ColumnChange {
  final LiveColumn column;
  DropColumn(this.column);
}

class AlterColumn extends ColumnChange {
  final LiveColumn liveColumn;
  final DbColumn targetColumn;
  AlterColumn(this.liveColumn, this.targetColumn);
}

// Key changes
abstract class KeyChange {}

class AddKey extends KeyChange {
  final DbKey key;
  AddKey(this.key);
}

class DropKey extends KeyChange {
  final LiveKey key;
  DropKey(this.key);
}

// View changes
abstract class ViewChange extends SchemaChange {}

class CreateView extends ViewChange {
  final DbView view;
  CreateView(this.view);
}

class AlterView extends ViewChange {
  final LiveView liveView;
  final DbView targetView;
  AlterView(this.liveView, this.targetView);
}

class DropView extends ViewChange {
  final LiveView view;
  DropView(this.view);
}
<!-- END FILE: declarative_sqlite/lib/src/migration/schema_diff.dart -->

<!-- BEGIN FILE: declarative_sqlite/lib/src/record_factory.dart -->
import 'package:declarative_sqlite/src/declarative_database.dart';
import 'package:declarative_sqlite/src/db_record.dart';

/// Factory for creating DbRecord instances from database query results.
class RecordFactory {
  static DbRecord fromMap(
    Map<String, Object?> data,
    String tableName,
    DeclarativeDatabase database,
  ) {
    return _GenericRecord(data, tableName, database);
  }

  /// Creates a list of records from query results
  static List<DbRecord> fromMapList(
    List<Map<String, Object?>> dataList,
    String tableName,
    DeclarativeDatabase database,
  ) {
    return dataList
        .map((data) => fromMap(data, tableName, database))
        .toList();
  }
}

/// Generic implementation of DbRecord for any table
class _GenericRecord extends DbRecord {
  _GenericRecord(super.data, super.tableName, super.database);

  /// Provides dynamic property access via noSuchMethod
  @override
  dynamic noSuchMethod(Invocation invocation) {
    final name = invocation.memberName.toString();

    // Handle getters (property access)
    if (invocation.isGetter) {
      // Remove 'Symbol("' and '")' from the symbol name
      final propertyName = name.substring(8, name.length - 2);

      // Handle special getters
      if (propertyName == 'tableName') return tableName;
      if (propertyName == 'data') return data;
      if (propertyName == 'modifiedFields') return modifiedFields;
      if (propertyName == 'systemId') return systemId;
      if (propertyName == 'systemCreatedAt') return systemCreatedAt;
      if (propertyName == 'systemVersion') return systemVersion;
      if (propertyName == 'isCrudEnabled') return isCrudEnabled;
      if (propertyName == 'updateTableName') return updateTableName;

      // Handle regular column getters
      return getValue(propertyName);
    }

    // Handle setters (property assignment)
    if (invocation.isSetter) {
      // Remove 'Symbol("' and '=")' from the symbol name
      final propertyName = name.substring(8, name.length - 3);
      final value = invocation.positionalArguments.first;

      setValue(propertyName, value);
      return;
    }

    // Handle method calls
    if (invocation.isMethod) {
      final methodName = name.substring(8, name.length - 2);

      switch (methodName) {
        case 'save':
          return save();
        case 'insert':
          return insert();
        case 'delete':
          return delete();
        case 'reload':
          return reload();
        case 'toString':
          return toString();
        default:
          return super.noSuchMethod(invocation);
      }
    }

    return super.noSuchMethod(invocation);
  }
}

<!-- END FILE: declarative_sqlite/lib/src/record_factory.dart -->

<!-- BEGIN FILE: declarative_sqlite/lib/src/record_map_factory_registry.dart -->
import 'package:declarative_sqlite/src/declarative_database.dart';
import 'package:declarative_sqlite/src/db_record.dart';

typedef RecordFactoryFunction<T extends DbRecord> = T Function(
    Map<String, Object?> data, DeclarativeDatabase database);

/// Registry for typed record factory functions.
///
/// This allows registering fromMap factory functions for specific record types
/// and looking them up by Type, eliminating the need for mapper parameters
/// in query methods.
class RecordMapFactoryRegistry {
  static final Map<Type, RecordFactoryFunction<DbRecord>> _factories = {};

  /// Registers a fromMap factory for the given record type.
  ///
  /// Example:
  /// ```dart
  /// RecordMapFactoryRegistry.register<User>(User.fromMap);
  /// ```
  static void register<T extends DbRecord>(
      T Function(Map<String, Object?> data, DeclarativeDatabase database)
          factory) {
    _factories[T] = factory;
  }

  /// Gets the factory for the given record type.
  ///
  /// Throws [ArgumentError] if no factory is registered for the type.
  static RecordFactoryFunction<T> getFactory<T extends DbRecord>() {
    final factory = _factories[T];
    if (factory == null) {
      throw ArgumentError('No factory registered for type $T. '
          'Call RecordMapFactoryRegistry.register<$T>(factory) first.');
    }
    return factory as RecordFactoryFunction<T>;
  }

  /// Checks if a factory is registered for the given type.
  static bool hasFactory<T extends DbRecord>() {
    return _factories.containsKey(T);
  }

  /// Checks if a factory is registered for the given type by Type object.
  static bool hasFactoryForType(Type type) {
    return _factories.containsKey(type);
  }

  /// Gets all registered types.
  static Set<Type> get registeredTypes => Set.unmodifiable(_factories.keys);

  /// Clears all registered factories. Useful for testing.
  static void clear() {
    _factories.clear();
  }

  /// Creates an instance using the registered factory for the given type.
  ///
  /// This is a convenience method that combines getFactory and calling it.
  static T create<T extends DbRecord>(
      Map<String, Object?> data, DeclarativeDatabase database) {
    final factory = getFactory<T>();
    // Create a mutable copy since SQLite returns read-only maps
    final mutableData = Map<String, Object?>.from(data);
    return factory(mutableData, database);
  }
}
<!-- END FILE: declarative_sqlite/lib/src/record_map_factory_registry.dart -->

<!-- BEGIN FILE: declarative_sqlite/lib/src/scheduling/database_maintenance_tasks.dart -->
import 'package:declarative_sqlite/src/scheduling/task_scheduler.dart';
import 'package:declarative_sqlite/src/sync/server_sync_manager.dart';

/// Built-in database maintenance tasks
class DatabaseMaintenanceTasks {
  /// Schedule fileset garbage collection
  static Future<String> scheduleFilesetGarbageCollection({
    required Future<Map<String, int>> Function() garbageCollectTask,
    Duration interval = const Duration(hours: 6),
    TaskPriority priority = TaskPriority.low,
  }) async {
    return TaskScheduler.instance.scheduleRecurringTask(
      name: 'Fileset Garbage Collection',
      task: garbageCollectTask,
      interval: interval,
      priority: priority,
      timeout: const Duration(minutes: 30),
    );
  }
  
  /// Schedule database optimization
  static Future<String> scheduleDatabaseOptimization({
    required Future<void> Function() optimizeTask,
    Duration interval = const Duration(days: 1),
    TaskPriority priority = TaskPriority.low,
  }) async {
    return TaskScheduler.instance.scheduleRecurringTask(
      name: 'Database Optimization',
      task: optimizeTask,
      interval: interval,
      priority: priority,
      timeout: const Duration(minutes: 10),
    );
  }
  
  /// Schedule sync operations using ServerSyncManager
  /// 
  /// This integrates with TaskScheduler instead of using internal timers
  /// for better resource management and fair scheduling.
  static Future<String> scheduleSyncOperation({
    required ServerSyncManager syncManager,
    Duration interval = const Duration(minutes: 15),
    TaskPriority priority = TaskPriority.normal,
  }) async {
    return TaskScheduler.instance.scheduleRecurringTask(
      name: 'Server Synchronization',
      task: () => syncManager.performSync(),
      interval: interval,
      priority: priority,
      timeout: const Duration(minutes: 5),
    );
  }
  
  /// Schedule backup operations
  static Future<String> scheduleBackup({
    required Future<void> Function() backupTask,
    Duration interval = const Duration(hours: 12),
    TaskPriority priority = TaskPriority.normal,
  }) async {
    return TaskScheduler.instance.scheduleRecurringTask(
      name: 'Database Backup',
      task: backupTask,
      interval: interval,
      priority: priority,
      timeout: const Duration(minutes: 15),
    );
  }
  
  /// Schedule cleanup of old records
  static Future<String> scheduleDataCleanup({
    required Future<void> Function() cleanupTask,
    Duration interval = const Duration(days: 7),
    TaskPriority priority = TaskPriority.low,
  }) async {
    return TaskScheduler.instance.scheduleRecurringTask(
      name: 'Data Cleanup',
      task: cleanupTask,
      interval: interval,
      priority: priority,
      timeout: const Duration(minutes: 20),
    );
  }
  
  /// Schedule health checks
  static Future<String> scheduleHealthCheck({
    required Future<void> Function() healthCheckTask,
    Duration interval = const Duration(hours: 1),
    TaskPriority priority = TaskPriority.high,
  }) async {
    return TaskScheduler.instance.scheduleRecurringTask(
      name: 'Database Health Check',
      task: healthCheckTask,
      interval: interval,
      priority: priority,
      timeout: const Duration(minutes: 2),
    );
  }

  /// Schedule comprehensive database maintenance.
  /// 
  /// This is a convenience method that schedules multiple common maintenance
  /// tasks with sensible defaults for intervals and priorities.
  static Future<Map<String, String>> scheduleComprehensiveMaintenance({
    required ServerSyncManager syncManager,
    required Future<Map<String, int>> Function() garbageCollectTask,
    required Future<void> Function() optimizationTask,
    Duration syncInterval = const Duration(minutes: 15),
    Duration garbageCollectionInterval = const Duration(hours: 6),
    Duration optimizationInterval = const Duration(days: 1),
  }) async {
    final taskIds = <String, String>{};

    // Schedule sync operations
    taskIds['sync'] = await scheduleSyncOperation(
      syncManager: syncManager,
      interval: syncInterval,
      priority: TaskPriority.normal,
    );

    // Schedule fileset garbage collection
    taskIds['garbage_collection'] = await scheduleFilesetGarbageCollection(
      garbageCollectTask: garbageCollectTask,
      interval: garbageCollectionInterval,
      priority: TaskPriority.low,
    );

    // Schedule database optimization
    taskIds['optimization'] = await scheduleDatabaseOptimization(
      optimizeTask: optimizationTask,
      interval: optimizationInterval,
      priority: TaskPriority.idle,
    );

    return taskIds;
  }
}

/// Helper for device-specific scheduler configuration
class DeviceOptimizedScheduler {
  /// Initialize scheduler with device-appropriate settings
  static void initialize({bool isResourceConstrained = false}) {
    final config = isResourceConstrained 
      ? TaskSchedulerConfig.resourceConstrained
      : TaskSchedulerConfig.highPerformance;
      
    TaskScheduler.withConfig(config);
    TaskScheduler.instance.start();
  }
  
  /// Auto-detect device capabilities and initialize
  static void autoInitialize() {
    // Simple heuristic - could be enhanced with actual device detection
    final isResourceConstrained = _isResourceConstrainedDevice();
    initialize(isResourceConstrained: isResourceConstrained);
  }
  
  static bool _isResourceConstrainedDevice() {
    // Simple heuristic - in a real implementation you might check:
    // - Available RAM
    // - CPU cores
    // - Platform type (mobile vs desktop)
    // - Battery status
    // For now, assume mobile platforms are more constrained
    try {
      // This is a simplified check - real implementation would be more sophisticated
      return false; // Default to not constrained
    } catch (e) {
      return true; // If we can't determine, assume constrained
    }
  }
}
<!-- END FILE: declarative_sqlite/lib/src/scheduling/database_maintenance_tasks.dart -->

<!-- BEGIN FILE: declarative_sqlite/lib/src/scheduling/task_scheduler.dart -->
import 'dart:async';
import 'dart:collection';
import 'dart:math';
import 'package:declarative_sqlite/declarative_sqlite.dart';
import 'package:pool/pool.dart';
import 'package:meta/meta.dart';

/// Priority levels for scheduled tasks
enum TaskPriority {
  /// Highest priority - critical tasks that should run immediately
  critical(4),
  
  /// High priority - important tasks that should run soon
  high(3),
  
  /// Normal priority - regular tasks (default)
  normal(2),
  
  /// Low priority - background tasks that can be deferred
  low(1),
  
  /// Lowest priority - tasks that only run when system is idle
  idle(0);

  const TaskPriority(this.value);
  final int value;
}

/// Configuration for resource management
class TaskSchedulerConfig {
  /// Maximum number of concurrent tasks
  final int maxConcurrentTasks;
  
  /// Maximum CPU usage percentage (0.0 to 1.0)
  final double maxCpuUsage;
  
  /// Time slice duration for each task in milliseconds
  final int timeSliceMs;
  
  /// Minimum delay between task executions in milliseconds
  final int minTaskDelayMs;
  
  /// Whether to use adaptive scheduling based on system load
  final bool adaptiveScheduling;

  const TaskSchedulerConfig({
    this.maxConcurrentTasks = 2,
    this.maxCpuUsage = 0.7,
    this.timeSliceMs = 100,
    this.minTaskDelayMs = 10,
    this.adaptiveScheduling = true,
  });
  
  /// Default configuration for resource-constrained devices
  static const TaskSchedulerConfig resourceConstrained = TaskSchedulerConfig(
    maxConcurrentTasks: 1,
    maxCpuUsage: 0.5,
    timeSliceMs: 50,
    minTaskDelayMs: 20,
    adaptiveScheduling: true,
  );
  
  /// Default configuration for high-performance devices
  static const TaskSchedulerConfig highPerformance = TaskSchedulerConfig(
    maxConcurrentTasks: 4,
    maxCpuUsage: 0.8,
    timeSliceMs: 200,
    minTaskDelayMs: 5,
    adaptiveScheduling: true,
  );
}

/// Represents a scheduled task
class ScheduledTask {
  final String id;
  final String name;
  final TaskPriority priority;
  final Future<void> Function() task;
  final DateTime? scheduledTime;
  final Duration? interval;
  final int maxRetries;
  final Duration? timeout;
  
  int _retryCount = 0;
  DateTime? _lastExecution;
  bool _isRunning = false;
  
  ScheduledTask({
    required this.id,
    required this.name,
    required this.task,
    this.priority = TaskPriority.normal,
    this.scheduledTime,
    this.interval,
    this.maxRetries = 3,
    this.timeout,
  });
  
  /// Whether this is a recurring task
  bool get isRecurring => interval != null;
  
  /// Whether the task is currently running
  bool get isRunning => _isRunning;
  
  /// Number of retry attempts made
  int get retryCount => _retryCount;
  
  /// When the task was last executed
  DateTime? get lastExecution => _lastExecution;
  
  /// When the task should next run
  DateTime? get nextRunTime {
    if (scheduledTime != null && _lastExecution == null) {
      return scheduledTime;
    }
    if (isRecurring && _lastExecution != null) {
      return _lastExecution!.add(interval!);
    }
    return null;
  }
  
  /// Whether the task is ready to run
  bool get isReady {
    if (_isRunning) return false;
    final nextRun = nextRunTime;
    return nextRun == null || DateTime.now().isAfter(nextRun);
  }
  
  /// Whether the task has exceeded maximum retries
  bool get hasExceededRetries => _retryCount >= maxRetries;
}

/// Task execution result
class TaskExecutionResult {
  final ScheduledTask task;
  final bool success;
  final Duration executionTime;
  final Object? error;
  final StackTrace? stackTrace;
  
  const TaskExecutionResult({
    required this.task,
    required this.success,
    required this.executionTime,
    this.error,
    this.stackTrace,
  });
}

/// Callback for task execution events
typedef TaskExecutionCallback = void Function(TaskExecutionResult result);

/// Fair task scheduler for background operations
class TaskScheduler {
  static TaskScheduler? _instance;
  
  /// Get the singleton instance
  static TaskScheduler get instance {
    _instance ??= TaskScheduler._internal();
    return _instance!;
  }
  
  /// Reset the singleton (for testing)
  static void resetInstance() {
    _instance?._shutdown();
    _instance = null;
  }
  
  final TaskSchedulerConfig _config;
  final Queue<ScheduledTask> _taskQueue = Queue<ScheduledTask>();
  final Map<String, ScheduledTask> _tasks = <String, ScheduledTask>{};
  final Set<String> _runningTasks = <String>{};

  /// Pool for managing concurrent task execution
  late final Pool _concurrencyPool;

  /// Database for storing task execution history
  DeclarativeDatabase? _database;
  
  Timer? _schedulerTimer;
  bool _isRunning = false;
  TaskExecutionCallback? _onTaskComplete;
  
  // Performance monitoring
  int _totalTasksExecuted = 0;
  int _totalTasksFailed = 0;
  Duration _totalExecutionTime = Duration.zero;

  @visibleForTesting
  TaskScheduler.internal([TaskSchedulerConfig? config])
      : _config = config ?? const TaskSchedulerConfig() {
    _concurrencyPool = Pool(_config.maxConcurrentTasks);
  }

  TaskScheduler._internal([TaskSchedulerConfig? config])
      : _config = config ?? const TaskSchedulerConfig() {
    _concurrencyPool = Pool(_config.maxConcurrentTasks);
  }
  
  /// Initialize with custom configuration
  factory TaskScheduler.withConfig(TaskSchedulerConfig config) {
    _instance = TaskScheduler._internal(config);
    return _instance!;
  }
  
  /// Initialize with database for persistent task tracking
  void initializeWithDatabase(DeclarativeDatabase database) {
    _database = database;
    _ensureTaskHistoryTable();
  }
  
  /// Set callback for task completion events
  void setTaskExecutionCallback(TaskExecutionCallback callback) {
    _onTaskComplete = callback;
  }
  
  /// Start the scheduler
  void start() {
    if (_isRunning) return;
    
    _isRunning = true;
    _schedulerTimer = Timer.periodic(
      Duration(milliseconds: _config.timeSliceMs),
      (_) => _processTasks(),
    );
  }
  
  /// Stop the scheduler
  void stop() {
    _isRunning = false;
    _schedulerTimer?.cancel();
    _schedulerTimer = null;
  }
  
  /// Schedule a one-time task
  String scheduleTask({
    required String name,
    required Future<void> Function() task,
    TaskPriority priority = TaskPriority.normal,
    DateTime? runAt,
    int maxRetries = 3,
    Duration? timeout,
  }) {
    final taskId = _generateTaskId();
    final scheduledTask = ScheduledTask(
      id: taskId,
      name: name,
      task: task,
      priority: priority,
      scheduledTime: runAt,
      maxRetries: maxRetries,
      timeout: timeout,
    );
    
    _addTask(scheduledTask);
    return taskId;
  }
  
  /// Schedule a recurring task with persistent tracking
  String scheduleRecurringTask({
    required String name,
    required Future<void> Function() task,
    required Duration interval,
    TaskPriority priority = TaskPriority.normal,
    DateTime? firstRun,
    int maxRetries = 3,
    Duration? timeout,
  }) {
    final taskId = _generateTaskId();

    // Check last run time from database if available
    DateTime? effectiveFirstRun = firstRun;
    if (_database != null && effectiveFirstRun == null) {
      _getNextRunTimeFromHistory(name, interval).then((nextRunTime) {
        final scheduledTask = ScheduledTask(
          id: taskId,
          name: name,
          task: task,
          priority: priority,
          scheduledTime: nextRunTime,
          interval: interval,
          maxRetries: maxRetries,
          timeout: timeout,
        );
        _addTask(scheduledTask);
      });
      return taskId;
    }

    final scheduledTask = ScheduledTask(
      id: taskId,
      name: name,
      task: task,
      priority: priority,
      scheduledTime: firstRun,
      interval: interval,
      maxRetries: maxRetries,
      timeout: timeout,
    );

    _addTask(scheduledTask);
    return taskId;
  }
  
  /// Cancel a scheduled task
  bool cancelTask(String taskId) {
    final task = _tasks.remove(taskId);
    if (task != null) {
      _taskQueue.remove(task);
      return true;
    }
    return false;
  }
  
  /// Get task status
  ScheduledTask? getTask(String taskId) {
    return _tasks[taskId];
  }
  
  /// Get all scheduled tasks
  List<ScheduledTask> getAllTasks() {
    return _tasks.values.toList();
  }
  
  /// Get scheduler statistics
  Map<String, dynamic> getStatistics() {
    return {
      'totalTasksExecuted': _totalTasksExecuted,
      'totalTasksFailed': _totalTasksFailed,
      'averageExecutionTime': _totalTasksExecuted > 0 
        ? _totalExecutionTime.inMilliseconds / _totalTasksExecuted 
        : 0,
      'activeTasks': _taskQueue.length,
      'runningTasks': _runningTasks.length,
      'maxConcurrentTasks': _config.maxConcurrentTasks,
    };
  }
  
  void _addTask(ScheduledTask task) {
    _tasks[task.id] = task;
    _insertTaskByPriority(task);
    
    // Start scheduler if not running
    if (!_isRunning) {
      start();
    }
  }
  
  void _insertTaskByPriority(ScheduledTask task) {
    // Insert task in priority order (higher priority first)
    var inserted = false;
    final queue = _taskQueue.toList();
    _taskQueue.clear();
    
    for (var existingTask in queue) {
      if (!inserted && task.priority.value > existingTask.priority.value) {
        _taskQueue.add(task);
        inserted = true;
      }
      _taskQueue.add(existingTask);
    }
    
    if (!inserted) {
      _taskQueue.add(task);
    }
  }
  
  void _processTasks() {
    if (!_isRunning) return;
    
    // Check if we can run more tasks
    if (_runningTasks.length >= _config.maxConcurrentTasks) {
      return;
    }
    
    // Find next ready task
    final readyTasks = _taskQueue.where((task) => task.isReady).toList();
    if (readyTasks.isEmpty) {
      return;
    }
    
    // Sort by priority and next run time
    readyTasks.sort((a, b) {
      final priorityCompare = b.priority.value.compareTo(a.priority.value);
      if (priorityCompare != 0) return priorityCompare;
      
      final aNext = a.nextRunTime ?? DateTime.now();
      final bNext = b.nextRunTime ?? DateTime.now();
      return aNext.compareTo(bNext);
    });
    
    final task = readyTasks.first;
    _runTask(task);
  }
  
  void _runTask(ScheduledTask task) async {
    if (task._isRunning || _runningTasks.contains(task.id)) {
      return;
    }

    await _concurrencyPool.withResource(() async {
      try {
        task._isRunning = true;
        _runningTasks.add(task.id);
        _taskQueue.remove(task);

        final startTime = DateTime.now();
        bool success = false;
        Object? error;
        StackTrace? stackTrace;

        try {
          // Apply timeout if specified
          if (task.timeout != null) {
            await task.task().timeout(task.timeout!);
          } else {
            await task.task();
          }
          success = true;
        } catch (e, st) {
          error = e;
          stackTrace = st;
          task._retryCount++;
        }

        final executionTime = DateTime.now().difference(startTime);
        task._lastExecution = DateTime.now();
        task._isRunning = false;
        _runningTasks.remove(task.id);

        // Update statistics
        _totalTasksExecuted++;
        _totalExecutionTime += executionTime;
        if (!success) {
          _totalTasksFailed++;
        }

        // Create execution result
        final result = TaskExecutionResult(
          task: task,
          success: success,
          executionTime: executionTime,
          error: error,
          stackTrace: stackTrace,
        );

        // Notify callback
        _onTaskComplete?.call(result);

        // Handle task completion
        if (success) {
          // Reset retry count on success
          task._retryCount = 0;

          // Update task history in database
          if (task.isRecurring) {
            await _updateTaskHistory(task.name);
          }

          // Reschedule if recurring
          if (task.isRecurring) {
            _insertTaskByPriority(task);
          } else {
            // Remove one-time completed task
            _tasks.remove(task.id);
          }
        } else {
          // Handle failure
          if (task.hasExceededRetries) {
            // Remove failed task
            _tasks.remove(task.id);
          } else {
            // Reschedule for retry with exponential backoff
            final delay = Duration(
              milliseconds:
                  _config.minTaskDelayMs * pow(2, task._retryCount).toInt(),
            );
            Timer(delay, () {
              if (_tasks.containsKey(task.id)) {
                _insertTaskByPriority(task);
              }
            });
          }
        }

        // Add small delay to prevent overwhelming the system
        await Future.delayed(Duration(milliseconds: _config.minTaskDelayMs));
      } finally {
        // The pool manages the resource, so no manual release needed
      }
    });
  }

  String _generateTaskId() {
    return 'task_${DateTime.now().millisecondsSinceEpoch}_${Random().nextInt(1000)}';
  }
  
  void _shutdown() {
    stop();
    _taskQueue.clear();
    _tasks.clear();
    _runningTasks.clear();
  }

  // ==========================================================================
  // Database persistence for task history
  // ==========================================================================

  static const String _taskHistoryTable = '_task_history';

  Future<void> _ensureTaskHistoryTable() async {
    await _database?.execute('''
      CREATE TABLE IF NOT EXISTS $_taskHistoryTable (
        name TEXT PRIMARY KEY,
        last_run TEXT NOT NULL
      )
    ''');
  }

  Future<void> _updateTaskHistory(String taskName) async {
    await _database?.execute('''
      INSERT OR REPLACE INTO $_taskHistoryTable (name, last_run)
      VALUES (?, ?)
    ''', [taskName, DateTime.now().toIso8601String()]);
  }

  Future<DateTime?> _getLastRunTimeFromHistory(String taskName) async {
    final result = await _database?.queryMaps(
      (q) => q
          .from(_taskHistoryTable)
          .select('last_run')
          .where(col('name').eq(taskName)),
    );

    if (result != null && result.isNotEmpty) {
      final lastRunString = result.first['last_run'] as String?;
      if (lastRunString != null) {
        return DateTime.tryParse(lastRunString);
      }
    }
    return null;
  }

  Future<DateTime> _getNextRunTimeFromHistory(
      String taskName, Duration interval) async {
    final lastRun = await _getLastRunTimeFromHistory(taskName);
    if (lastRun != null) {
      return lastRun.add(interval);
    }
    return DateTime.now();
  }
}
<!-- END FILE: declarative_sqlite/lib/src/scheduling/task_scheduler.dart -->

<!-- BEGIN FILE: declarative_sqlite/lib/src/schema/db_column.dart -->
import 'package:declarative_sqlite/src/utils/sql_escaping_utils.dart';

/// Callback function type for generating default values dynamically
typedef DefaultValueCallback = Object? Function();

class DbColumn {
  final String name;
  final String logicalType;
  final String type; // The actual DB type (e.g., TEXT, INTEGER)
  final bool isNotNull;
  final num? minValue;
  final num? maxValue;
  final int? maxLength;
  final bool isParent;
  final bool isSequence;
  final bool sequencePerParent;
  final bool isLww;
  final Object? defaultValue;
  final DefaultValueCallback? defaultValueCallback;

  const DbColumn({
    required this.name,
    required this.logicalType,
    required this.type,
    this.isNotNull = false,
    this.minValue,
    this.maxValue,
    this.maxLength,
    this.isParent = false,
    this.isSequence = false,
    this.sequencePerParent = false,
    this.isLww = false,
    this.defaultValue,
    this.defaultValueCallback,
  });

  String toSql() {
    assert(
      !isNotNull || defaultValue != null || defaultValueCallback != null,
      'defaultValue or defaultValueCallback is required when column is marked as "NOT NULL".',
    );

    final parts = [name, type];
    if (isNotNull) {
      parts.add('NOT NULL');
    }
    if (defaultValue != null) {
      if (defaultValue is String) {
        parts.add("DEFAULT '${escapeSingleQuotes(defaultValue as String)}'");
      } else {
        parts.add('DEFAULT $defaultValue');
      }
    }
    if (minValue != null) {
      parts.add('CHECK($name >= $minValue)');
    }
    if (maxLength != null) {
      parts.add('CHECK(length($name) <= $maxLength)');
    }

    return parts.join(' ');
  }

  Map<String, dynamic> toMap() {
    return {
      'name': name,
      'logicalType': logicalType,
      'type': type,
      'isNotNull': isNotNull,
      'minValue': minValue,
      'maxValue': maxValue,
      'maxLength': maxLength,
      'isParent': isParent,
      'isSequence': isSequence,
      'sequencePerParent': sequencePerParent,
      'isLww': isLww,
      'defaultValue': defaultValue,
    };
  }

  Object? getDefaultValue() {
    return defaultValueCallback != null
        ? defaultValueCallback!()
        : defaultValue;
  }
}

<!-- END FILE: declarative_sqlite/lib/src/schema/db_column.dart -->

<!-- BEGIN FILE: declarative_sqlite/lib/src/schema/db_key.dart -->
enum KeyType { primary, indexed, unique, foreign }

class DbKey {
  final List<String> columns;
  final KeyType type;
  final String? foreignTable;
  final List<String>? foreignColumns;

  const DbKey({
    required this.columns,
    required this.type,
    this.foreignTable,
    this.foreignColumns,
  });

  bool get isPrimary => type == KeyType.primary;
  bool get isUnique => type == KeyType.unique;
  bool get isForeign => type == KeyType.foreign;

  Map<String, dynamic> toMap() {
    return {
      'columns': columns,
      'type': type.toString(),
      'foreignTable': foreignTable,
      'foreignColumns': foreignColumns,
    };
  }
}

<!-- END FILE: declarative_sqlite/lib/src/schema/db_key.dart -->

<!-- BEGIN FILE: declarative_sqlite/lib/src/schema/db_table.dart -->
import 'package:declarative_sqlite/src/schema/db_column.dart';
import 'package:declarative_sqlite/src/schema/db_key.dart';

class DbTable {
  final String name;
  final List<DbColumn> columns;
  final List<DbKey> keys;

  bool get isSystem => name.startsWith('__');

  const DbTable({
    required this.name,
    required this.columns,
    required this.keys,
  });

  DbTable copyWith({
    String? name,
    List<DbColumn>? columns,
    List<DbKey>? keys,
  }) {
    return DbTable(
      name: name ?? this.name,
      columns: columns ?? this.columns,
      keys: keys ?? this.keys,
    );
  }

  Map<String, dynamic> toMap() {
    return {
      'name': name,
      'columns': columns.map((c) => c.toMap()).toList(),
      'keys': keys.map((k) => k.toMap()).toList(),
    };
  }
}

<!-- END FILE: declarative_sqlite/lib/src/schema/db_table.dart -->

<!-- BEGIN FILE: declarative_sqlite/lib/src/schema/db_view.dart -->
/// Represents a database view with structured information about its components
class DbView {
  final String name;
  final List<ViewColumn> columns;
  final List<ViewTable> fromTables;
  final List<ViewJoin> joins;
  final List<String> whereClauses;
  final List<String> groupByColumns;
  final List<String> havingClauses;
  final List<String> orderByColumns;

  bool get isSystem => name.startsWith('__');

  const DbView({
    required this.name,
    required this.columns,
    required this.fromTables,
    this.joins = const [],
    this.whereClauses = const [],
    this.groupByColumns = const [],
    this.havingClauses = const [],
    this.orderByColumns = const [],
  });

  /// Generates the SQL definition for this view
  String get definition {
    final buffer = StringBuffer();
    
    // SELECT clause
    buffer.write('SELECT ${columns.map((c) => c.toSql()).join(', ')}');
    
    // FROM clause
    if (fromTables.isNotEmpty) {
      buffer.write(' FROM ${fromTables.map((t) => t.toSql()).join(', ')}');
    }
    
    // JOIN clauses
    if (joins.isNotEmpty) {
      buffer.write(' ${joins.map((j) => j.toSql()).join(' ')}');
    }
    
    // WHERE clause
    if (whereClauses.isNotEmpty) {
      buffer.write(' WHERE ${whereClauses.join(' AND ')}');
    }
    
    // GROUP BY clause
    if (groupByColumns.isNotEmpty) {
      buffer.write(' GROUP BY ${groupByColumns.join(', ')}');
    }
    
    // HAVING clause
    if (havingClauses.isNotEmpty) {
      buffer.write(' HAVING ${havingClauses.join(' AND ')}');
    }
    
    // ORDER BY clause
    if (orderByColumns.isNotEmpty) {
      buffer.write(' ORDER BY ${orderByColumns.join(', ')}');
    }
    
    return buffer.toString();
  }

  String toSql() {
    return 'CREATE VIEW $name AS $definition';
  }

  DbView copyWith({
    String? name,
    List<ViewColumn>? columns,
    List<ViewTable>? fromTables,
    List<ViewJoin>? joins,
    List<String>? whereClauses,
    List<String>? groupByColumns,
    List<String>? havingClauses,
    List<String>? orderByColumns,
  }) {
    return DbView(
      name: name ?? this.name,
      columns: columns ?? this.columns,
      fromTables: fromTables ?? this.fromTables,
      joins: joins ?? this.joins,
      whereClauses: whereClauses ?? this.whereClauses,
      groupByColumns: groupByColumns ?? this.groupByColumns,
      havingClauses: havingClauses ?? this.havingClauses,
      orderByColumns: orderByColumns ?? this.orderByColumns,
    );
  }

  Map<String, dynamic> toMap() {
    return {
      'name': name,
      'columns': columns.map((c) => c.toMap()).toList(),
      'fromTables': fromTables.map((t) => t.toMap()).toList(),
      'joins': joins.map((j) => j.toMap()).toList(),
      'whereClauses': whereClauses,
      'groupByColumns': groupByColumns,
      'havingClauses': havingClauses,
      'orderByColumns': orderByColumns,
      'definition': definition,
    };
  }
}

/// Represents a column in a view's SELECT clause
class ViewColumn {
  final String expression;
  final String? alias;
  final String? sourceTable;
  final String? sourceColumn;

  const ViewColumn({
    required this.expression,
    this.alias,
    this.sourceTable,
    this.sourceColumn,
  });

  /// The effective name of this column (alias if provided, otherwise derived from expression)
  String get name {
    if (alias != null) return alias!;
    
    // Try to extract column name from simple expressions like "table.column"
    if (expression.contains('.')) {
      return expression.split('.').last;
    }
    
    return expression;
  }

  String toSql() {
    if (alias != null) {
      return '$expression AS $alias';
    }
    return expression;
  }

  Map<String, dynamic> toMap() {
    return {
      'expression': expression,
      'alias': alias,
      'sourceTable': sourceTable,
      'sourceColumn': sourceColumn,
    };
  }
}

/// Represents a table in the FROM clause
class ViewTable {
  final String name;
  final String? alias;

  const ViewTable({
    required this.name,
    this.alias,
  });

  String toSql() {
    if (alias != null) {
      return '$name AS $alias';
    }
    return name;
  }

  Map<String, dynamic> toMap() {
    return {
      'name': name,
      'alias': alias,
    };
  }
}

/// Represents a JOIN clause in the view
class ViewJoin {
  final String type; // INNER, LEFT, RIGHT, FULL OUTER, CROSS
  final String table;
  final String? alias;
  final String? onCondition;

  const ViewJoin({
    required this.type,
    required this.table,
    this.alias,
    this.onCondition,
  });

  String toSql() {
    final buffer = StringBuffer();
    buffer.write('$type JOIN ');
    
    if (alias != null) {
      buffer.write('$table AS $alias');
    } else {
      buffer.write(table);
    }
    
    if (onCondition != null) {
      buffer.write(' ON $onCondition');
    }
    
    return buffer.toString();
  }

  Map<String, dynamic> toMap() {
    return {
      'type': type,
      'table': table,
      'alias': alias,
      'onCondition': onCondition,
    };
  }
}

<!-- END FILE: declarative_sqlite/lib/src/schema/db_view.dart -->

<!-- BEGIN FILE: declarative_sqlite/lib/src/schema/live_schema.dart -->
class LiveSchema {
  final List<LiveTable> tables;
  final List<LiveView> views;

  Iterable<LiveTable> get userTables => tables.where((t) => !t.isSystem);
  Iterable<LiveTable> get systemTables => tables.where((t) => t.isSystem);

  LiveSchema({required this.tables, required this.views});
}

class LiveTable {
  final String name;
  final List<LiveColumn> columns;
  final List<LiveKey> keys;

  bool get isSystem => name.startsWith('__');

  LiveTable({
    required this.name,
    required this.columns,
    required this.keys,
  });
}

class LiveView {
  final String name;
  final String sql;

  LiveView({required this.name, required this.sql});
}

class LiveColumn {
  final String name;
  final String type;
  final bool isNotNull;
  final bool isPrimaryKey;
  final String? defaultValue;

  LiveColumn({
    required this.name,
    required this.type,
    required this.isNotNull,
    required this.isPrimaryKey,
    this.defaultValue,
  });
}

class LiveKey {
  final String name;
  final List<String> columns;
  final bool isUnique;

  LiveKey({required this.name, required this.columns, required this.isUnique});
}

<!-- END FILE: declarative_sqlite/lib/src/schema/live_schema.dart -->

<!-- BEGIN FILE: declarative_sqlite/lib/src/schema/schema.dart -->
import 'dart:convert';
import 'package:crypto/crypto.dart';
import 'package:declarative_sqlite/src/schema/db_table.dart';
import 'package:declarative_sqlite/src/schema/db_view.dart';
import '../builders/analysis_context.dart';

class Schema implements SchemaProvider {
  final List<DbTable> tables;
  final List<DbView> views;

  Iterable<DbTable> get userTables => tables.where((t) => !t.isSystem);
  Iterable<DbTable> get systemTables => tables.where((t) => t.isSystem);


  const Schema({
    required this.tables,
    required this.views,
  });

  String toHash() {
    final schemaMap = {
      'tables': tables.map((t) => t.toMap()).toList(),
      'views': views.map((v) => v.toMap()).toList(),
    };
    final jsonString = jsonEncode(schemaMap);
    return sha256.convert(utf8.encode(jsonString)).toString();
  }

  @override
  bool tableHasColumn(String tableName, String columnName) {
    // Check tables
    final table = tables.where((t) => t.name == tableName).firstOrNull;
    if (table != null) {
      return table.columns.any((c) => c.name == columnName);
    }
    
    // Check views using the new structured information
    final view = views.where((v) => v.name == tableName).firstOrNull;
    if (view != null) {
      return view.columns.any((c) => c.name == columnName);
    }
    
    return false;
  }

  @override
  List<String> getTablesWithColumn(String columnName) {
    final result = <String>[];
    
    // Check all tables
    for (final table in tables) {
      if (table.columns.any((c) => c.name == columnName)) {
        result.add(table.name);
      }
    }
    
    // Check all views using structured column information
    for (final view in views) {
      if (view.columns.any((c) => c.name == columnName)) {
        result.add(view.name);
      }
    }
    
    return result;
  }
}

<!-- END FILE: declarative_sqlite/lib/src/schema/schema.dart -->

<!-- BEGIN FILE: declarative_sqlite/lib/src/streaming/query_dependency_analyzer.dart -->
import '../builders/analysis_context.dart';
import '../builders/query_builder.dart';
import '../builders/query_dependencies.dart';
import '../builders/where_clause.dart';

/// Analyzes queries to determine their database dependencies using object-oriented approach.
/// 
/// This analyzer uses the self-reporting pattern where QueryBuilder and WhereClause
/// objects analyze their own dependencies rather than external SQL parsing.
/// Requires a schema provider to accurately resolve unqualified column references.
/// 
/// For complex queries with subqueries, joins, or intricate WHERE clauses, the analyzer
/// may fall back to table-level dependencies to ensure reliability. This conservative
/// approach prevents missed updates when column-level analysis might be incomplete.
class QueryDependencyAnalyzer {
  final SchemaProvider _schema;

  /// Creates a query dependency analyzer with the required schema provider.
  /// 
  /// The schema enables accurate resolution of unqualified column references
  /// to their correct tables, which is essential for proper dependency tracking
  /// in complex queries with multiple tables and subqueries.
  QueryDependencyAnalyzer(this._schema);

  /// Creates a schema-aware analysis context for use in custom analysis.
  AnalysisContext createAnalysisContext() {
    return AnalysisContext(_schema);
  }
  /// Analyzes a QueryBuilder to extract all database dependencies.
  ///
  /// Returns a [QueryDependencies] object containing:
  /// - Tables referenced in the query
  /// - Columns referenced in the query  
  /// - Whether wildcard selection (*) is used
  ///
  /// Uses schema information to accurately resolve unqualified column references
  /// to their correct tables. For complex queries where column-level analysis
  /// might miss dependencies, the system falls back to table-level tracking
  /// to ensure streaming queries update reliably when underlying data changes.
  QueryDependencies analyzeQuery(QueryBuilder builder) {
    final context = AnalysisContext(_schema);
    return builder.analyzeDependencies(context);
  }

  /// Analyzes a WHERE clause to extract column and table dependencies.
  ///
  /// Useful for analyzing WHERE clauses in isolation, such as for 
  /// conditional updates or filtered queries.
  /// Uses schema information for accurate column-to-table resolution.
  QueryDependencies analyzeWhereClause(WhereClause whereClause, [AnalysisContext? context]) {
    final analysisContext = context ?? AnalysisContext(_schema);
    return whereClause.analyzeDependencies(analysisContext);
  }

  /// Checks if a query depends on a specific table.
  ///
  /// This is useful for cache invalidation - if a table is modified,
  /// all queries that depend on it should have their cached results invalidated.
  bool queryDependsOnTable(QueryBuilder builder, String tableName) {
    final dependencies = analyzeQuery(builder);
    return dependencies.tables.contains(tableName) ||
           dependencies.tables.any((table) => table.split(' ').first == tableName);
  }

  /// Checks if a query depends on a specific column.
  ///
  /// This provides fine-grained dependency tracking for optimized caching.
  bool queryDependsOnColumn(QueryBuilder builder, String columnName) {
    final dependencies = analyzeQuery(builder);
    
    // Check for column match by name
    return dependencies.columns.any((col) => col.column == columnName);
  }

  /// Gets all tables that a query depends on.
  ///
  /// Returns table names without aliases for consistent cache key generation.
  Set<String> getQueryTables(QueryBuilder builder) {
    final dependencies = analyzeQuery(builder);
    
    // Extract base table names (remove aliases)
    return dependencies.tables.map((table) {
      final parts = table.split(' ');
      return parts.first; // Get table name before any AS alias
    }).toSet();
  }

  /// Gets all columns that a query depends on.
  ///
  /// Returns QueryDependencyColumn objects with table and column information.
  Set<QueryDependencyColumn> getQueryColumns(QueryBuilder builder) {
    final dependencies = analyzeQuery(builder);
    return Set.from(dependencies.columns);
  }

  /// Checks if a query uses wildcard selection.
  ///
  /// Wildcard queries depend on all columns of their referenced tables
  /// and require broader cache invalidation strategies.
  bool usesWildcardSelection(QueryBuilder builder) {
    final dependencies = analyzeQuery(builder);
    return dependencies.usesWildcard;
  }
}
<!-- END FILE: declarative_sqlite/lib/src/streaming/query_dependency_analyzer.dart -->

<!-- BEGIN FILE: declarative_sqlite/lib/src/streaming/query_emoji_utils.dart -->
/// Animal emojis for query ID differentiation
const animalEmojis = [
  'üê∂', 'üê±', 'üê≠', 'üêπ', 'üê∞', 'ü¶ä', 'üêª', 'üêº', 'üê®', 'üêØ',
  'ü¶Å', 'üêÆ', 'üê∑', 'üê∏', 'üêµ', 'üôà', 'üôâ', 'üôä', 'üêí', 'üêî',
  'üêß', 'üê¶', 'üê§', 'üê£', 'üê•', 'ü¶Ü', 'ü¶Ö', 'ü¶â', 'ü¶á', 'üê∫',
  'üêó', 'üê¥', 'ü¶Ñ', 'üêù', 'üêõ', 'ü¶ã', 'üêå', 'üêû', 'üêú', 'ü¶ü',
  'ü¶ó', 'üï∑Ô∏è', 'ü¶Ç', 'üê¢', 'üêç', 'ü¶é', 'ü¶ñ', 'ü¶ï', 'üêô', 'ü¶ë',
  'ü¶ê', 'ü¶û', 'ü¶Ä', 'üê°', 'üê†', 'üêü', 'üê¨', 'üê≥', 'üêã', 'ü¶à',
  'üêä', 'üêÖ', 'üêÜ', 'ü¶ì', 'ü¶è', 'ü¶õ', 'üêò', 'ü¶í', 'ü¶ò', 'üêøÔ∏è',
  'ü¶î', 'ü¶á', 'üêÅ', 'üêÄ', 'üêà', 'üêï', 'üê©', 'üêÇ', 'üêÑ', 'üêé',
  'üêñ', 'üêè', 'üêë', 'ü¶ô', 'üêê', 'ü¶å', 'üêï‚Äçü¶∫', 'üêà‚Äç‚¨õ', 'üêì', 'ü¶É',
  'ü¶ö', 'ü¶ú', 'ü¶¢', 'ü¶©', 'üïäÔ∏è', 'üêá', 'ü¶ù', 'ü¶®', 'ü¶°', 'ü¶´'
];

/// Generate an animal emoji based on query ID hash
String getAnimalEmoji(String queryId) {
  final hash = queryId.hashCode.abs();
  return animalEmojis[hash % animalEmojis.length];
}
<!-- END FILE: declarative_sqlite/lib/src/streaming/query_emoji_utils.dart -->

<!-- BEGIN FILE: declarative_sqlite/lib/src/streaming/query_stream_manager.dart -->
import 'dart:async';
import 'dart:developer' as developer;
import 'package:rxdart/rxdart.dart';
import 'streaming_query.dart';
import 'query_emoji_utils.dart';

/// Manages multiple streaming queries and coordinates their updates with batching and debouncing
class QueryStreamManager {
  final Map<String, StreamingQuery> _queries = {};
  
  // Use RxDart for batching table change notifications to prevent rapid refresh cycles
  PublishSubject<String> _tableChangeSubject = PublishSubject<String>();
  late StreamSubscription _tableChangeSubscription;
  
  QueryStreamManager() {
    developer.log('QueryStreamManager: Initializing with batched table change processing (100ms buffer window)', name: 'QueryStreamManager');
    
    // Use buffer with debounce to collect ALL table changes within the time window
    _tableChangeSubscription = _tableChangeSubject
        .bufferTime(const Duration(milliseconds: 50))
        .where((batch) => batch.isNotEmpty) // Only process non-empty batches
        .listen(
          _processBatchedTableChanges,
          onError: (error, stackTrace) {
            developer.log('QueryStreamManager: Error in batched stream processing', error: error, stackTrace: stackTrace, name: 'QueryStreamManager');
          },
        );
        
    developer.log('QueryStreamManager: Batched table change subscription established', name: 'QueryStreamManager');
  }
  
  /// Registers a streaming query with the manager
  void register(StreamingQuery query) {
    final emoji = getAnimalEmoji(query.id);
    developer.log('QueryStreamManager.register: $emoji Registering query id="${query.id}", isActive=${query.isActive}', name: 'QueryStreamManager');
    _queries[query.id] = query;
    developer.log('QueryStreamManager.register: $emoji Successfully registered query id="${query.id}". Total queries: ${_queries.length}', name: 'QueryStreamManager');
  }

  /// Unregisters a streaming query from the manager and disposes it
  void unregister(String queryId) {
    final emoji = getAnimalEmoji(queryId);
    developer.log('QueryStreamManager.unregister: $emoji Unregistering query id="$queryId"', name: 'QueryStreamManager');
    final query = _queries.remove(queryId);
    if (query != null) {
      // Fire and forget the async dispose
      query.dispose().catchError((error) {
        developer.log('QueryStreamManager.unregister: $emoji Error disposing query id="$queryId": $error', name: 'QueryStreamManager');
      });
      developer.log('QueryStreamManager.unregister: $emoji Successfully unregistered and disposed query id="$queryId"', name: 'QueryStreamManager');
    } else {
      developer.log('QueryStreamManager.unregister: $emoji Query id="$queryId" was not found in active queries', name: 'QueryStreamManager');
    }
  }

  /// Unregisters a streaming query from the manager without disposing it
  /// This is used when the query is managing its own disposal
  void unregisterOnly(String queryId) {
    final emoji = getAnimalEmoji(queryId);
    final wasPresent = _queries.containsKey(queryId);
    developer.log('QueryStreamManager.unregisterOnly: $emoji Unregistering query id="$queryId" (without disposal). Was present: $wasPresent', name: 'QueryStreamManager');
    _queries.remove(queryId);
    developer.log('QueryStreamManager.unregisterOnly: $emoji Successfully unregistered query id="$queryId". Total queries: ${_queries.length}', name: 'QueryStreamManager');
  }

  /// Notifies all relevant queries that a table has been modified (batched to prevent rapid cycles)
  Future<void> notifyTableChanged(String tableName) async {
    developer.log('QueryStreamManager.notifyTableChanged: Queuing table change notification for table="$tableName" (will be batched). Currently ${_queries.length} queries registered.', name: 'QueryStreamManager');
    
    // Check if we have any queries that would be affected
    final affectedCount = _queries.values
        .where((query) => query.isActive && query.isAffectedByTable(tableName))
        .length;
    developer.log('QueryStreamManager.notifyTableChanged: $affectedCount queries would be affected by table="$tableName" change', name: 'QueryStreamManager');
    
    // Debug the state of the debouncing stream
    if (_tableChangeSubject.isClosed) {
      developer.log('QueryStreamManager.notifyTableChanged: ERROR - _tableChangeSubject is closed! Resetting debouncing stream and retrying for table="$tableName"', name: 'QueryStreamManager');
      _resetDebouncingStream();
    }
    
    try {
      _tableChangeSubject.add(tableName);
      developer.log('QueryStreamManager.notifyTableChanged: Table change queued for batching, table="$tableName"', name: 'QueryStreamManager');
    } catch (e) {
      developer.log('QueryStreamManager.notifyTableChanged: ERROR adding to _tableChangeSubject for table="$tableName": $e. Attempting to reset stream.', name: 'QueryStreamManager');
      _resetDebouncingStream();
      
      // Try once more after reset
      try {
        _tableChangeSubject.add(tableName);
        developer.log('QueryStreamManager.notifyTableChanged: Successfully queued after stream reset for table="$tableName"', name: 'QueryStreamManager');
      } catch (retryError) {
        developer.log('QueryStreamManager.notifyTableChanged: FATAL - Still failing after stream reset for table="$tableName": $retryError', name: 'QueryStreamManager');
        
        // Last resort: process directly without debouncing
        developer.log('QueryStreamManager.notifyTableChanged: Using fallback direct processing for table="$tableName"', name: 'QueryStreamManager');
        _processTableChange(tableName).catchError((error) {
          developer.log('QueryStreamManager.notifyTableChanged: Fallback processing also failed for table="$tableName": $error', name: 'QueryStreamManager');
        });
      }
    }
  }
  
  /// Process a batch of table change notifications (called after buffering)
  Future<void> _processBatchedTableChanges(List<String> tableNames) async {
    if (tableNames.isEmpty) return;
    
    // Remove duplicates while preserving order
    final uniqueTableNames = tableNames.toSet().toList();
    
    developer.log('QueryStreamManager._processBatchedTableChanges: Processing batched table changes for tables=${uniqueTableNames.join(", ")} (${tableNames.length} events batched into ${uniqueTableNames.length} unique tables), checking ${_queries.length} registered queries', name: 'QueryStreamManager');
    
    try {
      // Collect all affected queries (deduplicated by query ID)
      final affectedQueries = <String, StreamingQuery>{};
      
      for (final tableName in uniqueTableNames) {
        for (final query in _queries.values) {
          if (query.isActive && query.isAffectedByTable(tableName)) {
            affectedQueries[query.id] = query;
          }
        }
      }

      developer.log('QueryStreamManager._processBatchedTableChanges: Found ${affectedQueries.length} unique affected queries for tables=${uniqueTableNames.join(", ")}', name: 'QueryStreamManager');
      
      if (affectedQueries.isEmpty) {
        developer.log('QueryStreamManager._processBatchedTableChanges: No affected queries for tables=${uniqueTableNames.join(", ")}, skipping refresh', name: 'QueryStreamManager');
        return;
      }

      developer.log('QueryStreamManager._processBatchedTableChanges: Refreshing ${affectedQueries.length} queries for tables=${uniqueTableNames.join(", ")}', name: 'QueryStreamManager');
      
      // Refresh all affected queries concurrently with error handling
      final results = await Future.wait(
        affectedQueries.values.map((query) async {
          try {
            final emoji = getAnimalEmoji(query.id);
            developer.log('QueryStreamManager._processBatchedTableChanges: $emoji Refreshing query id="${query.id}" for tables=${uniqueTableNames.join(", ")}', name: 'QueryStreamManager');
            await query.refresh();
            developer.log('QueryStreamManager._processBatchedTableChanges: $emoji Successfully refreshed query id="${query.id}" for tables=${uniqueTableNames.join(", ")}', name: 'QueryStreamManager');
            return null;
          } catch (e) {
            final emoji = getAnimalEmoji(query.id);
            final errorMsg = '$emoji Query ${query.id} refresh failed: $e';
            developer.log('QueryStreamManager._processBatchedTableChanges: $errorMsg', name: 'QueryStreamManager');
            return errorMsg;
          }
        }),
      );

      // Handle any errors that occurred
      final errors = results.where((error) => error != null).toList();
      if (errors.isNotEmpty) {
        developer.log('QueryStreamManager._processBatchedTableChanges: ${errors.length} queries had errors during refresh for tables=${uniqueTableNames.join(", ")}: ${errors.join(", ")}', name: 'QueryStreamManager');
      } else {
        developer.log('QueryStreamManager._processBatchedTableChanges: All queries refreshed successfully for tables=${uniqueTableNames.join(", ")}', name: 'QueryStreamManager');
      }

      // Aggregate and log cache performance across all refreshed queries
      _logAggregatedCacheStats(affectedQueries.values.toList(), uniqueTableNames);
    } catch (e, stackTrace) {
      developer.log('QueryStreamManager._processBatchedTableChanges: Error during batched table change notification for tables=${uniqueTableNames.join(", ")}', error: e, stackTrace: stackTrace, name: 'QueryStreamManager');
      rethrow;
    }
  }

  /// Process a single table change notification (for backward compatibility and debugging)
  Future<void> _processTableChange(String tableName) async {
    await _processBatchedTableChanges([tableName]);
  }

  /// Notifies all relevant queries that a specific column has been modified
  Future<void> notifyColumnChanged(String tableName, String columnName) async {
    developer.log('QueryStreamManager.notifyColumnChanged: Notifying queries about column="$tableName.$columnName" change, checking ${_queries.length} registered queries', name: 'QueryStreamManager');
    
    try {
      final affectedQueries = _queries.values
          .where((query) => 
              query.isActive && 
              query.isAffectedByColumn(tableName, columnName))
          .toList();

      developer.log('QueryStreamManager.notifyColumnChanged: Found ${affectedQueries.length} affected queries for column="$tableName.$columnName"', name: 'QueryStreamManager');
      
      if (affectedQueries.isEmpty) {
        developer.log('QueryStreamManager.notifyColumnChanged: No affected queries for column="$tableName.$columnName", skipping refresh', name: 'QueryStreamManager');
        return;
      }

      developer.log('QueryStreamManager.notifyColumnChanged: Refreshing ${affectedQueries.length} queries for column="$tableName.$columnName"', name: 'QueryStreamManager');
      
      // Refresh all affected queries concurrently with error handling
      final results = await Future.wait(
        affectedQueries.map((query) async {
          try {
            final emoji = getAnimalEmoji(query.id);
            developer.log('QueryStreamManager.notifyColumnChanged: $emoji Refreshing query id="${query.id}" for column="$tableName.$columnName"', name: 'QueryStreamManager');
            await query.refresh();
            developer.log('QueryStreamManager.notifyColumnChanged: $emoji Successfully refreshed query id="${query.id}" for column="$tableName.$columnName"', name: 'QueryStreamManager');
            return null;
          } catch (e) {
            final emoji = getAnimalEmoji(query.id);
            final errorMsg = '$emoji Query ${query.id} refresh failed: $e';
            developer.log('QueryStreamManager.notifyColumnChanged: $errorMsg', name: 'QueryStreamManager');
            return errorMsg;
          }
        }),
      );

      // Handle any errors that occurred
      final errors = results.where((error) => error != null).toList();
      if (errors.isNotEmpty) {
        developer.log('QueryStreamManager.notifyColumnChanged: ${errors.length} queries had errors during refresh for column="$tableName.$columnName": ${errors.join(", ")}', name: 'QueryStreamManager');
      } else {
        developer.log('QueryStreamManager.notifyColumnChanged: All queries refreshed successfully for column="$tableName.$columnName"', name: 'QueryStreamManager');
      }
    } catch (e, stackTrace) {
      developer.log('QueryStreamManager.notifyColumnChanged: Error during column change notification for column="$tableName.$columnName"', error: e, stackTrace: stackTrace, name: 'QueryStreamManager');
      rethrow;
    }
  }

  /// Returns the number of active streaming queries
  int get activeQueryCount => _queries.values.where((q) => q.isActive).length;

  /// Returns the total number of registered queries
  int get totalQueryCount => _queries.length;

  /// Returns the list of currently active streaming queries
  List<StreamingQuery> get activeQueries => 
      _queries.values.where((q) => q.isActive).toList();

  /// Returns all registered streaming queries (active and inactive)
  List<StreamingQuery> get allQueries => _queries.values.toList();

  /// Notifies all relevant queries about multiple table changes at once
  /// This is more efficient than calling notifyTableChanged multiple times
  Future<void> notifyMultipleTablesChanged(List<String> tableNames) async {
    if (tableNames.isEmpty) return;

    try {
      // Collect all affected queries (deduplicated)
      final affectedQueries = <String, StreamingQuery>{};
      
      for (final tableName in tableNames) {
        for (final query in _queries.values) {
          if (query.isActive && query.isAffectedByTable(tableName)) {
            affectedQueries[query.id] = query;
          }
        }
      }

      if (affectedQueries.isEmpty) return;

      // Refresh all affected queries concurrently
      final results = await Future.wait(
        affectedQueries.values.map((query) async {
          try {
            await query.refresh();
            return null;
          } catch (e) {
            return 'Query ${query.id} refresh failed: $e';
          }
        }),
      );

      // Handle any errors that occurred
      final errors = results.where((error) => error != null).toList();
      if (errors.isNotEmpty) {
        // In a production app, you might want to log these errors
      }
    } catch (e) {
      rethrow;
    }
  }

  /// Clean up inactive queries
  void cleanup() {
    developer.log('QueryStreamManager.cleanup: Starting cleanup, checking ${_queries.length} registered queries', name: 'QueryStreamManager');
    
    final inactiveQueries = _queries.entries
        .where((entry) => !entry.value.isActive)
        .map((entry) => entry.key)
        .toList();

    developer.log('QueryStreamManager.cleanup: Found ${inactiveQueries.length} inactive queries to remove: ${inactiveQueries.join(", ")}', name: 'QueryStreamManager');
    
    for (final queryId in inactiveQueries) {
      unregister(queryId);
    }
    
    developer.log('QueryStreamManager.cleanup: Cleanup completed, ${_queries.length} queries remaining', name: 'QueryStreamManager');
  }

  /// Dispose of all queries and clean up
  Future<void> dispose() async {
    developer.log('QueryStreamManager.dispose: Disposing ${_queries.length} registered queries', name: 'QueryStreamManager');
    
    // Clean up debounced table change subscription
    await _tableChangeSubscription.cancel();
    _tableChangeSubject.close();
    
    final disposeFutures = <Future<void>>[];
    
    for (final query in _queries.values) {
      final emoji = getAnimalEmoji(query.id);
      developer.log('QueryStreamManager.dispose: $emoji Disposing query id="${query.id}"', name: 'QueryStreamManager');
      disposeFutures.add(
        query.dispose().catchError((error) {
          developer.log('QueryStreamManager.dispose: $emoji Error disposing query id="${query.id}": $error', name: 'QueryStreamManager');
        })
      );
    }
    
    // Wait for all disposals to complete (with timeout)
    try {
      await Future.wait(disposeFutures).timeout(Duration(seconds: 10));
    } catch (e) {
      developer.log('QueryStreamManager.dispose: Timeout or error during bulk disposal: $e', name: 'QueryStreamManager');
    }
    
    _queries.clear();
    developer.log('QueryStreamManager.dispose: All queries disposed and cleared', name: 'QueryStreamManager');
  }

  /// Debug method to check the current state of the stream manager
  void debugState({String? context}) {
    final contextStr = context != null ? '[$context] ' : '';
    developer.log('${contextStr}QueryStreamManager.debugState: ${_queries.length} total queries, $activeQueryCount active', name: 'QueryStreamManager');
    
    if (_queries.isNotEmpty) {
      for (final query in _queries.values) {
        final emoji = getAnimalEmoji(query.id);
        final tables = query.dependencies.tables.join(', ');
        developer.log('${contextStr}QueryStreamManager.debugState: $emoji Query "${query.id}" - active: ${query.isActive}, tables: {$tables}', name: 'QueryStreamManager');
      }
    } else {
      developer.log('${contextStr}QueryStreamManager.debugState: No queries currently registered', name: 'QueryStreamManager');
    }
  }

  /// Test method to manually trigger table change processing (bypassing debounce)
  Future<void> debugProcessTableChange(String tableName) async {
    developer.log('QueryStreamManager.debugProcessTableChange: Manually processing table change for table="$tableName" (bypassing debounce)', name: 'QueryStreamManager');
    await _processTableChange(tableName);
  }

  /// Test method to check if the debouncing stream is working
  void debugTestDebouncing(String tableName) {
    developer.log('QueryStreamManager.debugTestDebouncing: Testing debouncing stream with table="$tableName"', name: 'QueryStreamManager');
    developer.log('QueryStreamManager.debugTestDebouncing: _tableChangeSubject.isClosed = ${_tableChangeSubject.isClosed}', name: 'QueryStreamManager');
    developer.log('QueryStreamManager.debugTestDebouncing: _tableChangeSubscription.isPaused = ${_tableChangeSubscription.isPaused}', name: 'QueryStreamManager');
    
    // Try adding a test event
    try {
      _tableChangeSubject.add(tableName);
      developer.log('QueryStreamManager.debugTestDebouncing: Successfully added test event to debouncing stream', name: 'QueryStreamManager');
    } catch (e) {
      developer.log('QueryStreamManager.debugTestDebouncing: ERROR adding test event: $e', name: 'QueryStreamManager');
    }
  }

  /// Reset the debouncing stream if it gets into a bad state
  void _resetDebouncingStream() {
    developer.log('QueryStreamManager._resetDebouncingStream: Resetting debouncing stream due to malfunction', name: 'QueryStreamManager');
    
    try {
      // Cancel the old subscription
      _tableChangeSubscription.cancel();
      
      // Close the old subject if it's not already closed
      if (!_tableChangeSubject.isClosed) {
        _tableChangeSubject.close();
      }
    } catch (e) {
      developer.log('QueryStreamManager._resetDebouncingStream: Error cleaning up old stream: $e', name: 'QueryStreamManager');
    }
    
    // Create new subject and subscription with batching
    final newSubject = PublishSubject<String>();
    final newSubscription = newSubject
        .bufferTime(const Duration(milliseconds: 100))
        .where((batch) => batch.isNotEmpty)
        .listen(
          _processBatchedTableChanges,
          onError: (error, stackTrace) {
            developer.log('QueryStreamManager: Error in batched stream processing', error: error, stackTrace: stackTrace, name: 'QueryStreamManager');
          },
        );
    
    // Replace with new instances
    _tableChangeSubject = newSubject;
    _tableChangeSubscription = newSubscription;
    
    developer.log('QueryStreamManager._resetDebouncingStream: Debouncing stream reset complete', name: 'QueryStreamManager');
  }

  /// Log aggregated cache statistics across multiple queries
  void _logAggregatedCacheStats(List<StreamingQuery> queries, List<String> tableNames) {
    if (queries.isEmpty) return;

    int totalHits = 0;
    int totalMisses = 0;
    int totalCacheSize = 0;
    int queriesWithStats = 0;
    int queriesWithCache = 0;
    int queriesWithoutCache = 0;

    for (final query in queries) {
      final stats = query.lastCacheStats;
      final cacheSize = query.cacheSize;
      
      if (cacheSize > 0) {
        queriesWithCache++;
        totalCacheSize += cacheSize;
      } else {
        queriesWithoutCache++;
      }
      
      if (stats != null) {
        totalHits += stats.hits;
        totalMisses += stats.misses;
        queriesWithStats++;
      }
    }

    final totalItems = totalHits + totalMisses;
    if (totalItems > 0 && queriesWithStats > 0) {
      final overallHitPercentage = (totalHits / totalItems * 100).toStringAsFixed(1);
      String cacheabilityInfo = queriesWithoutCache > 0 
          ? " ($queriesWithCache cacheable, $queriesWithoutCache non-cacheable)"
          : " (all cacheable)";
      developer.log('QueryStreamManager._processBatchedTableChanges: üìä Aggregated cache performance for ${queries.length} queries$cacheabilityInfo (tables=${tableNames.join(", ")}): $totalHits/$totalItems hits ($overallHitPercentage%), $totalMisses misses, total cache entries: $totalCacheSize', name: 'QueryStreamManager');
    } else if (totalCacheSize > 0) {
      String cacheabilityInfo = queriesWithoutCache > 0 
          ? " ($queriesWithCache cacheable, $queriesWithoutCache non-cacheable)"
          : " (all cacheable)";
      developer.log('QueryStreamManager._processBatchedTableChanges: üìä Cache status for ${queries.length} queries$cacheabilityInfo (tables=${tableNames.join(", ")}): $totalCacheSize total cached entries, no refresh statistics available', name: 'QueryStreamManager');
    } else {
      developer.log('QueryStreamManager._processBatchedTableChanges: üìä Cache status for ${queries.length} queries (tables=${tableNames.join(", ")}): No caching available (queries may lack system columns)', name: 'QueryStreamManager');
    }
  }

  @override
  String toString() {
    return 'QueryStreamManager(active: $activeQueryCount, total: $totalQueryCount)';
  }
}
<!-- END FILE: declarative_sqlite/lib/src/streaming/query_stream_manager.dart -->

<!-- BEGIN FILE: declarative_sqlite/lib/src/streaming/streaming_query.dart -->
import 'dart:async';
import 'dart:developer' as developer;

import 'package:rxdart/rxdart.dart';

import '../builders/query_builder.dart';
import '../builders/query_dependencies.dart';
import '../declarative_database.dart';
import 'query_dependency_analyzer.dart';
import 'query_emoji_utils.dart';

/// A cached result entry containing the mapped object and its system version
class _CachedResult<T> {
  final T object;
  final String systemVersion;

  const _CachedResult(this.object, this.systemVersion);
}

/// A streaming query that emits new results whenever the underlying data changes.
///
/// Uses sophisticated dependency analysis to track exactly which tables and columns
/// this query depends on, ensuring updates only occur when relevant data changes.
/// For complex queries, falls back to table-level dependencies for reliability.
///
/// Requires that all queried tables have system_id and system_version columns
/// for proper change detection and object caching optimization.
class StreamingQuery<T> {
  final String _id;
  late QueryBuilder _builder;
  late QueryDependencies _dependencies;
  final DeclarativeDatabase _database;
  late T Function(Map<String, Object?>) _mapper;

  late final BehaviorSubject<List<T>> _subject;
  bool _isActive = false;
  bool _isDisposed = false;

  /// Cache of previously mapped results indexed by their system_id
  final Map<String, _CachedResult<T>> _resultCache = {};

  /// System IDs of the last emitted result set for fast comparison
  List<String>? _lastResultSystemIds;

  /// Reference to the last mapper function for change detection
  T Function(Map<String, Object?>)? _lastMapper;

  /// Completer to track ongoing refresh operations
  Completer<void>? _ongoingRefresh;

  StreamingQuery._({
    required String id,
    required QueryBuilder builder,
    required QueryDependencies dependencies,
    required DeclarativeDatabase database,
    required T Function(Map<String, Object?>) mapper,
  }) : _id = id,
       _builder = builder,
       _dependencies = dependencies,
       _database = database,
       _mapper = mapper,
       _lastMapper = mapper {
    _subject = BehaviorSubject<List<T>>();
  }

  /// Factory constructor to create a streaming query
  factory StreamingQuery.create({
    required String id,
    required QueryBuilder builder,
    required DeclarativeDatabase database,
    required T Function(Map<String, Object?>) mapper,
  }) {
    // Use schema-aware dependency analysis
    final analyzer = QueryDependencyAnalyzer(database.schema);
    final dependencies = analyzer.analyzeQuery(builder);

    return StreamingQuery._(
      id: id,
      builder: builder,
      dependencies: dependencies,
      database: database,
      mapper: mapper,
    );
  }

  /// The unique identifier for this streaming query
  String get id => _id;

  /// The dependencies this query has on database entities
  QueryDependencies get dependencies => _dependencies;

  /// The stream of query results with automatic replay of last value
  Stream<List<T>> get stream {
    return _subject.stream.doOnListen(_onListen).doOnCancel(_onCancel);
  }

  /// Whether this query is currently active (has listeners)
  bool get isActive => _isActive;

  /// The current size of the result cache
  int get cacheSize => _resultCache.length;

  /// Cache statistics from the last refresh operation
  ({int hits, int misses, double hitPercentage})? _lastCacheStats;

  /// Get the cache statistics from the last refresh operation
  ({int hits, int misses, double hitPercentage})? get lastCacheStats =>
      _lastCacheStats;

  /// Whether this query supports caching (has system columns and cached data)
  bool get supportsCaching =>
      _resultCache.isNotEmpty || _lastResultSystemIds != null;

  /// Updates the query builder and mapper with smart lifecycle management.
  ///
  /// Re-analyzes dependencies when the query changes to ensure accurate
  /// dependency tracking. Invalidates cache when mapper changes.
  Future<void> updateQuery({
    QueryBuilder? newBuilder,
    T Function(Map<String, Object?>)? newMapper,
  }) async {
    bool needsRefresh = false;
    bool needsCacheInvalidation = false;

    // Check if query builder changed (using Equatable value equality)
    if (newBuilder != null && newBuilder != _builder) {
      _builder = newBuilder;

      // Re-analyze dependencies for the new query
      final analyzer = QueryDependencyAnalyzer(_database.schema);
      _dependencies = analyzer.analyzeQuery(newBuilder);

      needsRefresh = true;
    }

    // Check if mapper function changed (using reference equality)
    if (newMapper != null && !identical(newMapper, _lastMapper)) {
      _mapper = newMapper;
      _lastMapper = newMapper;
      needsCacheInvalidation = true;
      needsRefresh = true;
    }

    // Invalidate cache if mapper changed
    if (needsCacheInvalidation) {
      _resultCache.clear();
      _lastResultSystemIds = null;
    }

    // Execute new query if needed
    if (needsRefresh && _isActive) {
      await refresh();
    }
  }

  /// Returns true if this query might be affected by changes to the given table.
  ///
  /// For complex queries, dependency analysis falls back to table-level tracking
  /// to ensure reliability when column-level analysis might miss edge cases.
  bool isAffectedByTable(String tableName) {
    return _dependencies.tables.contains(tableName) ||
        _dependencies.tables.any(
          (table) => table.split(' ').first == tableName,
        );
  }

  /// Returns true if this query might be affected by changes to the given column.
  ///
  /// Uses precise column-level dependency tracking when possible. For wildcard
  /// queries or complex cases, falls back to table-level dependencies.
  bool isAffectedByColumn(String tableName, String columnName) {
    // If using wildcard selection, any column in referenced tables affects the query
    if (_dependencies.usesWildcard &&
        _dependencies.tables.any(
          (table) => table.split(' ').first == tableName,
        )) {
      return true;
    }

    // Check for specific column dependencies
    return _dependencies.columns.any(
      (col) => col.table == tableName && col.column == columnName,
    );
  }

  /// Manually trigger a refresh of this query with system column optimization.
  ///
  /// Requires that all queried tables have system_id and system_version columns
  /// for proper change detection and caching optimization.
  Future<void> refresh() async {
    // Check if disposed before starting
    if (_isDisposed || !_isActive) {
      return;
    }

    // Track this refresh operation
    _ongoingRefresh = Completer<void>();

    try {
      final rawResults = await _database.queryMapsWith(_builder);

      // Try to use caching, fall back to direct mapping if system columns are missing
      final systemData = _extractSystemData(rawResults);
      if (systemData == null) {
        await _emitDirectResults(rawResults, 'No system columns detected');
        return;
      }

      final (newResultSystemIds, systemIdToVersion) = systemData;

      // Quick check: if system ID sequence is identical, check for version changes
      bool hasChanges = !_areSystemIdSequencesEqual(
        newResultSystemIds,
        _lastResultSystemIds,
      );
      if (!hasChanges && _lastResultSystemIds != null) {
        // Check if any system versions have changed
        for (final systemId in newResultSystemIds) {
          final cached = _resultCache[systemId];
          final currentVersion = systemIdToVersion[systemId];
          if (cached == null || cached.systemVersion != currentVersion) {
            hasChanges = true;
            break;
          }
        }
      }

      if (!hasChanges) {
        return; // No changes, no emission needed
      }

      // Build the new result list using cache optimization
      await _emitCachedResults(
        rawResults,
        newResultSystemIds,
        systemIdToVersion,
      );

      // Update cached state
      _lastResultSystemIds = newResultSystemIds;
    } catch (error, stackTrace) {
      final emoji = getAnimalEmoji(_id);
      developer.log(
        'StreamingQuery.refresh: $emoji Error during refresh for id="$_id"',
        error: error,
        stackTrace: stackTrace,
        name: 'StreamingQuery',
      );

      // Only add error if not disposed and subject is open
      if (!_isDisposed && !_subject.isClosed) {
        _subject.addError(error);
      }
    } finally {
      // Mark refresh as completed
      _ongoingRefresh?.complete();
      _ongoingRefresh = null;
    }
  }

  /// Extracts system_id and system_version data from raw results.
  /// Returns null if system columns are not available at all.
  /// Allows mixed results where some rows have system columns and others don't.
  (List<String>, Map<String, String>)? _extractSystemData(
    List<Map<String, Object?>> rawResults,
  ) {
    if (rawResults.isEmpty) {
      return ([], {});
    }

    // Check if any row has system columns
    final hasAnySystemColumns = rawResults.any(
      (row) =>
          row.containsKey('system_id') && row.containsKey('system_version'),
    );

    if (!hasAnySystemColumns) {
      return null;
    }

    final newResultSystemIds = <String>[];
    final systemIdToVersion = <String, String>{};

    for (final rawRow in rawResults) {
      final systemIdValue = rawRow['system_id'];
      final systemVersionValue = rawRow['system_version'];

      // Skip rows without system columns (will be handled without caching)
      if (systemIdValue == null || systemVersionValue == null) {
        continue;
      }

      final systemId = systemIdValue as String;
      final systemVersion = systemVersionValue as String;

      newResultSystemIds.add(systemId);
      systemIdToVersion[systemId] = systemVersion;
    }

    final emoji = getAnimalEmoji(_id);
    developer.log(
      'StreamingQuery._extractSystemData: $emoji Found ${newResultSystemIds.length} cacheable rows out of ${rawResults.length} total for id="$_id"',
      name: 'StreamingQuery',
    );

    return (newResultSystemIds, systemIdToVersion);
  }

  /// Emits results directly without caching, used as fallback when system columns are unavailable.
  Future<void> _emitDirectResults(
    List<Map<String, Object?>> rawResults,
    String reason,
  ) async {
    final emoji = getAnimalEmoji(_id);
    developer.log(
      'StreamingQuery._emitDirectResults: $emoji $reason for id="$_id", caching disabled for this query',
      name: 'StreamingQuery',
    );

    final mappedResults = rawResults.map(_mapper).toList();

    // Update state and emit (only if not disposed)
    _lastResultSystemIds = null; // Clear cached system IDs
    _resultCache.clear(); // Clear any existing cache

    // Check if query was disposed during the async operation
    if (_isDisposed) {
      return;
    }

    // Only add to subject if it's not closed
    if (!_subject.isClosed) {
      _subject.add(mappedResults);
    }
  }

  /// Builds and emits results using cache optimization.
  Future<void> _emitCachedResults(
    List<Map<String, Object?>> rawResults,
    List<String> systemIds,
    Map<String, String> systemIdToVersion,
  ) async {
    final mappedResults = <T>[];
    int cacheHits = 0;
    int cacheMisses = 0;

    for (int i = 0; i < rawResults.length; i++) {
      final rawRow = rawResults[i];
      final systemId = rawRow['system_id'];
      final systemVersion = rawRow['system_version'];

      final cachedRow = _getCachedRow(systemId, systemVersion);
      if (cachedRow != null) {
        mappedResults.add(cachedRow);
        cacheHits++;
      } else {
        final mappedRow = _mapper(rawRow);
        mappedResults.add(mappedRow);
        cacheMisses++;
        _cacheRow(systemId, systemVersion, mappedRow);
      }
    }

    // Log and store cache performance statistics
    final totalItems = cacheHits + cacheMisses;
    if (totalItems > 0) {
      final hitPercentage = (cacheHits / totalItems * 100);
      _lastCacheStats = (
        hits: cacheHits,
        misses: cacheMisses,
        hitPercentage: hitPercentage,
      );

      final emoji = getAnimalEmoji(_id);
      developer.log(
        'StreamingQuery._emitCachedResults: $emoji Cache performance for id="$_id": $cacheHits/$totalItems hits (${hitPercentage.toStringAsFixed(1)}%), $cacheMisses misses, total cache size: ${_resultCache.length}',
        name: 'StreamingQuery',
      );
    } else {
      _lastCacheStats = null;
    }

    // Clean up cache: remove entries not in current result set
    _cleanupCache(systemIds.toSet());

    // Check if query was disposed during the async operation
    if (_isDisposed) {
      return;
    }

    // Only add to subject if it's not closed
    if (!_subject.isClosed) {
      _subject.add(mappedResults);
    }
  }

  T? _getCachedRow(Object? systemId, Object? systemVersion) {
    if (systemId != null && systemVersion != null) {
      final cached = _resultCache[systemId as String];
      if (cached != null && cached.systemVersion == systemVersion as String) {
        return cached.object;
      }
    }
    return null;
  }

  void _cacheRow(Object? systemId, Object? systemVersion, T row) {
    if (systemId == null || systemVersion == null) {
      return;
    }
    final cachedResult = _CachedResult(row, systemVersion as String);
    _resultCache[systemId as String] = cachedResult;
  }

  /// Compares two system ID sequences for equality
  bool _areSystemIdSequencesEqual(List<String>? a, List<String>? b) {
    if (a == null && b == null) return true;
    if (a == null || b == null) return false;
    if (a.length != b.length) return false;

    for (int i = 0; i < a.length; i++) {
      if (a[i] != b[i]) return false;
    }

    return true;
  }

  /// Removes cached entries that are no longer in the current result set
  void _cleanupCache(Set<String> currentSystemIds) {
    // Only keep cache entries that are still relevant to prevent infinite growth
    _resultCache.removeWhere(
      (systemId, _) => !currentSystemIds.contains(systemId),
    );
  }

  /// Called when the first listener subscribes
  void _onListen() {
    final emoji = getAnimalEmoji(_id);
    developer.log(
      'StreamingQuery._onListen: $emoji First listener subscribed, activating query id="$_id"',
      name: 'StreamingQuery',
    );

    _isActive = true;
    _database.streamManager.register(this);

    // Trigger initial refresh asynchronously
    refresh().catchError((error, stackTrace) {
      if (!_isDisposed && !_subject.isClosed) {
        _subject.addError(error);
      }
    });
  }

  /// Called when the last listener unsubscribes
  void _onCancel() {
    final emoji = getAnimalEmoji(_id);
    developer.log(
      'StreamingQuery._onCancel: $emoji Last listener unsubscribed, deactivating query id="$_id"',
      name: 'StreamingQuery',
    );

    _isActive = false;
    _lastResultSystemIds = null;
    _database.streamManager.unregisterOnly(_id);
    _resultCache.clear();

    developer.log(
      'StreamingQuery._onCancel: $emoji Unregistered from QueryStreamManager, query id="$_id"',
      name: 'StreamingQuery',
    );
  }

  /// Dispose of this streaming query
  Future<void> dispose() async {
    final emoji = getAnimalEmoji(_id);
    developer.log(
      'StreamingQuery.dispose: $emoji Disposing query id="$_id"',
      name: 'StreamingQuery',
    );

    if (_isDisposed) {
      developer.log(
        'StreamingQuery.dispose: $emoji Already disposed, skipping for id="$_id"',
        name: 'StreamingQuery',
      );
      return;
    }

    _isDisposed = true;
    _isActive = false;

    // Wait for any ongoing refresh to complete
    if (_ongoingRefresh != null && !_ongoingRefresh!.isCompleted) {
      developer.log(
        'StreamingQuery.dispose: $emoji Waiting for ongoing refresh to complete for id="$_id"',
        name: 'StreamingQuery',
      );
      try {
        await _ongoingRefresh!.future.timeout(Duration(seconds: 5));
      } catch (e) {
        developer.log(
          'StreamingQuery.dispose: $emoji Timeout waiting for refresh completion for id="$_id"',
          name: 'StreamingQuery',
        );
      }
    }

    _resultCache.clear();

    if (!_subject.isClosed) {
      await _subject.close();
    }

    developer.log(
      'StreamingQuery.dispose: $emoji Successfully disposed query id="$_id"',
      name: 'StreamingQuery',
    );
  }

  @override
  String toString() {
    return 'StreamingQuery(id: $_id, dependencies: $_dependencies, active: $_isActive, cached: ${_resultCache.length})';
  }
}

<!-- END FILE: declarative_sqlite/lib/src/streaming/streaming_query.dart -->

<!-- BEGIN FILE: declarative_sqlite/lib/src/sync/dirty_row.dart -->
import 'package:declarative_sqlite/src/sync/hlc.dart';
import 'package:equatable/equatable.dart';

class DirtyRow extends Equatable {
  final String tableName;
  final String rowId;
  final Hlc hlc;

  @override
  List<Object?> get props => [tableName, rowId, hlc];

  const DirtyRow({
    required this.tableName,
    required this.rowId,
    required this.hlc,
  });
}

<!-- END FILE: declarative_sqlite/lib/src/sync/dirty_row.dart -->

<!-- BEGIN FILE: declarative_sqlite/lib/src/sync/dirty_row_store.dart -->
import 'package:declarative_sqlite/src/sync/hlc.dart';
import 'package:declarative_sqlite/src/sync/dirty_row.dart';
import 'package:sqflite_common/sqflite.dart';

/// Abstract base class for a data store that holds pending operations.
abstract class DirtyRowStore {
  /// Initializes the store with the [DatabaseExecutor].
  Future<void> init(DatabaseExecutor db);

  /// Adds an operation to the store.
  Future<void> add(String tableName, String rowId, Hlc hlc);

  /// Retrieves all pending operations from the store.
  Future<List<DirtyRow>> getAll();

  /// Removes a list of operations from the store, usually after they have been
  /// successfully synchronized.
  Future<void> remove(List<DirtyRow> operations);

  /// Clears all pending operations from the store.
  Future<void> clear();
}

<!-- END FILE: declarative_sqlite/lib/src/sync/dirty_row_store.dart -->

<!-- BEGIN FILE: declarative_sqlite/lib/src/sync/hlc.dart -->
import 'package:equatable/equatable.dart';
import 'package:uuid/uuid.dart';

/// A Hybrid Logical Clock (HLC) timestamp.
///
/// HLCs combine physical time (wall-clock) with a logical counter to create
/// a partially ordered, sortable, and conflict-free timestamp across
/// distributed nodes.
///
/// The format is: `<milliseconds>:<counter>:<nodeId>`
/// - `milliseconds`: Milliseconds since the Unix epoch, left-padded with zeros.
/// - `counter`: A logical counter, left-padded with zeros, to resolve ties
///   when events occur in the same millisecond.
/// - `nodeId`: A unique identifier for the node that generated the timestamp.
///
/// The padding ensures that HLC timestamps can be lexically sorted.
class Hlc extends Equatable implements Comparable<Hlc> {
  final int milliseconds;
  final int counter;
  final String nodeId;

  @override
  List<Object?> get props =>
      [milliseconds.hashCode, counter.hashCode, nodeId.hashCode];

  @override
  bool? get stringify => false;

  static Hlc min = const Hlc(0, 0, '0');

  const Hlc(this.milliseconds, this.counter, this.nodeId);

  /// Creates an HLC timestamp from a string representation.
  factory Hlc.parse(String encoded) {
    final parts = encoded.split(':');
    if (parts.length != 3) {
      throw FormatException('Invalid HLC string format', encoded);
    }
    return Hlc(
      int.parse(parts[0]),
      int.parse(parts[1]),
      parts[2],
    );
  }

  @override
  String toString() {
    // Pad to ensure lexical sortability.
    // Milliseconds: 15 digits (supports dates far into the future)
    // Counter: 9 digits (allows for 1,000,000,000 events per millisecond)
    // NodeId: 36 characters (standard UUID v4 format)
    return '${milliseconds.toString().padLeft(15, '0')}:'
        '${counter.toString().padLeft(9, '0')}:'
        '${nodeId.padLeft(36, '0')}';
  }

  @override
  int compareTo(Hlc other) {
    if (milliseconds != other.milliseconds) {
      return milliseconds.compareTo(other.milliseconds);
    }
    if (counter != other.counter) {
      return counter.compareTo(other.counter);
    }
    return nodeId.compareTo(other.nodeId);
  }
}

/// A clock that generates Hybrid Logical Clock timestamps.
/// 
/// This is a singleton to ensure causal ordering is preserved throughout
/// the entire application. All database instances should use the same
/// HLC clock instance.
class HlcClock {
  static HlcClock? _instance;
  
  int _lastMilliseconds;
  int _lastCounter;
  final String nodeId;

  HlcClock._internal({String? nodeId})
      : _lastMilliseconds = DateTime.now().millisecondsSinceEpoch,
        _lastCounter = 0,
        nodeId = nodeId ?? const Uuid().v4();

  /// Gets the singleton instance of the HLC clock.
  /// 
  /// If [nodeId] is provided on first access, it will be used as the node ID.
  /// Subsequent calls with different node IDs will be ignored.
  factory HlcClock({String? nodeId}) {
    return _instance ??= HlcClock._internal(nodeId: nodeId);
  }

  /// Gets the singleton instance without creating it.
  /// Throws if the instance hasn't been created yet.
  static HlcClock get instance {
    if (_instance == null) {
      throw StateError('HlcClock instance not initialized. Call HlcClock() first.');
    }
    return _instance!;
  }

  /// Resets the singleton instance. Used primarily for testing.
  static void resetInstance() {
    _instance = null;
  }

  /// Generates a new HLC timestamp.
  Hlc now() {
    final wallClock = DateTime.now().millisecondsSinceEpoch;

    if (wallClock > _lastMilliseconds) {
      _lastMilliseconds = wallClock;
      _lastCounter = 0;
    } else {
      _lastCounter++;
    }

    return Hlc(_lastMilliseconds, _lastCounter, nodeId);
  }

  /// Updates the clock based on a received HLC timestamp from another node.
  /// This is crucial for keeping clocks synchronized in a distributed system.
  void update(Hlc received) {
    final wallClock = DateTime.now().millisecondsSinceEpoch;

    if (wallClock > _lastMilliseconds && wallClock > received.milliseconds) {
      // Case 1: Local and received time are both in the past.
      // The physical clock is authoritative.
      _lastMilliseconds = wallClock;
      _lastCounter = 0;
    } else if (_lastMilliseconds == received.milliseconds) {
      // Case 2: Same millisecond, update to the higher counter.
      _lastCounter =
          (received.counter > _lastCounter ? received.counter : _lastCounter) +
              1;
    } else if (_lastMilliseconds > received.milliseconds) {
      // Case 3: Local clock is ahead. Increment counter.
      _lastCounter++;
    } else {
      // Case 4: Received clock is ahead. Adopt its time.
      _lastMilliseconds = received.milliseconds;
      _lastCounter = received.counter + 1;
    }
  }
}

<!-- END FILE: declarative_sqlite/lib/src/sync/hlc.dart -->

<!-- BEGIN FILE: declarative_sqlite/lib/src/sync/server_sync_manager.dart -->
import 'package:declarative_sqlite/src/declarative_database.dart';
import 'package:declarative_sqlite/src/sync/hlc.dart';

import 'dirty_row.dart';

/// Callback for fetching all data from the server.
/// 
/// The [tableTimestamps] map contains the latest server HLC timestamp
/// for each table that this client has received. The server should return
/// all records that have a server timestamp newer than these values.
typedef OnFetch = Future<void> Function(
    DeclarativeDatabase database, Map<String, Hlc?> tableTimestamps);

typedef OnSend = Future<bool> Function(List<DirtyRow> operations);

/// Manages server synchronization without internal timers.
/// 
/// Timer responsibility has been moved to TaskScheduler for better
/// resource management and fair scheduling.
class ServerSyncManager {
  final DeclarativeDatabase _db;
  final OnFetch onFetch;
  final OnSend onSend;
  final dynamic retryStrategy;

  bool _isSyncing = false;

  ServerSyncManager({
    required DeclarativeDatabase db,
    required this.onFetch,
    required this.onSend,
    this.retryStrategy,
  }) : _db = db;

  /// Performs a complete sync cycle.
  /// 
  /// This should be called by the TaskScheduler at regular intervals.
  Future<void> performSync() async {
    if (_isSyncing) {
      return;
    }
    _isSyncing = true;

    try {
      // 1. Send pending operations
      final pendingOperations = await _db.dirtyRowStore?.getAll();
      if (pendingOperations != null && pendingOperations.isNotEmpty) {
        final success = await onSend(pendingOperations);
        if (success) {
          await _db.dirtyRowStore?.remove(pendingOperations);
        }
      }

      // 2. Fetch new data from the server with delta timestamps
      final tableTimestamps = await _getTableTimestamps();
      await onFetch(_db, tableTimestamps);
    } catch (e) {
      // Handle errors, potentially using the retryStrategy
      rethrow;
    } finally {
      _isSyncing = false;
    }
  }

  /// Gets the latest server timestamp for each table to enable delta sync.
  Future<Map<String, Hlc?>> _getTableTimestamps() async {
    final timestamps = <String, Hlc?>{};
    
    try {
      // Get the latest server timestamp for each table
      for (final table in _db.schema.userTables) {
        final result = await _db.queryTable(
          'sync_server_timestamps',
          columns: ['server_timestamp'],
          where: 'table_name = ?',
          whereArgs: [table.name],
          limit: 1,
        );
        
        if (result.isNotEmpty) {
          final timestampStr = result.first['server_timestamp'] as String?;
          timestamps[table.name] = timestampStr != null ? Hlc.parse(timestampStr) : null;
        } else {
          timestamps[table.name] = null;
        }
      }
    } catch (e) {
      // If sync_server_timestamps table doesn't exist yet, return null timestamps
      for (final table in _db.schema.userTables) {
        timestamps[table.name] = null;
      }
    }
    
    return timestamps;
  }

  /// Updates the server timestamp for a table after successful fetch.
  /// 
  /// This should be called after processing records from the server
  /// to track the latest server timestamp received.
  Future<void> updateTableTimestamp(String tableName, Hlc serverTimestamp) async {
    await _ensureTimestampTableExists();

    await _db.rawInsert(
      'INSERT OR REPLACE INTO sync_server_timestamps (table_name, server_timestamp, updated_at) VALUES (?, ?, ?)',
      [
        tableName,
        serverTimestamp.toString(),
        DateTime.now().toIso8601String(),
      ],
    );
  }

  /// Ensures the sync_server_timestamps table exists.
  Future<void> _ensureTimestampTableExists() async {
    try {
      await _db.rawUpdate('''
        CREATE TABLE IF NOT EXISTS sync_server_timestamps (
          table_name TEXT PRIMARY KEY,
          server_timestamp TEXT NOT NULL,
          updated_at TEXT NOT NULL
        )
      ''');
    } catch (e) {
      // Table might already exist
    }
  }

  /// Manually triggers a sync cycle.
  /// 
  /// Deprecated: Use TaskScheduler.triggerTask() instead for better resource management.
  @Deprecated('Use TaskScheduler for triggering sync operations')
  Future<void> triggerSync() => performSync();
}

<!-- END FILE: declarative_sqlite/lib/src/sync/server_sync_manager.dart -->

<!-- BEGIN FILE: declarative_sqlite/lib/src/sync/sqlite_dirty_row_store.dart -->
import 'package:declarative_sqlite/src/sync/dirty_row.dart';
import 'package:declarative_sqlite/src/sync/dirty_row_store.dart';
import 'package:declarative_sqlite/src/sync/hlc.dart';
import 'package:sqflite_common/sqflite.dart';

/// An implementation of [DirtyRowStore] that uses a SQLite table.
class SqliteDirtyRowStore implements DirtyRowStore {
  late final DatabaseExecutor _db;
  final String _tableName = '__dirty_rows';

  SqliteDirtyRowStore();

  @override
  Future<void> init(DatabaseExecutor db) async {
    _db = db;
  }

  @override
  Future<void> add(String tableName, String rowId, Hlc hlc) async {
    await _db.rawInsert('''
      INSERT OR REPLACE INTO $_tableName (table_name, row_id, hlc)
      VALUES (?, ?, ?)
    ''', [tableName, rowId, hlc.toString()]);
  }

  @override
  Future<List<DirtyRow>> getAll() async {
    final results = await _db.query(
      _tableName,
      columns: ['table_name', 'row_id', 'hlc'],
    );
    return results.map((row) {
      return DirtyRow(
        tableName: row['table_name'] as String,
        rowId: row['row_id'] as String,
        hlc: Hlc.parse(row['hlc'] as String),
      );
    }).toList();
  }

  /// Removes a list of rows from the dirty rows log.
  ///
  /// This should be called after successfully syncing rows with a server.
  /// It uses a lock-free approach to only remove rows that have not been
  /// modified again since the sync started.
  @override
  Future<void> remove(List<DirtyRow> operations) async {
    for (final operation in operations) {
      await _db.delete(
        _tableName,
        where: 'table_name = ? AND row_id = ? AND hlc = ?',
        whereArgs: [
          operation.tableName,
          operation.rowId,
          operation.hlc.toString()
        ],
      );
    }
  }

  @override
  Future<void> clear() async {
    await _db.delete(_tableName);
  }
}

<!-- END FILE: declarative_sqlite/lib/src/sync/sqlite_dirty_row_store.dart -->

<!-- BEGIN FILE: declarative_sqlite/lib/src/utils/sql_escaping_utils.dart -->
String escapeSingleQuotes(String value) {
  return value.replaceAll("'", "''");
}

<!-- END FILE: declarative_sqlite/lib/src/utils/sql_escaping_utils.dart -->

<!-- BEGIN FILE: declarative_sqlite/lib/src/utils/string_utils.dart -->
bool isNullOrWhitespace(String? value) {
  if (value == null) {
    return true;
  }
  if (value.trim().isEmpty) {
    return true;
  }
  return false;
}
<!-- END FILE: declarative_sqlite/lib/src/utils/string_utils.dart -->

<!-- BEGIN FILE: declarative_sqlite/lib/src/utils/value_serializer.dart -->
import '../files/fileset_field.dart';

/// Utility class for serializing Dart values to SQLite-compatible format
class DatabaseValueSerializer {
  /// Serializes a Dart value for SQLite storage
  /// 
  /// This uses the same logic as DbRecord.setValue for consistency
  static Object? serialize(Object? value) {
    if (value == null) return null;
    
    if (value is DateTime) {
      return value.toIso8601String();
    }
    if (value is FilesetField) {
      return value.toDatabaseValue();
    }
    
    return value;
  }
}
<!-- END FILE: declarative_sqlite/lib/src/utils/value_serializer.dart -->

<!-- BEGIN FILE: declarative_sqlite/pubspec.yaml -->
name: declarative_sqlite
description: A dart package for declaratively creating SQLite tables and automatically migrating them.
version: 1.0.1
repository: https://github.com/graknol/declarative_sqlite

environment:
  sdk: ^3.9.2

dependencies:
  path: ^1.9.1
  meta: ^1.16.0
  equatable: ^2.0.7
  uuid: ^4.5.1
  sqflite_common: ^2.5.6
  path_provider: ^2.1.5
  crypto: ^3.0.6
  collection: ^1.19.1
  async: ^2.13.0
  pool: ^1.5.2
  async_locks: ^4.0.2
  rxdart: ^0.28.0

dev_dependencies:
  lints: ^6.0.0
  test: ^1.26.2
  sqflite: ^2.4.2
  sqflite_common_ffi: ^2.3.6

flutter: {}

<!-- END FILE: declarative_sqlite/pubspec.yaml -->

<!-- BEGIN FILE: declarative_sqlite/test/default_value_callback_test.dart -->
import 'package:declarative_sqlite/declarative_sqlite.dart';
import 'package:declarative_sqlite/src/schema/db_column.dart';
import 'package:test/test.dart';
import 'package:uuid/uuid.dart';

/// Test demonstrating default value callback functionality and automatic serialization
void main() {
  
  test('default value callbacks and static defaults with DateTime serialization', () {
    // This test verifies that DateTime values are automatically serialized
    // both in callbacks and static defaults
    final schemaBuilder = SchemaBuilder();
    
    schemaBuilder.table('test_serialization', (table) {
      // Auto-generate UUID for id
      table.guid('id').notNull('').defaultCallback(() => Uuid().v4());
      
      // Test DateTime callback (should be auto-serialized to string)
      table.date('callback_date').notNull('').defaultCallback(() => DateTime.now());
      
      // Test static DateTime default (should be auto-serialized to string)
      table.date('static_date').notNull('').defaultsTo(DateTime(2024, 1, 1));
      
      // Test string callback (no serialization needed)
      table.text('callback_text').defaultCallback(() => 'generated_text');
      
      // Test static string default (no serialization needed)
      table.text('static_text').defaultsTo('static_text_value');
      
      // Test integer callback (no serialization needed)
      table.integer('callback_int').defaultCallback(() => 42);
      
      // Test static integer default (no serialization needed)  
      table.integer('static_int').defaultsTo(100);
      
      table.key(['id']).primary();
    });
    
    final schema = schemaBuilder.build();
    
    // Verify the schema builds correctly (check user tables only, not system tables)
    final userTables = schema.tables.where((t) => !t.isSystem).toList();
    expect(userTables.length, 1);
    final testTable = userTables.first;
    expect(testTable.name, 'test_serialization');
    
    // Debug: Print all columns and their callback status
    print('Table columns:');
    for (final col in testTable.columns) {
      print('  ${col.name}: callback=${col.defaultValueCallback != null}, defaultValue=${col.defaultValue}');
    }
    
    // Helper function to find a column by name
    DbColumn getColumn(String name) {
      return testTable.columns.firstWhere((col) => col.name == name);
    }
    
    // Verify all columns exist
    expect(getColumn('id').name, 'id');
    expect(getColumn('callback_date').name, 'callback_date');
    expect(getColumn('static_date').name, 'static_date');
    expect(getColumn('callback_text').name, 'callback_text');
    expect(getColumn('static_text').name, 'static_text');
    expect(getColumn('callback_int').name, 'callback_int');
    expect(getColumn('static_int').name, 'static_int');
    
    // Test that date column callbacks return DateTime objects (they should be serialized during insert)
    final callbackDateCol = getColumn('callback_date');
    expect(callbackDateCol.defaultValueCallback, isNotNull);
    final dateCallback = callbackDateCol.defaultValueCallback!;
    final callbackResult = dateCallback();
    expect(callbackResult, isA<DateTime>());
    
    // Test that static date default is DateTime object (should be serialized during insert)
    final staticDateCol = getColumn('static_date');
    final staticDateDefault = staticDateCol.defaultValue;
    expect(staticDateDefault, isA<DateTime>());
    expect(staticDateDefault, equals(DateTime(2024, 1, 1)));
    
    // Test other callback types - verify they exist
    final textCallbackCol = getColumn('callback_text');
    expect(textCallbackCol.defaultValueCallback, isNotNull, reason: 'Text callback should be stored');
    final textCallback = textCallbackCol.defaultValueCallback!;
    expect(textCallback(), 'generated_text');
    
    final intCallbackCol = getColumn('callback_int');  
    expect(intCallbackCol.defaultValueCallback, isNotNull, reason: 'Int callback should be stored');
    final intCallback = intCallbackCol.defaultValueCallback!;
    expect(intCallback(), 42);
    
    // Test static defaults
    expect(getColumn('static_text').defaultValue, 'static_text_value');
    expect(getColumn('static_int').defaultValue, 100);
    
    print('‚úì Default value callback API works correctly');
    print('‚úì DateTime callbacks return DateTime objects (will be auto-serialized)');
    print('‚úì Static DateTime defaults are DateTime objects (will be auto-serialized)');
    print('‚úì Other data types work without serialization');
    print('‚úì Callback result: $callbackResult');
    print('‚úì Static date default: $staticDateDefault');
  });
}
<!-- END FILE: declarative_sqlite/test/default_value_callback_test.dart -->

<!-- BEGIN FILE: declarative_sqlite/test/dependency_analyzer_test.dart -->
import 'package:declarative_sqlite/declarative_sqlite.dart';
import 'package:test/test.dart';

/// Mock schema provider for testing
class MockSchemaProvider implements SchemaProvider {
  final Map<String, Set<String>> _tableColumns = {
    'users': {'id', 'name', 'username', 'department', 'active'},
    'posts': {'id', 'title', 'author_id', 'category_id', 'published_date', 'created_at', 'status'},
    'comments': {'id', 'content', 'post_id', 'user_id'},
    'categories': {'id', 'name'},
    'subscriptions': {'id', 'user_id', 'active', 'created_at'},
    'table_a': {'id', 'value'},
    'table_b': {'id', 'data'},
    'table_c': {'id', 'info', 'ref_id'},
    // Views can now be included since View class has structured column information
    'user_posts_view': {'user_id', 'username', 'post_title', 'post_count'},
    'active_subscriptions_view': {'user_id', 'user_name', 'subscription_date'},
  };

  @override
  bool tableHasColumn(String tableName, String columnName) {
    return _tableColumns[tableName]?.contains(columnName) ?? false;
  }

  @override
  List<String> getTablesWithColumn(String columnName) {
    return _tableColumns.entries
        .where((entry) => entry.value.contains(columnName))
        .map((entry) => entry.key)
        .toList();
  }
}

void main() {
  group('QueryDependencyAnalyzer Tests', () {
    late QueryDependencyAnalyzer analyzer;
    late MockSchemaProvider schema;

    setUp(() {
      schema = MockSchemaProvider();
      analyzer = QueryDependencyAnalyzer(schema);
    });

    test('should analyze simple query with basic JOIN', () {
      // Build a query: SELECT u.name, p.title FROM users u INNER JOIN posts p ON u.id = p.user_id WHERE u.active = ?
      final query = QueryBuilder()
          .select('u.name')
          .select('p.title')
          .from('users', 'u')
          .innerJoin('posts', col('u.id').eq(col('p.user_id')), 'p')
          .where(col('u.active').eq(true));

      final dependencies = analyzer.analyzeQuery(query);

      // Should have both tables
      expect(dependencies.tables, containsAll(['users AS u', 'posts AS p']));

      // Should have specific columns
      expect(dependencies.columns, hasLength(greaterThanOrEqualTo(4)));
      expect(
          dependencies.columns
              .any((c) => c.table == 'users' && c.column == 'name'),
          isTrue);
      expect(
          dependencies.columns
              .any((c) => c.table == 'posts' && c.column == 'title'),
          isTrue);
      expect(
          dependencies.columns
              .any((c) => c.table == 'users' && c.column == 'id'),
          isTrue);
      expect(
          dependencies.columns
              .any((c) => c.table == 'posts' && c.column == 'user_id'),
          isTrue);
      expect(
          dependencies.columns
              .any((c) => c.table == 'users' && c.column == 'active'),
          isTrue);

      expect(dependencies.usesWildcard, isFalse);
    });

    test('should analyze complex query with multiple JOINs and subquery', () {
      // Build a complex query with multiple joins and a subquery
      // SELECT u.username, p.title, c.content, cat.name as category_name
      // FROM users u
      // INNER JOIN posts p ON u.id = p.author_id
      // LEFT JOIN comments c ON p.id = c.post_id
      // INNER JOIN categories cat ON p.category_id = cat.id
      // WHERE u.id IN (SELECT user_id FROM subscriptions WHERE active = ?)
      // AND p.published_date > ?
      // ORDER BY p.created_at DESC

      final subQuery = QueryBuilder()
          .select('user_id')
          .from('subscriptions')
          .where(col('active').eq(true));

      final mainQuery = QueryBuilder()
          .select('u.username')
          .select('p.title')
          .select('c.content')
          .select('cat.name', 'category_name')
          .from('users', 'u')
          .innerJoin('posts', col('u.id').eq(col('p.author_id')), 'p')
          .leftJoin('comments', col('p.id').eq(col('c.post_id')), 'c')
          .innerJoin(
              'categories', col('p.category_id').eq(col('cat.id')), 'cat')
          .where(and([
            col('u.id').inSubQuery(subQuery),
            col('p.published_date').gt(DateTime.now())
          ]))
          .orderBy(['p.created_at DESC']);

      final dependencies = analyzer.analyzeQuery(mainQuery);

      // Should have all main tables
      expect(
          dependencies.tables,
          containsAll([
            'users AS u',
            'posts AS p',
            'comments AS c',
            'categories AS cat',
            'subscriptions' // From subquery
          ]));

      // Should have all referenced columns
      final expectedColumns = [
        // SELECT columns
        QueryDependencyColumn('users', 'username'),
        QueryDependencyColumn('posts', 'title'),
        QueryDependencyColumn('comments', 'content'),
        QueryDependencyColumn('categories', 'name'),

        // JOIN conditions
        QueryDependencyColumn('users', 'id'),
        QueryDependencyColumn('posts', 'author_id'),
        QueryDependencyColumn('posts', 'id'),
        QueryDependencyColumn('comments', 'post_id'),
        QueryDependencyColumn('posts', 'category_id'),
        QueryDependencyColumn('categories', 'id'),

        // WHERE conditions
        QueryDependencyColumn('posts', 'published_date'),

        // Subquery columns
        QueryDependencyColumn('subscriptions', 'user_id'),
        QueryDependencyColumn('subscriptions', 'active'),

        // ORDER BY columns
        QueryDependencyColumn('posts', 'created_at'),
      ];

      for (final expectedCol in expectedColumns) {
        expect(
            dependencies.columns.any((c) =>
                c.table == expectedCol.table && c.column == expectedCol.column),
            isTrue,
            reason:
                'Expected column ${expectedCol.table}.${expectedCol.column} not found');
      }

      expect(dependencies.usesWildcard, isFalse);
    });

    test('should analyze query with wildcard and table aliases', () {
      // SELECT u.*, p.title FROM users u LEFT JOIN posts p ON u.id = p.user_id
      final query = QueryBuilder()
          .select('u.*')
          .select('p.title')
          .from('users', 'u')
          .leftJoin('posts', col('u.id').eq(col('p.user_id')), 'p');

      final dependencies = analyzer.analyzeQuery(query);

      expect(dependencies.tables, containsAll(['users AS u', 'posts AS p']));
      expect(dependencies.usesWildcard, isTrue);

      // Should still track specific columns from JOIN and non-wildcard SELECT
      expect(
          dependencies.columns
              .any((c) => c.table == 'posts' && c.column == 'title'),
          isTrue);
      expect(
          dependencies.columns
              .any((c) => c.table == 'users' && c.column == 'id'),
          isTrue);
      expect(
          dependencies.columns
              .any((c) => c.table == 'posts' && c.column == 'user_id'),
          isTrue);
    });

    test('should analyze nested subqueries with different alias scopes', () {
      // Test that alias resolution works correctly in nested contexts
      // SELECT u.name FROM users u WHERE u.id IN (
      //   SELECT p.author_id FROM posts p WHERE p.category_id IN (
      //     SELECT c.id FROM categories c WHERE c.name = ?
      //   )
      // )

      final innerSubquery = QueryBuilder()
          .select('c.id')
          .from('categories', 'c')
          .where(col('c.name').eq('technology'));

      final middleSubquery = QueryBuilder()
          .select('p.author_id')
          .from('posts', 'p')
          .where(col('p.category_id').inSubQuery(innerSubquery));

      final mainQuery = QueryBuilder()
          .select('u.name')
          .from('users', 'u')
          .where(col('u.id').inSubQuery(middleSubquery));

      final dependencies = analyzer.analyzeQuery(mainQuery);

      expect(dependencies.tables,
          containsAll(['users AS u', 'posts AS p', 'categories AS c']));

      // Verify all columns are properly resolved despite alias reuse
      expect(
          dependencies.columns
              .any((c) => c.table == 'users' && c.column == 'name'),
          isTrue);
      expect(
          dependencies.columns
              .any((c) => c.table == 'users' && c.column == 'id'),
          isTrue);
      expect(
          dependencies.columns
              .any((c) => c.table == 'posts' && c.column == 'author_id'),
          isTrue);
      expect(
          dependencies.columns
              .any((c) => c.table == 'posts' && c.column == 'category_id'),
          isTrue);
      expect(
          dependencies.columns
              .any((c) => c.table == 'categories' && c.column == 'id'),
          isTrue);
      expect(
          dependencies.columns
              .any((c) => c.table == 'categories' && c.column == 'name'),
          isTrue);
    });

    test('should handle CROSS JOIN and FULL OUTER JOIN', () {
      // Test different join types
      final query = QueryBuilder()
          .select('a.value')
          .select('b.data')
          .select('c.info')
          .from('table_a', 'a')
          .crossJoin('table_b', 'b')
          .fullOuterJoin('table_c', col('a.id').eq(col('c.ref_id')), 'c');

      final dependencies = analyzer.analyzeQuery(query);

      expect(dependencies.tables,
          containsAll(['table_a AS a', 'table_b AS b', 'table_c AS c']));
      expect(
          dependencies.columns
              .any((c) => c.table == 'table_a' && c.column == 'value'),
          isTrue);
      expect(
          dependencies.columns
              .any((c) => c.table == 'table_b' && c.column == 'data'),
          isTrue);
      expect(
          dependencies.columns
              .any((c) => c.table == 'table_c' && c.column == 'info'),
          isTrue);
      expect(
          dependencies.columns
              .any((c) => c.table == 'table_a' && c.column == 'id'),
          isTrue);
      expect(
          dependencies.columns
              .any((c) => c.table == 'table_c' && c.column == 'ref_id'),
          isTrue);
    });

    test('should analyze query with GROUP BY and HAVING clauses', () {
      // SELECT u.department, COUNT(*) as user_count
      // FROM users u
      // INNER JOIN posts p ON u.id = p.author_id
      // WHERE p.status = ?
      // GROUP BY u.department
      // HAVING COUNT(*) > ?
      // ORDER BY user_count DESC

      final query = QueryBuilder()
          .select('u.department')
          .select('COUNT(*)', 'user_count')
          .from('users', 'u')
          .innerJoin('posts', col('u.id').eq(col('p.author_id')), 'p')
          .where(col('p.status').eq(col('published')))
          .groupBy(['u.department'])
          .having('COUNT(*) > ?')
          .orderBy(['user_count DESC']);

      final dependencies = analyzer.analyzeQuery(query);

      expect(dependencies.tables, containsAll(['users AS u', 'posts AS p']));

      // Should include columns from all clauses
      expect(
          dependencies.columns
              .any((c) => c.table == 'users' && c.column == 'department'),
          isTrue);
      expect(
          dependencies.columns
              .any((c) => c.table == 'users' && c.column == 'id'),
          isTrue);
      expect(
          dependencies.columns
              .any((c) => c.table == 'posts' && c.column == 'author_id'),
          isTrue);
      expect(
          dependencies.columns
              .any((c) => c.table == 'posts' && c.column == 'status'),
          isTrue);
    });
  });

  group('AnalysisContext Tests', () {
    test('should resolve aliases correctly with nested scopes', () {
      final context = AnalysisContext();

      // Main query scope
      context.addTable('users', alias: 'u');
      context.addTable('posts', alias: 'p');

      expect(context.resolveTable('u'), equals('users'));
      expect(context.resolveTable('p'), equals('posts'));
      expect(context.resolveTable('users'), equals('users'));

      // Enter subquery scope
      context.pushLevel();
      context.addTable('categories', alias: 'u'); // Shadow 'u' alias

      expect(context.resolveTable('u'), equals('categories')); // Closest wins
      expect(context.resolveTable('p'), equals('posts')); // Still accessible

      // Exit subquery scope
      context.popLevel();

      expect(context.resolveTable('u'), equals('users')); // Back to original
      expect(context.resolveTable('p'), equals('posts'));
    });

    test('should resolve unqualified columns using schema information', () {
      final schema = MockSchemaProvider();
      final context = AnalysisContext(schema);

      // Set up context with multiple tables
      context.addTable('users', alias: 'u');
      context.addTable('posts', alias: 'p');

      // Test column resolution - 'name' exists in both users and categories,
      // but only users is in context, so it should resolve to users
      expect(context.resolveUnqualifiedColumn('name'), equals('users'));
      
      // Test column that only exists in posts
      expect(context.resolveUnqualifiedColumn('title'), equals('posts'));
      
      // Test column that doesn't exist in any table in context
      expect(context.resolveUnqualifiedColumn('nonexistent'), isNull);

      // Add categories to context and test precedence
      context.addTable('categories', alias: 'cat');
      // 'name' exists in both users and categories, but categories was added last
      // so it should be found first in the available tables list
      expect(context.resolveUnqualifiedColumn('name'), equals('categories'));
    });

    test('should fall back to heuristics when no schema is provided', () {
      final context = AnalysisContext(); // No schema

      context.addTable('users', alias: 'u');
      context.addTable('posts', alias: 'p');

      // Without schema, should fall back to first table in current level
      expect(context.resolveUnqualifiedColumn('any_column'), equals('users'));
    });

    test('should resolve columns in views using structured view information', () {
      final schema = MockSchemaProvider();
      final context = AnalysisContext(schema);

      // Set up context with a view and tables
      context.addTable('user_posts_view', alias: 'upv');
      context.addTable('users', alias: 'u');

      // Test column that exists in the view
      expect(context.resolveUnqualifiedColumn('post_count'), equals('user_posts_view'));
      
      // Test column that exists in both view and table - view should win (added first)
      expect(context.resolveUnqualifiedColumn('user_id'), equals('user_posts_view'));
      
      // Test column that only exists in regular table
      expect(context.resolveUnqualifiedColumn('department'), equals('users'));
    });
  });
}

<!-- END FILE: declarative_sqlite/test/dependency_analyzer_test.dart -->

<!-- BEGIN FILE: declarative_sqlite_flutter/lib/declarative_sqlite_flutter.dart -->
library declarative_sqlite_flutter;

export 'src/database_provider.dart';
export 'src/server_sync_manager.dart';
export 'src/query_list_view.dart';

<!-- END FILE: declarative_sqlite_flutter/lib/declarative_sqlite_flutter.dart -->

<!-- BEGIN FILE: declarative_sqlite_flutter/lib/src/database_provider.dart -->
import 'dart:io';

import 'package:declarative_sqlite/declarative_sqlite.dart';
import 'package:flutter/widgets.dart';
import 'package:sqflite/sqflite.dart';
import 'package:path_provider/path_provider.dart';
import 'package:path/path.dart' as path;

/// An inherited widget that provides access to a [DeclarativeDatabase] instance
/// throughout the widget tree.
class _DatabaseInheritedWidget extends InheritedWidget {
  final DeclarativeDatabase database;

  const _DatabaseInheritedWidget({
    required this.database,
    required super.child,
  });

  @override
  bool updateShouldNotify(_DatabaseInheritedWidget oldWidget) {
    return database != oldWidget.database;
  }

  static DeclarativeDatabase? maybeOf(BuildContext context) {
    final widget =
        context.dependOnInheritedWidgetOfExactType<_DatabaseInheritedWidget>();
    return widget?.database;
  }

  static DeclarativeDatabase of(BuildContext context) {
    final database = maybeOf(context);
    if (database == null) {
      throw FlutterError(
        'DatabaseProvider.of() called with a context that does not contain a DatabaseProvider.\n'
        'No DatabaseProvider ancestor could be found starting from the context that was passed '
        'to DatabaseProvider.of(). This usually happens when the context provided is from a widget '
        'that is not a descendant of a DatabaseProvider widget.\n'
        'The context used was:\n'
        '  $context',
      );
    }
    return database;
  }
}

/// A widget that initializes and provides a [DeclarativeDatabase] to its descendants.
///
/// This widget manages the lifecycle of the database connection and provides it
/// through an [InheritedWidget] for efficient access throughout the widget tree.
///
/// Example:
/// ```dart
/// DatabaseProvider(
///   schema: (builder) {
///     builder.table('users', (table) {
///       table.guid('id').notNull();
///       table.text('name').notNull();
///     });
///   },
///   databaseName: 'my_app.db',
///   child: MyApp(),
/// )
/// ```
class DatabaseProvider extends StatefulWidget {
  final void Function(SchemaBuilder builder) schema;
  final String databaseName;
  final Widget child;
  final String? databasePath;
  final bool recreateDatabase;

  const DatabaseProvider({
    super.key,
    required this.schema,
    required this.databaseName,
    required this.child,
    this.databasePath,
    this.recreateDatabase = false,
  });

  /// Access the database from anywhere in the widget tree.
  static DeclarativeDatabase of(BuildContext context) {
    return _DatabaseInheritedWidget.of(context);
  }

  /// Access the database from anywhere in the widget tree, returning null if not found.
  static DeclarativeDatabase? maybeOf(BuildContext context) {
    return _DatabaseInheritedWidget.maybeOf(context);
  }

  @override
  State<DatabaseProvider> createState() => _DatabaseProviderState();
}

class _DatabaseProviderState extends State<DatabaseProvider> {
  DeclarativeDatabase? _database;
  bool _isInitializing = true;
  Object? _initializationError;

  @override
  void initState() {
    super.initState();
    _initializeDatabase();
  }

  @override
  void didUpdateWidget(DatabaseProvider oldWidget) {
    super.didUpdateWidget(oldWidget);

    // If schema or database name changed, reinitialize
    if (widget.databaseName != oldWidget.databaseName ||
        widget.databasePath != oldWidget.databasePath) {
      _disposeDatabase();
      _initializeDatabase();
    }
  }

  @override
  void dispose() {
    _disposeDatabase();
    super.dispose();
  }

  void _disposeDatabase() {
    _database?.close();
    _database = null;
  }

  Future<void> _initializeDatabase() async {
    _setInitializationState(isInitializing: true, error: null);

    try {
      final schema = _buildDatabaseSchema();
      final database = await _createDatabaseInstance(schema);
      _setInitializationState(isInitializing: false, database: database);
    } catch (error) {
      _setInitializationState(isInitializing: false, error: error);
    }
  }

  Schema _buildDatabaseSchema() {
    final schemaBuilder = SchemaBuilder();
    widget.schema(schemaBuilder);
    return schemaBuilder.build();
  }

  Future<DeclarativeDatabase> _createDatabaseInstance(Schema schema) async {
    final fileRepositoryPath = await _getFileRepositoryPath();
    return await DeclarativeDatabase.open(
      widget.databasePath ?? widget.databaseName,
      databaseFactory: databaseFactory,
      schema: schema,
      fileRepository: FilesystemFileRepository(fileRepositoryPath),
      recreateDatabase: widget.recreateDatabase,
    );
  }

  Future<String> _getFileRepositoryPath() async {
    final rootDirectory = Platform.isMacOS || Platform.isIOS
        ? await getLibraryDirectory()
        : await getApplicationSupportDirectory();
    return path.join(rootDirectory.path, 'file_repository');
  }

  void _setInitializationState({
    required bool isInitializing,
    Object? error,
    DeclarativeDatabase? database,
  }) {
    if (mounted) {
      setState(() {
        _isInitializing = isInitializing;
        _initializationError = error;
        if (database != null) {
          _database = database;
        }
      });
    }
  }

  @override
  Widget build(BuildContext context) {
    // Show error if database initialization failed
    if (_initializationError != null) {
      return ErrorWidget(_initializationError!);
    }

    // Show loading while initializing
    if (_isInitializing || _database == null) {
      return const SizedBox.shrink();
    }

    // Provide database to descendants
    return _DatabaseInheritedWidget(
      database: _database!,
      child: widget.child,
    );
  }
}

<!-- END FILE: declarative_sqlite_flutter/lib/src/database_provider.dart -->

<!-- BEGIN FILE: declarative_sqlite_flutter/lib/src/query_list_view.dart -->
import 'dart:developer' as developer;

import 'package:declarative_sqlite/declarative_sqlite.dart';
import 'package:declarative_sqlite/src/streaming/query_emoji_utils.dart';
import 'package:flutter/gestures.dart';
import 'package:flutter/material.dart';

import 'database_provider.dart';

class QueryListView<T extends DbRecord> extends StatefulWidget {
  final DeclarativeDatabase? database;
  final void Function(QueryBuilder query) query;
  final T Function(Map<String, Object?>, DeclarativeDatabase)? mapper;
  final Widget Function(BuildContext context) loadingBuilder;
  final Widget Function(BuildContext context, Object error) errorBuilder;
  final Widget Function(BuildContext context, T record) itemBuilder;
  
  // ListView properties for Flutter SDK compatibility
  final Axis scrollDirection;
  final bool reverse;
  final ScrollController? controller;
  final bool? primary;
  final ScrollPhysics? physics;
  final bool shrinkWrap;
  final EdgeInsetsGeometry? padding;
  final double? itemExtent;
  final Widget? prototypeItem;
  final bool addAutomaticKeepAlives;
  final bool addRepaintBoundaries;
  final bool addSemanticIndexes;
  final double? cacheExtent;
  final int? semanticChildCount;
  final DragStartBehavior dragStartBehavior;
  final ScrollViewKeyboardDismissBehavior keyboardDismissBehavior;
  final String? restorationId;
  final Clip clipBehavior;

  const QueryListView({
    super.key,
    this.database,
    required this.query,
    this.mapper,
    required this.loadingBuilder,
    required this.errorBuilder,
    required this.itemBuilder,
    // ListView properties with Flutter SDK defaults
    this.scrollDirection = Axis.vertical,
    this.reverse = false,
    this.controller,
    this.primary,
    this.physics,
    this.shrinkWrap = false,
    this.padding,
    this.itemExtent,
    this.prototypeItem,
    this.addAutomaticKeepAlives = true,
    this.addRepaintBoundaries = true,
    this.addSemanticIndexes = true,
    this.cacheExtent,
    this.semanticChildCount,
    this.dragStartBehavior = DragStartBehavior.start,
    this.keyboardDismissBehavior = ScrollViewKeyboardDismissBehavior.manual,
    this.restorationId,
    this.clipBehavior = Clip.hardEdge,
  });

  @override
  State<QueryListView<T>> createState() => _QueryListViewState<T>();
}

class _QueryListViewState<T extends DbRecord> extends State<QueryListView<T>> {
  StreamingQuery<T>? _streamingQuery;
  DeclarativeDatabase? _currentDatabase;
  String? _lastQuerySignature; // Track query changes more efficiently

  @override
  void initState() {
    super.initState();
    // Initialize streaming query in initState
    WidgetsBinding.instance.addPostFrameCallback((_) {
      _initializeStreamingQuery();
    });
  }

  @override
  void didChangeDependencies() {
    super.didChangeDependencies();
    // Check if database changed due to InheritedWidget changes
    _handleDatabaseChanges();
  }

  @override
  void didUpdateWidget(QueryListView<T> oldWidget) {
    super.didUpdateWidget(oldWidget);
    // Handle widget property changes
    _handleWidgetChanges(oldWidget);
  }

  @override
  Widget build(BuildContext context) {
    // Get database from widget parameter or DatabaseProvider
    final database = _getDatabase(context);
    
    // If no database is available, show loading state
    if (database == null) {
      return widget.loadingBuilder(context);
    }

    // If no streaming query is ready, show loading state
    if (_streamingQuery == null) {
      return widget.loadingBuilder(context);
    }
    
    // Use StreamBuilder to handle all stream lifecycle management
    return StreamBuilder<List<T>>(
      stream: _streamingQuery!.stream,
      builder: (context, snapshot) {
        // Handle error state
        if (snapshot.hasError) {
          return widget.errorBuilder(context, snapshot.error!);
        }

        // Handle loading state (waiting for first data or no data yet)
        if (!snapshot.hasData) {
          return widget.loadingBuilder(context);
        }

        // Build the list with current data
        return _buildListView(snapshot.data!);
      },
    );
  }

  /// Gets the database from widget parameter or DatabaseProvider context
  DeclarativeDatabase? _getDatabase(BuildContext context) {
    // First try the explicitly provided database
    if (widget.database != null) {
      return widget.database;
    }
    
    // Fall back to DatabaseProvider context
    return DatabaseProvider.maybeOf(context);
  }

  void _initializeStreamingQuery() {
    final database = _getDatabase(context);
    if (database != null) {
      _currentDatabase = database;
      _createStreamingQuery(database).then((_) {
        // Trigger rebuild now that streaming query is ready
        if (mounted) setState(() {});
      });
    }
  }

  void _handleDatabaseChanges() {
    final newDatabase = _getDatabase(context);
    if (newDatabase != _currentDatabase) {
      _currentDatabase = newDatabase;
      if (newDatabase != null) {
        _createStreamingQuery(newDatabase).then((_) {
          // Trigger rebuild now that streaming query is ready
          if (mounted) setState(() {});
        });
      } else {
        _disposeStreamingQuery().then((_) {
          // Trigger rebuild to show loading state
          if (mounted) setState(() {});
        });
      }
    }
  }

  void _handleWidgetChanges(QueryListView<T> oldWidget) {
    final database = _currentDatabase;
    if (database == null) return;
    
    // Generate signature for current query to detect meaningful changes
    final currentSignature = _generateQuerySignature();
    
    // Only recreate the streaming query if there's a meaningful change
    if (_lastQuerySignature != currentSignature || widget.mapper != oldWidget.mapper) {
      developer.log('QueryListView: Query changed, recreating stream', name: 'QueryListView');
      _createStreamingQuery(database).then((_) {
        _lastQuerySignature = currentSignature;
        // Trigger rebuild now that streaming query has been recreated
        if (mounted) setState(() {});
      });
    }
  }
  
  /// Generate a signature for the current query to detect meaningful changes
  String _generateQuerySignature() {
    final builder = QueryBuilder();
    widget.query(builder);
    
    // Build the SQL to use as signature (this captures all meaningful changes)
    try {
      final (sql, params) = builder.build();
      return '$sql|${params.join(',')}';
    } catch (e) {
      // If build fails, fall back to table name + hash of widget.query function
      return '${builder.tableName}_${widget.query.hashCode}';
    }
  }

  Future<void> _disposeStreamingQuery() async {
    if (_streamingQuery != null) {
      final emoji = getAnimalEmoji(_streamingQuery!.id);
      try {
        // Wait for disposal to complete to avoid race conditions
        await _streamingQuery!.dispose();
        developer.log('QueryListView: $emoji Successfully disposed streaming query', name: 'QueryListView');
      } catch (error) {
        developer.log('QueryListView: $emoji Error during dispose: $error', name: 'QueryListView');
      }
      _streamingQuery = null;
    }
  }

  Future<void> _createStreamingQuery(DeclarativeDatabase database) async {
    // Dispose of existing query if any and wait for completion
    await _disposeStreamingQuery();

    // Build the query
    final builder = QueryBuilder();
    widget.query(builder);

    // Create the effective mapper
    final T Function(Map<String, Object?>) effectiveMapper = _createEffectiveMapper(database);
    
    final queryId = 'query_list_view_${DateTime.now().millisecondsSinceEpoch}';
    final emoji = getAnimalEmoji(queryId);
    developer.log('QueryListView: $emoji Creating new streaming query with id="$queryId"', name: 'QueryListView');
    
    // Create new streaming query with RxDart-enhanced lifecycle management
    _streamingQuery = StreamingQuery.create(
      id: queryId,
      builder: builder,
      database: database,
      mapper: effectiveMapper,
    );
  }

  T Function(Map<String, Object?>) _createEffectiveMapper(DeclarativeDatabase database) {
    if (widget.mapper != null) {
      return (data) => widget.mapper!(data, database);
    } else {
      // Try to get mapper from registry
      if (!RecordMapFactoryRegistry.hasFactory<T>()) {
        throw ArgumentError(
          'No mapper provided and no factory registered for type $T. '
          'Either provide a mapper parameter or register a factory using '
          'RecordMapFactoryRegistry.register<$T>(factory).'
        );
      }
      return (data) => RecordMapFactoryRegistry.create<T>(data, database);
    }
  }

  @override
  void dispose() {
    // StreamBuilder handles stream subscription lifecycle automatically
    // We only need to dispose of our StreamingQuery
    // Note: We don't await this since dispose() must be synchronous
    _disposeStreamingQuery().catchError((error) {
      developer.log('QueryListView: Error during widget dispose: $error', name: 'QueryListView');
    });
    super.dispose();
  }

  Widget _buildListView(List<T> items) {
    return ListView.builder(
      // Core ListView.builder properties
      itemCount: items.length,
      itemBuilder: (context, index) => widget.itemBuilder(context, items[index]),
      
      // Pass through all ListView properties to maintain Flutter SDK compatibility
      scrollDirection: widget.scrollDirection,
      reverse: widget.reverse,
      controller: widget.controller,
      primary: widget.primary,
      physics: widget.physics,
      shrinkWrap: widget.shrinkWrap,
      padding: widget.padding,
      itemExtent: widget.itemExtent,
      prototypeItem: widget.prototypeItem,
      addAutomaticKeepAlives: widget.addAutomaticKeepAlives,
      addRepaintBoundaries: widget.addRepaintBoundaries,
      addSemanticIndexes: widget.addSemanticIndexes,
      cacheExtent: widget.cacheExtent,
      semanticChildCount: widget.semanticChildCount,
      dragStartBehavior: widget.dragStartBehavior,
      keyboardDismissBehavior: widget.keyboardDismissBehavior,
      restorationId: widget.restorationId,
      clipBehavior: widget.clipBehavior,
    );
  }
}

<!-- END FILE: declarative_sqlite_flutter/lib/src/query_list_view.dart -->

<!-- BEGIN FILE: declarative_sqlite_flutter/lib/src/server_sync_manager.dart -->
import 'package:declarative_sqlite/declarative_sqlite.dart';
import 'package:flutter/widgets.dart';
import 'database_provider.dart';

/// A widget that manages server synchronization using TaskScheduler.
/// 
/// This widget registers sync operations with the TaskScheduler for better
/// resource management and fair scheduling with other background tasks.
/// 
/// Example:
/// ```dart
/// ServerSyncManagerWidget(
///   retryStrategy: ExponentialBackoffRetry(),
///   syncInterval: Duration(minutes: 5),
///   onFetch: (database, tableTimestamps) async {
///     // Fetch data from server using delta timestamps
///   },
///   onSend: (operations) async {
///     // Send changes to server
///     return true; // Success
///   },
///   child: MyApp(),
/// )
/// ```
class ServerSyncManagerWidget extends StatefulWidget {
  final dynamic retryStrategy;
  final Duration syncInterval;
  final OnFetch onFetch;
  final OnSend onSend;
  final Widget child;
  final DeclarativeDatabase? database;
  final TaskScheduler? taskScheduler;

  const ServerSyncManagerWidget({
    super.key,
    required this.retryStrategy,
    this.syncInterval = const Duration(minutes: 5),
    required this.onFetch,
    required this.onSend,
    required this.child,
    this.database,
    this.taskScheduler,
  });

  @override
  State<ServerSyncManagerWidget> createState() => _ServerSyncManagerWidgetState();
}

class _ServerSyncManagerWidgetState extends State<ServerSyncManagerWidget> {
  ServerSyncManager? _syncManager;
  TaskScheduler? _scheduler;
  String? _syncTaskName;

  @override
  void initState() {
    super.initState();
    WidgetsBinding.instance.addPostFrameCallback((_) {
      _initializeSyncManager();
    });
  }

  @override
  void didUpdateWidget(ServerSyncManagerWidget oldWidget) {
    super.didUpdateWidget(oldWidget);
    
    // If configuration changed, restart sync manager
    if (_shouldRestartSyncManager(oldWidget)) {
      _disposeSyncManager();
      _initializeSyncManager();
    }
  }

  bool _shouldRestartSyncManager(ServerSyncManagerWidget oldWidget) {
    return widget.syncInterval != oldWidget.syncInterval ||
        widget.onFetch != oldWidget.onFetch ||
        widget.onSend != oldWidget.onSend ||
        widget.database != oldWidget.database ||
        widget.taskScheduler != oldWidget.taskScheduler;
  }

  @override
  void dispose() {
    _disposeSyncManager();
    super.dispose();
  }

  void _initializeSyncManager() {
    final database = _getDatabaseInstance();
    
    if (database == null) {
      // No database available, can't initialize sync
      return;
    }

    try {
      _createSyncManagerAndScheduleTask(database);
    } catch (error) {
      _handleSyncManagerError(error);
    }
  }

  DeclarativeDatabase? _getDatabaseInstance() {
    return widget.database ?? DatabaseProvider.maybeOf(context);
  }

  void _createSyncManagerAndScheduleTask(DeclarativeDatabase database) {
    // Create sync manager without internal timer
    _syncManager = ServerSyncManager(
      db: database,
      retryStrategy: widget.retryStrategy,
      onFetch: widget.onFetch,
      onSend: widget.onSend,
    );

    // Get or create task scheduler
    _scheduler = widget.taskScheduler ?? TaskScheduler.withConfig(
      TaskSchedulerConfig.resourceConstrained
    );

    // Initialize scheduler with database for persistent tracking
    _scheduler!.initializeWithDatabase(database);

    // Schedule recurring sync task
    _syncTaskName = 'server_sync_${database.hashCode}';
    _scheduler!.scheduleRecurringTask(
      name: _syncTaskName!,
      task: () => _syncManager!.performSync(),
      interval: widget.syncInterval,
      priority: TaskPriority.normal,
    );

    // Perform initial sync
    _syncManager!.performSync();
  }

  void _handleSyncManagerError(Object error) {
    debugPrint('Failed to initialize ServerSyncManager: $error');
  }

  void _disposeSyncManager() {
    if (_syncTaskName != null && _scheduler != null) {
      _scheduler!.cancelTask(_syncTaskName!);
    }
    _syncManager = null;
    _scheduler = null;
    _syncTaskName = null;
  }

  @override
  Widget build(BuildContext context) {
    return widget.child;
  }
}

<!-- END FILE: declarative_sqlite_flutter/lib/src/server_sync_manager.dart -->

<!-- BEGIN FILE: declarative_sqlite_flutter/pubspec.yaml -->
name: declarative_sqlite_flutter
description: A Flutter package that provides seamless integration of declarative_sqlite with Flutter widgets, forms, and UI patterns.
version: 1.0.0
publish_to: none
repository: https://github.com/graknol/declarative_sqlite

environment:
  sdk: ^3.9.2
  flutter: ">=3.0.0"

dependencies:
  flutter:
    sdk: flutter
  declarative_sqlite:
    path: ../declarative_sqlite
  sqflite_common: ^2.5.6
  equatable: ^2.0.7

dev_dependencies:
  flutter_test:
    sdk: flutter
  flutter_lints: ^6.0.0
  # Testing dependencies
  test: ^1.26.2
  mockito: ^5.5.0
  build_runner: ^2.7.1
  sqflite: ^2.4.2
  sqflite_common_ffi: ^2.3.6

flutter:
  {}
  # This package is a Flutter library

<!-- END FILE: declarative_sqlite_flutter/pubspec.yaml -->

<!-- BEGIN FILE: declarative_sqlite_generator/build.yaml -->
builders:
  declarative_sqlite_generator:
    import: "package:declarative_sqlite_generator/src/builder.dart"
    builder_factories: ["declarativeSqliteGenerator"]
    build_extensions: { ".dart": [".db.dart"] }
    auto_apply: dependents
    build_to: source

  registration_scanner:
    import: "package:declarative_sqlite_generator/src/builder.dart"
    builder_factories: ["registrationScanner"]
    build_extensions: { ".dart": [".dbrecord_meta"] }
    auto_apply: dependents
    build_to: cache

  registration_aggregator:
    import: "package:declarative_sqlite_generator/src/builder.dart"
    builder_factories: ["registrationAggregator"]
    build_extensions: { "$lib$": ["sqlite_factory_registration.dart"] }
    auto_apply: dependents
    build_to: source
    required_inputs: [".dbrecord_meta"]

<!-- END FILE: declarative_sqlite_generator/build.yaml -->

<!-- BEGIN FILE: declarative_sqlite_generator/lib/declarative_sqlite_generator.dart -->
library declarative_sqlite_generator;

export 'src/builder.dart';

<!-- END FILE: declarative_sqlite_generator/lib/declarative_sqlite_generator.dart -->

<!-- BEGIN FILE: declarative_sqlite_generator/lib/src/builder.dart -->
import 'package:analyzer/dart/element/element.dart';
import 'package:build/build.dart';
import 'package:declarative_sqlite/declarative_sqlite.dart';
import 'package:logging/logging.dart';
import 'package:source_gen/source_gen.dart';

import 'registration_aggregator.dart';
import 'registration_scanner.dart';

Builder declarativeSqliteGenerator(BuilderOptions options) =>
    PartBuilder([DeclarativeSqliteGenerator()], '.db.dart');

Builder registrationScanner(BuilderOptions options) =>
    RegistrationScanner();

Builder registrationAggregator(BuilderOptions options) =>
    RegistrationAggregator();

class DeclarativeSqliteGenerator extends GeneratorForAnnotation<GenerateDbRecord> {
  static final _logger = Logger('DeclarativeSqliteGenerator');
  
  @override
  String generateForAnnotatedElement(
      Element element, ConstantReader annotation, BuildStep buildStep) {
    _logger.info('=== DeclarativeSqliteGenerator.generateForAnnotatedElement START ===');
    _logger.info('Processing element: ${element.name} (${element.runtimeType})');
    if (element is! ClassElement) {
      throw InvalidGenerationSourceError(
        '`@GenerateDbRecord` can only be used on classes.',
        element: element,
      );
    }

    final buffer = StringBuffer();
    final tableName = annotation.read('tableName').stringValue;
    _logger.info('Extracted table name from annotation: "$tableName"');

    // This is a placeholder. A real implementation would need a way
    // to access the schema definition. For this example, we'll
    // assume a function `createAppSchema()` exists and can be used.
    // This part of the logic is complex and would require more robust
    // schema discovery.
    _logger.info('Creating app schema...');
    final schema = createAppSchema();
    _logger.info('Schema created with ${schema.tables.length} tables: ${schema.tables.map((t) => t.name).join(', ')}');
    
    final table = schema.tables.firstWhere((t) => t.name == tableName,
        orElse: () {
          _logger.severe('Table "$tableName" not found in schema. Available tables: ${schema.tables.map((t) => t.name).join(', ')}');
          throw InvalidGenerationSourceError(
              'Table "$tableName" not found in schema.',
              element: element);
        });
    
    _logger.info('Found table "$tableName" with ${table.columns.length} columns');
    for (final col in table.columns) {
      _logger.fine('  Column: ${col.name} (${col.logicalType}, notNull: ${col.isNotNull})');
    }

    _logger.info('Generating record class...');
    buffer.writeln(_generateRecordClass(element, table));
    buffer.writeln();

    final result = buffer.toString();
    _logger.info('Generated ${result.split('\n').length} lines of code');
    _logger.info('=== DeclarativeSqliteGenerator.generateForAnnotatedElement END ===');
    return result;
  }

  /// Generates typed properties extension
  String _generateRecordClass(ClassElement element, DbTable schemaTable) {
    final className = element.name;
    _logger.info('Generating record class for $className with table ${schemaTable.name}');
    final buffer = StringBuffer();

    // Generate extension for typed properties
    buffer.writeln('/// Generated typed properties for $className');
    buffer.writeln('extension ${className}Generated on $className {');

    _logger.info('Generating getters and setters for ${schemaTable.columns.length} columns');
    _generateGettersAndSetters(buffer, schemaTable);

    buffer.writeln('}');

    _logger.info('Completed record class generation for $className');
    return buffer.toString();
  }

  /// Generates getters and setters based on the actual schema table
  void _generateGettersAndSetters(StringBuffer buffer, DbTable table) {
    final primaryKeyColumns =
        table.keys.where((k) => k.isPrimary).expand((k) => k.columns).toSet();

    buffer.writeln('  // Generated getters and setters');
    for (final col in table.columns) {
      final propertyName = _camelCase(col.name);
      final dartType = _getDartTypeForColumn(col.logicalType, col.isNotNull);
      final getterMethod =
          _getGetterMethodForColumn(col.logicalType, col.isNotNull);

      buffer.writeln('  /// Gets the ${col.name} column value.');
      buffer.writeln(
          '  $dartType get $propertyName => $getterMethod(\'${col.name}\');');

      // Make properties from primary keys immutable (no setter)
      if (primaryKeyColumns.contains(col.name)) {
        continue;
      }

      final setterMethod = _getSetterMethodForColumn(col.logicalType);
      buffer.writeln('  /// Sets the ${col.name} column value.');
      buffer.writeln(
          '  set $propertyName($dartType value) => $setterMethod(\'${col.name}\', value);');
      buffer.writeln();
    }
  }

  /// Gets the Dart type for a column type
  String _getDartTypeForColumn(String logicalType, bool notNull) {
    final baseType = switch (logicalType) {
      'text' || 'guid' => 'String',
      'integer' => 'int',
      'real' => 'double',
      'date' => 'DateTime',
      'fileset' => 'FilesetField',
      _ => 'Object',
    };

    return notNull ? baseType : '$baseType?';
  }

  /// Gets the getter method name for a column type
  String _getGetterMethodForColumn(String logicalType, bool notNull) {
    return switch (logicalType) {
      'text' || 'guid' => notNull ? 'getTextNotNull' : 'getText',
      'integer' => notNull ? 'getIntegerNotNull' : 'getInteger',
      'real' => notNull ? 'getRealNotNull' : 'getReal',
      'date' => notNull ? 'getDateTimeNotNull' : 'getDateTime',
      'fileset' => notNull ? 'getFilesetFieldNotNull' : 'getFilesetField',
      _ => 'getValue',
    };
  }

  /// Gets the setter method name for a column type
  String _getSetterMethodForColumn(String logicalType) {
    return switch (logicalType) {
      'text' || 'guid' => 'setText',
      'integer' => 'setInteger',
      'real' => 'setReal',
      'date' => 'setDateTime',
      'fileset' => 'setFilesetField',
      _ => 'setValue',
    };
  }

  /// Converts snake_case to camelCase
  String _camelCase(String input) {
    final parts = input.split('_');
    if (parts.isEmpty) return input;

    final result = parts[0].toLowerCase() +
        parts.skip(1)
            .map((word) => word.isEmpty ? '' : word[0].toUpperCase() + word.substring(1).toLowerCase())
            .join('');

    return result;
  }
}

// A placeholder function to make the generator compile.
// In a real-world scenario, schema information would be accessed differently,
// possibly by analyzing the source code where the schema is defined.
Schema createAppSchema() {
  final builder = SchemaBuilder();
  builder.table('users', (table) {
    table.guid('id').notNull('');
    table.text('name').notNull('');
    table.text('email').notNull('');
    table.integer('age').notNull(0);
    table.date('created_at').notNull('');
    table.key(['id']).primary();
  });
  builder.table('posts', (table) {
    table.guid('id').notNull('');
    table.guid('user_id').notNull('');
    table.text('title').notNull('');
    table.text('content').notNull('');
    table.date('created_at').notNull('');
    table.text('user_name').notNull(''); // Denormalized for demo simplicity
    table.key(['id']).primary();
  });
  builder.table('comments', (table) {
    table.integer('id').notNull();
    table.integer('post_id').notNull();
    table.integer('user_id').notNull();
    table.text('comment').notNull();
    table.date('created_at').notNull();
    table.key(['id']).primary();
  });
  return builder.build();
}

<!-- END FILE: declarative_sqlite_generator/lib/src/builder.dart -->

<!-- BEGIN FILE: declarative_sqlite_generator/lib/src/registration_aggregator.dart -->
import 'dart:async';
import 'dart:convert';

import 'package:build/build.dart';
import 'package:logging/logging.dart';
import 'package:glob/glob.dart';

/// Aggregator that combines DbRecord metadata and generates the registration file
class RegistrationAggregator implements Builder {
  static final _logger = Logger('RegistrationAggregator');

  @override
  Map<String, List<String>> get buildExtensions => {
    r'$lib$': ['sqlite_factory_registration.dart'],
  };

  @override
  Future<void> build(BuildStep buildStep) async {
    _logger.info('=== RegistrationAggregator.build START ===');
    
    final packageName = buildStep.inputId.package;
    _logger.info('Aggregating DbRecord classes for package: $packageName');

    // Find all .dbrecord_meta files
    final metaFiles = await buildStep.findAssets(Glob('**/*.dbrecord_meta')).toList();
    _logger.info('Found ${metaFiles.length} metadata files');

    final allDbRecordClasses = <DbRecordClassInfo>[];
    
    for (final metaFile in metaFiles) {
      try {
        final metaContent = await buildStep.readAsString(metaFile);
        final metadata = jsonDecode(metaContent) as Map<String, dynamic>;
        
        final sourceFile = metadata['sourceFile'] as String;
        final classes = metadata['dbRecordClasses'] as List<dynamic>;
        
        _logger.info('Processing ${classes.length} classes from $sourceFile');
        
        for (final classData in classes) {
          final classMap = classData as Map<String, dynamic>;
          final className = classMap['className'] as String;
          final importPath = classMap['importPath'] as String;
          
          allDbRecordClasses.add(DbRecordClassInfo(
            className: className,
            importPath: importPath,
          ));
          
          _logger.info('  Found DbRecord class: $className (import: $importPath)');
        }
      } catch (e) {
        _logger.warning('Failed to process metadata file ${metaFile.path}: $e');
      }
    }

    _logger.info('Total DbRecord classes found: ${allDbRecordClasses.length}');

    // Generate the registration file
    final content = _generateRegistrationFile(allDbRecordClasses);
    
    // Write to sqlite_factory_registration.dart
    final outputId = AssetId(packageName, 'lib/sqlite_factory_registration.dart');
    await buildStep.writeAsString(outputId, content);
    
    _logger.info('Generated registration file: ${outputId.path}');
  }

  /// Generates the content of the registration file
  String _generateRegistrationFile(List<DbRecordClassInfo> classes) {
    final buffer = StringBuffer();
    
    // File header
    buffer.writeln('// GENERATED CODE - DO NOT MODIFY BY HAND');
    buffer.writeln('// Generated by declarative_sqlite_generator');
    buffer.writeln();
    
    // Core imports
    buffer.writeln("import 'package:declarative_sqlite/declarative_sqlite.dart';");
    buffer.writeln();
    
    // Import all DbRecord classes
    final uniqueImports = classes.map((c) => c.importPath).toSet();
    for (final importPath in uniqueImports) {
      buffer.writeln("import '$importPath';");
    }
    buffer.writeln();
    
    // Generate the registration class
    buffer.writeln('/// Auto-generated registration for all DbRecord classes');
    buffer.writeln('class SqliteFactoryRegistration {');
    buffer.writeln('  /// Registers all factory methods for DbRecord classes');
    buffer.writeln('  static void registerAllFactories() {');
    
    if (classes.isEmpty) {
      buffer.writeln('    // No DbRecord classes found to register');
    } else {
      // Sort classes by name for consistent output
      final sortedClasses = List<DbRecordClassInfo>.from(classes);
      sortedClasses.sort((a, b) => a.className.compareTo(b.className));
      
      for (final classInfo in sortedClasses) {
        buffer.writeln('    RecordMapFactoryRegistry.register<${classInfo.className}>((data, db) => ${classInfo.className}(data, db));');
      }
    }
    
    buffer.writeln('  }');
    buffer.writeln('}');
    
    return buffer.toString();
  }
}

/// Information about a DbRecord class
class DbRecordClassInfo {
  final String className;
  final String importPath;

  DbRecordClassInfo({
    required this.className,
    required this.importPath,
  });
}
<!-- END FILE: declarative_sqlite_generator/lib/src/registration_aggregator.dart -->

<!-- BEGIN FILE: declarative_sqlite_generator/lib/src/registration_scanner.dart -->
import 'dart:async';
import 'dart:convert';

import 'package:analyzer/dart/element/element.dart';
import 'package:build/build.dart';
import 'package:logging/logging.dart';

/// Scanner that finds DbRecord classes in individual files and outputs metadata
class RegistrationScanner implements Builder {
  static final _logger = Logger('RegistrationScanner');

  @override
  Map<String, List<String>> get buildExtensions => {
    '.dart': ['.dbrecord_meta'],
  };

  @override
  Future<void> build(BuildStep buildStep) async {
    final inputId = buildStep.inputId;
    _logger.info('Scanning file: ${inputId.path}');
    
    final library = await buildStep.inputLibrary;
    final dbRecordClasses = <Map<String, String>>[];
    
    for (final topLevelElement in library.children) {
      if (topLevelElement is ClassElement) {
        _logger.fine('Checking class: ${topLevelElement.name}');
        
        if (_extendsDbRecord(topLevelElement)) {
          final name = topLevelElement.name;
          if (name != null) {
            _logger.info('Found DbRecord class: $name in ${inputId.path}');
            
            // Create metadata for this class
            dbRecordClasses.add({
              'className': name,
              'sourceFile': inputId.path,
              'importPath': inputId.path.replaceFirst('lib/', ''),
            });
          }
        }
      }
    }
    
    // Write metadata as JSON
    final metadata = {
      'sourceFile': inputId.path,
      'dbRecordClasses': dbRecordClasses,
    };
    
    final outputId = inputId.changeExtension('.dbrecord_meta');
    await buildStep.writeAsString(outputId, jsonEncode(metadata));
    
    if (dbRecordClasses.isNotEmpty) {
      _logger.info('Generated metadata for ${dbRecordClasses.length} DbRecord classes from ${inputId.path}');
    }
  }

  /// Checks if a class extends DbRecord
  bool _extendsDbRecord(ClassElement element) {
    _logger.fine('Checking inheritance for class: ${element.name}');
    
    ClassElement? current = element;
    while (current != null) {
      final supertype = current.supertype;
      if (supertype == null) break;
      
      final supertypeName = supertype.element.name;
      _logger.fine('  Checking supertype: $supertypeName');
      
      if (supertypeName == 'DbRecord') {
        _logger.fine('  Found DbRecord inheritance!');
        return true;
      }
      
      // Continue up the inheritance chain
      current = supertype.element as ClassElement?;
    }
    
    return false;
  }
}
<!-- END FILE: declarative_sqlite_generator/lib/src/registration_scanner.dart -->

<!-- BEGIN FILE: declarative_sqlite_generator/lib/src/standalone_registration_builder.dart -->
import 'dart:async';

import 'package:analyzer/dart/element/element.dart';
import 'package:build/build.dart';
import 'package:logging/logging.dart';

/// Builder that generates a standalone registration file for all DbRecord classes in a package
class StandaloneRegistrationBuilder implements Builder {
  static final _logger = Logger('StandaloneRegistrationBuilder');

  @override
  Map<String, List<String>> get buildExtensions => {
    r'$lib$': ['generated_registration.dart'],
  };

  @override
  Future<void> build(BuildStep buildStep) async {
    _logger.info('=== StandaloneRegistrationBuilder.build START ===');
    
    // Get all libraries from the current package
    final packageName = buildStep.inputId.package;
    final allLibraries = await buildStep.resolver.libraries.toList();
    
    _logger.info('Scanning package "$packageName" for DbRecord classes...');
    _logger.info('Found ${allLibraries.length} total libraries');

    final dbRecordClasses = <DbRecordClassInfo>[];
    var packageLibraryCount = 0;

    for (final library in allLibraries) {
      // Only process libraries from the current package
      if (library.identifier.startsWith('package:$packageName/')) {
        packageLibraryCount++;
        _logger.info('Processing package library #$packageLibraryCount: ${library.identifier}');
        
        for (final topLevelElement in library.children) {
          if (topLevelElement is ClassElement) {
            _logger.fine('Checking class: ${topLevelElement.name} in ${library.identifier}');
            
            if (_extendsDbRecord(topLevelElement)) {
              final name = topLevelElement.name;
              if (name != null) {
                _logger.info('Found DbRecord class: $name');
                
                // Extract the file path for import
                final libraryUri = library.identifier;
                final relativePath = libraryUri.replaceFirst('package:$packageName/', '');
                
                dbRecordClasses.add(DbRecordClassInfo(
                  className: name,
                  importPath: relativePath,
                ));
              }
            }
          }
        }
      }
    }

    _logger.info('Found ${dbRecordClasses.length} DbRecord classes total: ${dbRecordClasses.map((c) => c.className).join(', ')}');

    // Generate the registration file
    final content = _generateRegistrationFile(dbRecordClasses);
    
    // Write to generated_registration.dart  
    final outputId = AssetId(packageName, 'lib/generated_registration.dart');
    await buildStep.writeAsString(outputId, content);
    
    _logger.info('Generated registration file: ${outputId.path}');
  }

  /// Checks if a class extends DbRecord
  bool _extendsDbRecord(ClassElement element) {
    _logger.fine('Checking inheritance for class: ${element.name}');
    
    ClassElement? current = element;
    while (current != null) {
      _logger.fine('  Current class: ${current.name}');
      
      final supertype = current.supertype;
      if (supertype == null) {
        _logger.fine('  No supertype found, stopping');
        break;
      }
      
      final supertypeName = supertype.element.name;
      _logger.fine('  Supertype: $supertypeName');
      
      if (supertypeName == 'DbRecord') {
        _logger.fine('  Found DbRecord inheritance!');
        return true;
      }
      
      // Continue up the inheritance chain
      current = supertype.element as ClassElement?;
    }
    
    _logger.fine('  No DbRecord inheritance found');
    return false;
  }

  /// Generates the content of the registration file
  String _generateRegistrationFile(List<DbRecordClassInfo> classes) {
    final buffer = StringBuffer();
    
    // File header
    buffer.writeln('// GENERATED CODE - DO NOT MODIFY BY HAND');
    buffer.writeln('// Generated by declarative_sqlite_generator');
    buffer.writeln();
    
    // Core imports
    buffer.writeln("import 'package:declarative_sqlite/declarative_sqlite.dart';");
    buffer.writeln();
    
    // Import all DbRecord classes
    for (final classInfo in classes) {
      buffer.writeln("import '${classInfo.importPath}';");
    }
    buffer.writeln();
    
    // Generate the registration class
    buffer.writeln('/// Auto-generated registration for all DbRecord classes');
    buffer.writeln('class GeneratedRegistration {');
    buffer.writeln('  /// Registers all factory methods for DbRecord classes');
    buffer.writeln('  static void registerAllFactories() {');
    
    if (classes.isEmpty) {
      buffer.writeln('    // No DbRecord classes found to register');
    } else {
      for (final classInfo in classes) {
        buffer.writeln('    RecordMapFactoryRegistry.register<${classInfo.className}>(${classInfo.className}.fromMap);');
      }
    }
    
    buffer.writeln('  }');
    buffer.writeln('}');
    
    return buffer.toString();
  }
}

/// Information about a DbRecord class
class DbRecordClassInfo {
  final String className;
  final String importPath;

  DbRecordClassInfo({
    required this.className,
    required this.importPath,
  });
}
<!-- END FILE: declarative_sqlite_generator/lib/src/standalone_registration_builder.dart -->

<!-- BEGIN FILE: declarative_sqlite_generator/pubspec.yaml -->
name: declarative_sqlite_generator
description: A build generator that generates data classes for interacting with table rows and view rows from declarative_sqlite schemas.
version: 1.0.0
repository: https://github.com/graknol/declarative_sqlite
publish_to: none

environment:
  sdk: ^3.9.2

dependencies:
  # Core build system dependencies
  build: ^4.0.0
  build_config: ^1.2.0
  source_gen: ^4.0.1
  analyzer: ^8.2.0

  # Code generation utilities
  code_builder: ^4.7.0
  dart_style: ^3.0.0

  # Reference to the main library for schema metadata
  declarative_sqlite:
    path: ../declarative_sqlite

dev_dependencies:
  lints: ^3.0.0
  test: ^1.24.0
  sqflite_common_ffi: ^2.3.6 # For examples

<!-- END FILE: declarative_sqlite_generator/pubspec.yaml -->

<!-- BEGIN FILE: demo/README.md -->
# demo

A new Flutter project.

<!-- END FILE: demo/README.md -->

<!-- BEGIN FILE: demo/analysis_options.yaml -->
include: package:flutter_lints/flutter.yaml

<!-- END FILE: demo/analysis_options.yaml -->

<!-- BEGIN FILE: demo/build.yaml -->
targets:
  $default:
    builders:
      declarative_sqlite_generator:declarative_sqlite_generator:
        enabled: true
        generate_for:
          - lib/**
      declarative_sqlite_generator:registration_scanner:
        enabled: true
        generate_for:
          - lib/**
      declarative_sqlite_generator:registration_aggregator:
        enabled: true

<!-- END FILE: demo/build.yaml -->

<!-- BEGIN FILE: demo/lib/main.dart -->
import 'package:flutter/material.dart';
import 'package:declarative_sqlite_flutter/declarative_sqlite_flutter.dart';
import 'package:declarative_sqlite/declarative_sqlite.dart';
import 'package:uuid/uuid.dart';

import 'user.dart';
import 'post.dart';
import 'sqlite_factory_registration.dart';

const uuid = Uuid();

void main() {
  // Register all factory functions using auto-generated registration
  SqliteFactoryRegistration.registerAllFactories();

  runApp(const DeclarativeSqliteDemo());
}

class DeclarativeSqliteDemo extends StatelessWidget {
  const DeclarativeSqliteDemo({super.key});

  @override
  Widget build(BuildContext context) {
    return MaterialApp(
      title: 'Declarative SQLite Demo',
      theme: ThemeData(primarySwatch: Colors.blue, useMaterial3: true),
      home: DatabaseProvider(
        schema: _buildDatabaseSchema,
        databaseName: 'demo.db',
        recreateDatabase: false,
        child: const DemoHomeScreen(),
      ),
    );
  }

  void _buildDatabaseSchema(SchemaBuilder builder) {
    // Users table
    builder.table('users', (table) {
      table.guid('id').notNull('');
      table.text('name').notNull('');
      table.text('email').notNull('');
      table.integer('age').notNull(0);
      table.text('gender').notNull('non-binary');
      table.date('created_at').notNull().defaultCallback(() => DateTime.now());
      table.key(['id']).primary();
    });

    // Posts table
    builder.table('posts', (table) {
      table.guid('id').notNull('');
      table.guid('user_id').notNull('');
      table.text('title').notNull('');
      table.text('content').notNull('');
      table.date('created_at').notNull().defaultCallback(() => DateTime.now());
      table.text('user_name').notNull(''); // Denormalized for demo simplicity
      table.key(['id']).primary();
    });
  }
}

class DemoHomeScreen extends StatefulWidget {
  const DemoHomeScreen({super.key});

  @override
  State<DemoHomeScreen> createState() => _DemoHomeScreenState();
}

class _DemoHomeScreenState extends State<DemoHomeScreen> {
  bool _showPostsOnly = false;
  String _currentFilter = 'all'; // 'all', 'young', 'old'

  @override
  void initState() {
    super.initState();
    // Add initial data after the widget is built and database is available
    WidgetsBinding.instance.addPostFrameCallback((_) {
      _populateInitialData();
    });
  }

  Future<void> _populateInitialData() async {
    try {
      final db = DatabaseProvider.of(context);

      // Check if users table is empty
      final existingUsers = await db.rawQuery(
        'SELECT COUNT(*) as count FROM users',
      );
      final userCount = existingUsers.first['count'] as int;

      if (userCount == 0) {
        // Add initial users
        final now = DateTime.now();
        final users = [
          {
            // ID and created_at will be auto-generated via callbacks!
            'name': 'Alice Johnson',
            'email': 'alice.johnson@example.com',
            'age': 28,
          },
          {
            'id': uuid.v4(),
            'name': 'Bob Smith',
            'email': 'bob.smith@example.com',
            'age': 22,
            'created_at': now
                .subtract(const Duration(days: 25)),
          },
          {
            'id': uuid.v4(),
            'name': 'Charlie Brown',
            'email': 'charlie.brown@example.com',
            'age': 35,
            'created_at': now
                .subtract(const Duration(days: 20)),
          },
          {
            'id': uuid.v4(),
            'name': 'Diana Prince',
            'email': 'diana.prince@example.com',
            'age': 24,
            'created_at': now
                .subtract(const Duration(days: 15)),
          },
          {
            'id': uuid.v4(),
            'name': 'Edward Wilson',
            'email': 'edward.wilson@example.com',
            'age': 45,
            'created_at': now
                .subtract(const Duration(days: 10)),
          },
        ];

        // Insert users
        for (final user in users) {
          await db.insert('users', user);
        }

        // Add initial posts
        final posts = [
          {
            'id': uuid.v4(),
            'user_id': users[0]['id'],
            'title': 'Welcome to Declarative SQLite!',
            'content':
                'This is my first post using the new declarative SQLite library. It makes database operations so much easier!',
            'user_name': users[0]['name'],
            'created_at': now
                .subtract(const Duration(days: 5)),
          },
          {
            'id': uuid.v4(),
            'user_id': users[1]['id'],
            'title': 'Learning Flutter Development',
            'content':
                'Just started learning Flutter and I\'m amazed by how quickly you can build beautiful apps.',
            'user_name': users[1]['name'],
            'created_at': now
                .subtract(const Duration(days: 4)),
          },
          {
            'id': uuid.v4(),
            'user_id': users[0]['id'],
            'title': 'Database Reactivity is Amazing',
            'content':
                'The way the UI automatically updates when data changes is incredible. No more manual refreshes!',
            'user_name': users[0]['name'],
            'created_at': now
                .subtract(const Duration(days: 3)),
          },
          {
            'id': uuid.v4(),
            'user_id': users[2]['id'],
            'title': 'Building Better Apps',
            'content':
                'With declarative SQLite, building data-driven apps has never been easier. The reactive queries are a game changer.',
            'user_name': users[2]['name'],
            'created_at': now
                .subtract(const Duration(days: 2)),
          },
          {
            'id': uuid.v4(),
            'user_id': users[3]['id'],
            'title': 'Tips for Mobile Development',
            'content':
                'Here are some tips I\'ve learned while developing mobile apps with Flutter and SQLite.',
            'user_name': users[3]['name'],
            'created_at': now
                .subtract(const Duration(days: 1)),
          },
        ];

        // Insert posts
        for (final post in posts) {
          await db.insert('posts', post);
        }

        if (mounted) {
          ScaffoldMessenger.of(context).showSnackBar(
            const SnackBar(
              content: Text('Initial demo data loaded successfully!'),
              backgroundColor: Colors.green,
            ),
          );
        }
      }
    } catch (e) {
      if (mounted) {
        ScaffoldMessenger.of(context).showSnackBar(
          SnackBar(
            content: Text('Error loading initial data: $e'),
            backgroundColor: Colors.red,
          ),
        );
      }
    }
  }

  @override
  Widget build(BuildContext context) {
    return Scaffold(
      appBar: AppBar(
        title: const Text('Declarative SQLite Demo'),
        backgroundColor: Theme.of(context).colorScheme.inversePrimary,
      ),
      body: Column(
        children: [
          _buildControlPanel(),
          Expanded(
            child: _showPostsOnly ? _buildPostsList() : _buildUsersList(),
          ),
        ],
      ),
      floatingActionButton: Column(
        mainAxisAlignment: MainAxisAlignment.end,
        children: [
          FloatingActionButton.extended(
            onPressed: _addSampleUser,
            heroTag: "addUser",
            icon: const Icon(Icons.person_add),
            label: const Text('Add User'),
          ),
          const SizedBox(height: 8),
          FloatingActionButton.extended(
            onPressed: _addSamplePost,
            heroTag: "addPost",
            icon: const Icon(Icons.add_comment),
            label: const Text('Add Post'),
          ),
        ],
      ),
    );
  }

  Widget _buildControlPanel() {
    return Container(
      padding: const EdgeInsets.all(16),
      child: Column(
        crossAxisAlignment: CrossAxisAlignment.start,
        children: [
          const Text(
            'Demo Controls',
            style: TextStyle(fontSize: 18, fontWeight: FontWeight.bold),
          ),
          const SizedBox(height: 8),
          Row(
            children: [
              Expanded(
                child: SegmentedButton<String>(
                  segments: const [
                    ButtonSegment(value: 'all', label: Text('All Users')),
                    ButtonSegment(value: 'young', label: Text('Young (‚â§25)')),
                    ButtonSegment(value: 'old', label: Text('Older (>25)')),
                  ],
                  selected: {_currentFilter},
                  onSelectionChanged: (Set<String> selection) {
                    setState(() {
                      _currentFilter = selection.first;
                    });
                  },
                ),
              ),
            ],
          ),
          const SizedBox(height: 8),
          Row(
            children: [
              Expanded(
                child: SwitchListTile(
                  title: const Text('Show Posts Instead'),
                  value: _showPostsOnly,
                  onChanged: (value) {
                    setState(() {
                      _showPostsOnly = value;
                    });
                  },
                ),
              ),
            ],
          ),
          const Divider(),
          Column(
            children: [
              Row(
                children: [
                  Expanded(
                    child: ElevatedButton.icon(
                      onPressed: _updateRandomUser,
                      icon: const Icon(Icons.refresh, size: 16),
                      label: const Text('Update User Age'),
                      style: ElevatedButton.styleFrom(
                        padding: const EdgeInsets.symmetric(
                          vertical: 8,
                          horizontal: 12,
                        ),
                      ),
                    ),
                  ),
                  const SizedBox(width: 8),
                  Expanded(
                    child: ElevatedButton.icon(
                      onPressed: _updateUserOutsideFilter,
                      icon: const Icon(Icons.logout, size: 16),
                      label: const Text('Move Outside Filter'),
                      style: ElevatedButton.styleFrom(
                        padding: const EdgeInsets.symmetric(
                          vertical: 8,
                          horizontal: 12,
                        ),
                      ),
                    ),
                  ),
                ],
              ),
              const SizedBox(height: 4),
              Text(
                'Test reactive updates: First button updates within filter, second moves user outside current filter',
                style: Theme.of(context).textTheme.bodySmall?.copyWith(
                  color: Colors.grey[600],
                  fontSize: 11,
                ),
                textAlign: TextAlign.center,
              ),
            ],
          ),
        ],
      ),
    );
  }

  Widget _buildUsersList() {
    return QueryListView<User>(
      key: const ValueKey('users'),
      query: (q) {
        q.from('users');

        // Apply age filter based on current selection
        switch (_currentFilter) {
          case 'young':
            q.where(col('age').lte(25));
            break;
          case 'old':
            q.where(and([col('age').gt(25), col('created_at').gt(DateTime.now().add(const Duration(minutes: -5)))]));
            break;
          case 'all':
          default:
            // No filter
            break;
        }

        q.orderBy(['created_at DESC']);
      },
      loadingBuilder: (context) => const Center(
        child: Column(
          mainAxisAlignment: MainAxisAlignment.center,
          children: [
            CircularProgressIndicator(),
            SizedBox(height: 16),
            Text('Loading users...'),
          ],
        ),
      ),
      errorBuilder: (context, error) => Center(
        child: Column(
          mainAxisAlignment: MainAxisAlignment.center,
          children: [
            const Icon(Icons.error, color: Colors.red, size: 48),
            const SizedBox(height: 16),
            Text(
              'Error: $error',
              style: const TextStyle(color: Colors.red),
              textAlign: TextAlign.center,
            ),
          ],
        ),
      ),
      itemBuilder: (context, user) => Card(
        margin: const EdgeInsets.symmetric(horizontal: 16, vertical: 4),
        child: ListTile(
          leading: CircleAvatar(
            backgroundColor: Colors.blue,
            child: Text(
              user.name.substring(0, 1).toUpperCase(),
              style: const TextStyle(color: Colors.white),
            ),
          ),
          title: Text(user.name),
          subtitle: Text('${user.email} ‚Ä¢ Age: ${user.age}'),
          trailing: IconButton(
            icon: const Icon(Icons.edit),
            onPressed: () => _editUser(user),
          ),
          onTap: () => _showUserDetails(user),
        ),
      ),
      padding: const EdgeInsets.only(bottom: 160), // Account for FABs
    );
  }

  Widget _buildPostsList() {
    return QueryListView<Post>(
      key: const ValueKey('posts'),
      query: (q) => q.from('posts').orderBy(['created_at DESC']),
      loadingBuilder: (context) => const Center(
        child: Column(
          mainAxisAlignment: MainAxisAlignment.center,
          children: [
            CircularProgressIndicator(),
            SizedBox(height: 16),
            Text('Loading posts...'),
          ],
        ),
      ),
      errorBuilder: (context, error) => Center(
        child: Column(
          mainAxisAlignment: MainAxisAlignment.center,
          children: [
            const Icon(Icons.error, color: Colors.red, size: 48),
            const SizedBox(height: 16),
            Text(
              'Error: $error',
              style: const TextStyle(color: Colors.red),
              textAlign: TextAlign.center,
            ),
          ],
        ),
      ),
      itemBuilder: (context, post) => Card(
        margin: const EdgeInsets.symmetric(horizontal: 16, vertical: 4),
        child: Padding(
          padding: const EdgeInsets.all(16),
          child: Column(
            crossAxisAlignment: CrossAxisAlignment.start,
            children: [
              Row(
                children: [
                  Expanded(
                    child: Text(
                      post.title,
                      style: const TextStyle(
                        fontWeight: FontWeight.bold,
                        fontSize: 16,
                      ),
                    ),
                  ),
                  Text(
                    'by ${post.userName}',
                    style: TextStyle(color: Colors.grey[600], fontSize: 12),
                  ),
                ],
              ),
              const SizedBox(height: 8),
              Text(post.content),
              const SizedBox(height: 8),
              Text(
                'Posted ${_formatDate(post.createdAt)}',
                style: TextStyle(color: Colors.grey[600], fontSize: 12),
              ),
            ],
          ),
        ),
      ),
      padding: const EdgeInsets.only(bottom: 160), // Account for FABs
    );
  }

  Future<void> _addSampleUser() async {
    final db = DatabaseProvider.of(context);
    final now = DateTime.now();

    // Generate a random user
    final names = [
      'Alice',
      'Bob',
      'Charlie',
      'Diana',
      'Eve',
      'Frank',
      'Grace',
      'Henry',
    ];
    final domains = ['gmail.com', 'yahoo.com', 'example.com', 'test.org'];

    final name = names[DateTime.now().millisecond % names.length];
    final domain = domains[DateTime.now().microsecond % domains.length];
    final age = 18 + (DateTime.now().millisecond % 40); // Age between 18-57

    await db.insert('users', {
      'id': uuid.v4(),
      'name': '$name ${DateTime.now().millisecond}',
      'email': '${name.toLowerCase()}${DateTime.now().millisecond}@$domain',
      'age': age,
      'created_at': now,
    });

    if (mounted) {
      ScaffoldMessenger.of(
        context,
      ).showSnackBar(SnackBar(content: Text('Added user: $name (Age: $age)')));
    }
  }

  Future<void> _addSamplePost() async {
    final db = DatabaseProvider.of(context);

    // First, get a random user
    final users = await db.rawQuery('SELECT * FROM users LIMIT 10');
    if (users.isEmpty) {
      if (mounted) {
        ScaffoldMessenger.of(context).showSnackBar(
          const SnackBar(content: Text('Please add some users first!')),
        );
      }
      return;
    }

    final randomUser = users[DateTime.now().millisecond % users.length];
    final now = DateTime.now();

    final postTitles = [
      'My thoughts on Flutter',
      'Learning SQLite',
      'Declarative programming rocks!',
      'Building better apps',
      'Database design patterns',
    ];

    final postContents = [
      'Flutter makes mobile development so much easier!',
      'Working with databases can be fun when done right.',
      'Declarative approaches lead to cleaner, more maintainable code.',
      'Always thinking about user experience first.',
      'Good database design is crucial for app performance.',
    ];

    final title = postTitles[DateTime.now().millisecond % postTitles.length];
    final content =
        postContents[DateTime.now().microsecond % postContents.length];

    await db.insert('posts', {
      'id': uuid.v4(),
      'user_id': randomUser['id'],
      'title': '$title ${DateTime.now().millisecond}',
      'content': content,
      'user_name': randomUser['name'],
      'created_at': now,
    });

    if (mounted) {
      ScaffoldMessenger.of(context).showSnackBar(
        SnackBar(
          content: Text('Added post: "$title" by ${randomUser['name']}'),
        ),
      );
    }
  }

  Future<void> _updateRandomUser() async {
    final db = DatabaseProvider.of(context);

    // Get users in current filter
    WhereClause? whereClause;
    switch (_currentFilter) {
      case 'young':
        whereClause = col('age').lte(25);
      case 'old':
        whereClause = col('age').gt(25);
        break;
    }

    final users = await db.queryTyped<User>((q) => q.from("users").where(whereClause));

    if (users.isEmpty) {
      if (mounted) {
        ScaffoldMessenger.of(context).showSnackBar(
          const SnackBar(content: Text('No users found in current filter!')),
        );
      }
      return;
    }

    final randomUser = users[DateTime.now().millisecond % users.length];
    final newAge = 20 + (DateTime.now().millisecond % 30); // Age between 20-49

    randomUser.age = newAge;
    await randomUser.save();

    if (mounted) {
      ScaffoldMessenger.of(context).showSnackBar(
        SnackBar(
          content: Text(
            'Updated ${randomUser['name']} age to $newAge (was ${randomUser['age']})',
          ),
        ),
      );
    }
  }

  Future<void> _updateUserOutsideFilter() async {
    final db = DatabaseProvider.of(context);

    // Get users in current filter
    WhereClause? whereClause;
    switch (_currentFilter) {
      case 'young':
        whereClause = col('age').lte(25);
      case 'old':
        whereClause = col('age').gt(25);
        break;
      case 'all':
        // When showing all, update someone to be very old (outside typical range)
        whereClause = col('age').lt(60);
        break;
    }

    final users = await db.queryTyped<User>((q) => q.from("users").where(whereClause));

    if (users.isEmpty) {
      if (mounted) {
        ScaffoldMessenger.of(context).showSnackBar(
          const SnackBar(
            content: Text('No users found outside current filter!'),
          ),
        );
      }
      return;
    }

    final randomUser = users[DateTime.now().millisecond % users.length];

    // Update age to something that will move them outside current filter
    int newAge;
    switch (_currentFilter) {
      case 'young':
        newAge = 30 + (DateTime.now().millisecond % 20); // Make them older
        break;
      case 'old':
        newAge = 20 + (DateTime.now().millisecond % 5); // Make them younger
        break;
      case 'all':
      default:
        newAge = 65; // Very old
        break;
    }

    randomUser.age = newAge;
    await randomUser.save();

    if (mounted) {
      ScaffoldMessenger.of(context).showSnackBar(
        SnackBar(
          content: Text(
            'Updated ${randomUser['name']} age to $newAge (outside current filter) - they should disappear from the list!',
          ),
          duration: const Duration(seconds: 4),
        ),
      );
    }
  }

  void _editUser(User user) {
    // Show a simple dialog to edit user age
    showDialog(
      context: context,
      builder: (context) => _EditUserDialog(user: user),
    );
  }

  void _showUserDetails(User user) {
    showDialog(
      context: context,
      builder: (context) => AlertDialog(
        title: Text(user.name),
        content: Column(
          mainAxisSize: MainAxisSize.min,
          crossAxisAlignment: CrossAxisAlignment.start,
          children: [
            Text('Email: ${user.email}'),
            Text('Age: ${user.age}'),
            Text('Created: ${_formatDate(user.createdAt)}'),
            Text('ID: ${user.id}'),
            Text('Gender: ${user.gender}'),
          ],
        ),
        actions: [
          TextButton(
            onPressed: () => Navigator.of(context).pop(),
            child: const Text('Close'),
          ),
        ],
      ),
    );
  }

  String _formatDate(DateTime date) {
    return '${date.day}/${date.month}/${date.year} ${date.hour}:${date.minute.toString().padLeft(2, '0')}';
  }
}

class _EditUserDialog extends StatefulWidget {
  final User user;

  const _EditUserDialog({required this.user});

  @override
  State<_EditUserDialog> createState() => _EditUserDialogState();
}

class _EditUserDialogState extends State<_EditUserDialog> {
  late TextEditingController _nameController;
  late TextEditingController _ageController;

  @override
  void initState() {
    super.initState();
    _nameController = TextEditingController(text: widget.user.name);
    _ageController = TextEditingController(text: widget.user.age.toString());
  }

  @override
  void dispose() {
    _nameController.dispose();
    _ageController.dispose();
    super.dispose();
  }

  @override
  Widget build(BuildContext context) {
    return AlertDialog(
      title: const Text('Edit User'),
      content: Column(
        mainAxisSize: MainAxisSize.min,
        children: [
          TextField(
            controller: _nameController,
            decoration: const InputDecoration(labelText: 'Name'),
          ),
          const SizedBox(height: 16),
          TextField(
            controller: _ageController,
            decoration: const InputDecoration(labelText: 'Age'),
            keyboardType: TextInputType.number,
          ),
        ],
      ),
      actions: [
        TextButton(
          onPressed: () => Navigator.of(context).pop(),
          child: const Text('Cancel'),
        ),
        ElevatedButton(onPressed: _saveChanges, child: const Text('Save')),
      ],
    );
  }

  Future<void> _saveChanges() async {
    final name = _nameController.text.trim();
    final ageText = _ageController.text.trim();

    if (name.isEmpty || ageText.isEmpty) {
      return;
    }

    final age = int.tryParse(ageText);
    if (age == null || age < 0 || age > 120) {
      return;
    }

    widget.user.name = name;
    widget.user.age = age;
    await widget.user.save();

    if (mounted) {
      Navigator.of(context).pop();
      ScaffoldMessenger.of(
        context,
      ).showSnackBar(SnackBar(content: Text('Updated ${widget.user.name}')));
    }
  }
}

<!-- END FILE: demo/lib/main.dart -->

<!-- BEGIN FILE: demo/lib/post.dart -->

import 'package:declarative_sqlite/declarative_sqlite.dart';

part 'post.db.dart';

@GenerateDbRecord('posts')
class Post extends DbRecord {
  Post(Map<String, Object?> data, DeclarativeDatabase database) 
      : super(data, 'posts', database);
}

<!-- END FILE: demo/lib/post.dart -->

<!-- BEGIN FILE: demo/lib/post.db.dart -->
// GENERATED CODE - DO NOT MODIFY BY HAND
// dart format width=80

part of 'post.dart';

// **************************************************************************
// DeclarativeSqliteGenerator
// **************************************************************************

/// Generated typed properties for Post
extension PostGenerated on Post {
  // Generated getters and setters
  /// Gets the system_id column value.
  String get systemId => getTextNotNull('system_id');

  /// Sets the system_id column value.
  set systemId(String value) => setText('system_id', value);

  /// Gets the system_created_at column value.
  Object get systemCreatedAt => getValue('system_created_at');

  /// Sets the system_created_at column value.
  set systemCreatedAt(Object value) => setValue('system_created_at', value);

  /// Gets the system_version column value.
  Object get systemVersion => getValue('system_version');

  /// Sets the system_version column value.
  set systemVersion(Object value) => setValue('system_version', value);

  /// Gets the id column value.
  String get id => getTextNotNull('id');

  /// Gets the user_id column value.
  String get userId => getTextNotNull('user_id');

  /// Sets the user_id column value.
  set userId(String value) => setText('user_id', value);

  /// Gets the title column value.
  String get title => getTextNotNull('title');

  /// Sets the title column value.
  set title(String value) => setText('title', value);

  /// Gets the content column value.
  String get content => getTextNotNull('content');

  /// Sets the content column value.
  set content(String value) => setText('content', value);

  /// Gets the created_at column value.
  DateTime get createdAt => getDateTimeNotNull('created_at');

  /// Sets the created_at column value.
  set createdAt(DateTime value) => setDateTime('created_at', value);

  /// Gets the user_name column value.
  String get userName => getTextNotNull('user_name');

  /// Sets the user_name column value.
  set userName(String value) => setText('user_name', value);
}

<!-- END FILE: demo/lib/post.db.dart -->

<!-- BEGIN FILE: demo/lib/sqlite_factory_registration.dart -->
// GENERATED CODE - DO NOT MODIFY BY HAND
// Generated by declarative_sqlite_generator

import 'package:declarative_sqlite/declarative_sqlite.dart';

import 'post.dart';
import 'user.dart';

/// Auto-generated registration for all DbRecord classes
class SqliteFactoryRegistration {
  /// Registers all factory methods for DbRecord classes
  static void registerAllFactories() {
    RecordMapFactoryRegistry.register<Post>((data, db) => Post(data, db));
    RecordMapFactoryRegistry.register<User>((data, db) => User(data, db));
  }
}

<!-- END FILE: demo/lib/sqlite_factory_registration.dart -->

<!-- BEGIN FILE: demo/lib/user.dart -->

import 'package:declarative_sqlite/declarative_sqlite.dart';

part 'user.db.dart';

@GenerateDbRecord('users')
class User extends DbRecord {
  User(Map<String, Object?> data, DeclarativeDatabase database) 
      : super(data, 'users', database);
}
<!-- END FILE: demo/lib/user.dart -->

<!-- BEGIN FILE: demo/lib/user.db.dart -->
// GENERATED CODE - DO NOT MODIFY BY HAND
// dart format width=80

part of 'user.dart';

// **************************************************************************
// DeclarativeSqliteGenerator
// **************************************************************************

/// Generated typed properties for User
extension UserGenerated on User {
  // Generated getters and setters
  /// Gets the system_id column value.
  String get systemId => getTextNotNull('system_id');

  /// Sets the system_id column value.
  set systemId(String value) => setText('system_id', value);

  /// Gets the system_created_at column value.
  Object get systemCreatedAt => getValue('system_created_at');

  /// Sets the system_created_at column value.
  set systemCreatedAt(Object value) => setValue('system_created_at', value);

  /// Gets the system_version column value.
  Object get systemVersion => getValue('system_version');

  /// Sets the system_version column value.
  set systemVersion(Object value) => setValue('system_version', value);

  /// Gets the id column value.
  String get id => getTextNotNull('id');

  /// Gets the name column value.
  String get name => getTextNotNull('name');

  /// Sets the name column value.
  set name(String value) => setText('name', value);

  /// Gets the email column value.
  String get email => getTextNotNull('email');

  /// Sets the email column value.
  set email(String value) => setText('email', value);

  /// Gets the age column value.
  int get age => getIntegerNotNull('age');

  /// Sets the age column value.
  set age(int value) => setInteger('age', value);
  
  /// Gets the email column value.
  String get gender => getTextNotNull('gender');

  /// Sets the gender column value.
  set gender(String value) => setText('gender', value);

  /// Gets the created_at column value.
  DateTime get createdAt => getDateTimeNotNull('created_at');

  /// Sets the created_at column value.
  set createdAt(DateTime value) => setDateTime('created_at', value);
}

<!-- END FILE: demo/lib/user.db.dart -->

<!-- BEGIN FILE: demo/pubspec.yaml -->
name: demo
description: "A new Flutter project."
publish_to: "none"
version: 0.1.0

environment:
  sdk: ^3.9.2

dependencies:
  flutter:
    sdk: flutter
  declarative_sqlite:
    path: ../declarative_sqlite
  declarative_sqlite_flutter:
    path: ../declarative_sqlite_flutter
  uuid: ^4.5.1
  sqflite: ^2.4.2

dev_dependencies:
  flutter_test:
    sdk: flutter
  flutter_lints: ^3.0.0
  build_runner: ^2.4.13
  declarative_sqlite_generator:
    path: ../declarative_sqlite_generator

flutter:
  uses-material-design: true

<!-- END FILE: demo/pubspec.yaml -->

---
Generated with llmifier v0.2.2
Created by Software Engineering Philipp Gerber
Repository: https://github.com/PhilippHGerber/llmifier
Package: https://pub.dev/packages/llmifier
